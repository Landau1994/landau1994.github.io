---
title: Dobrow-chap3
author: å¤ç›®æ²‰åŸ
avatar: /images/faceicon.png
authorLink: 'https://github.com/Landau1994'
authorAbout: 'https://github.com/Landau1994'
authorDesc: A PhD student in bioinformatics
mathjax: true
categories:
  - math
tags:
  - note
date: 2020-04-25 20:55:53
keywords:
description: Markov Chains for the Long term
photos:
---

This is a note of the textbook `Introduction to stochastic processes with R`

> There exists everywhere a medium in things, determined by equilibrium.
>                                                  â€”Dmitri Mendeleev

æ‰¿æ¥ä¸Šç« æœ€åçš„æ•°å€¼æ¡ˆä¾‹ï¼Œæœ¬ç« ä¸»è¦è®²è½¬ç§»æ­¥æ•°è¶‹äºæ— ç©·æ—¶é©¬å°”å¯å¤«é“¾çš„æ€§è´¨ã€‚

### 3.1 Limiting Distribution

#### 3.1.1 å®šä¹‰

ä½œè€…ç»™äº†æœ‰ä¸€ä¸ªå®šä¹‰å’Œä¸‰ä¸ªç­‰ä»·å®šä¹‰ã€‚è¿™ä¸ªå«ä¹‰æœ€æ¸…æ¥šï¼š

> A limiting distribution
for the Markov chain is a probability distribution ğ€ with the property that, for any initial distribution $\boldsymbol{\alpha}$:
> $$\lim_{n\rightarrow\infty}\boldsymbol{\alpha}P^n=\boldsymbol{\lambda}$$

è¿™ä¸ªå®šä¹‰ä¸åŸå®šä¹‰çš„ç­‰ä»·æ€§ä¹Ÿå¾ˆå®¹æ˜“ç†è§£ï¼š

è‹¥å¯¹æŸä¸€é©¬å°”å¯å¤«é“¾çš„çŠ¶æ€è½¬ç§»çŸ©é˜µæœ‰ï¼š
$$\lim_{n\rightarrow\infty}P^n_{ij}=\lambda_j$$
å¹¶ä¸”è®¾åˆå§‹åˆ†å¸ƒ$\boldsymbol{\alpha}=(\alpha_1,\dots,\alpha_n)$,çŠ¶æ€æ€»æ•°ä¸º$m$
åˆ™æœ‰ï¼š
$$\begin{aligned}
  \lim_{n\rightarrow\infty}\boldsymbol{\alpha}\boldsymbol{P}^n &=(\alpha_1,\dots,\alpha_n)\begin{pmatrix}
   \lambda_1 & \lambda_2 & \cdots &  \lambda_m \\
   \lambda_1 & \lambda_2 & \cdots &  \lambda_m \\
   \vdots & \vdots & \ddots &  \lambda_m \\
   \lambda_1 & \lambda_2 & \cdots &  \lambda_m
  \end{pmatrix} \\ 
  & = \begin{pmatrix}
    \lambda_1\sum_{i=1}^n\alpha_i \\
    \lambda_2\sum_{i=1}^n\alpha_i \\
    \cdots \\
    \lambda_m\sum_{i=1}^n\alpha_i
  \end{pmatrix} \\
  & = \begin{pmatrix}
    \lambda_1 \\
    \lambda_2 \\
    \cdots \\
    \lambda_m
  \end{pmatrix} \\
  & = \boldsymbol{\lambda}
\end{aligned}
  

$$


Ex3.1 Two state Markov Chain
è®¡ç®—æ¡ˆä¾‹ï¼›

#### 3.1.2 Proportion of Time in Each State

åˆ©ç”¨è®¡ç®—æ¡ä»¶æœŸæœ›çš„æŠ€æœ¯ï¼Œæ¥ä»çŠ¶æ€åœ¨è¿‡ç¨‹ä¸­æ‰€å çš„æ¯”ä¾‹æ¥ç†è§£Limit distribution



Ex3.2

```r
###### Simulate discrete-time Markov chain ########################
# Simulates n steps of a Markov chain 
# markov(init,mat,n,states)
# Generates X0, ..., Xn for a Markov chain with initiial
#  distribution init and transition matrix mat
# Labels can be a character vector of states; default is 1, .... k

markov <- function(init,mat,n,labels) { 
	if (missing(labels)) labels <- 1:length(init)
simlist <- numeric(n+1)
states <- 1:length(init)
simlist[1] <- sample(states,1,prob=init)
for (i in 2:(n+1)) 
	{ simlist[i] <- sample(states,1,prob=mat[simlist[i-1],]) }
labels[simlist]
}
####################################################
P <- matrix(c(0.1,0.2,0.4,0.3,0.4,0,0.4,0.2,0.3,0.3,0,0.4,0.2,0.1,0.4,0.3),
  nrow=4, byrow=TRUE)
lab <- c("Aerobics","Massage","Weights","Yoga")
rownames(P) <- lab
colnames(P) <- lab
P
init <- c(1/4,1/4,1/4,1/4) # initial distribution
states <- c("a","m","w","y")
# simulate chain for 100 steps
simlist <- markov(init,P,100,states)
simlist
table(simlist)/100
steps <- 1000000
simlist <- markov(init,P,steps,states)
table(simlist)/steps
```

### 3.2 Stationary Distribution

#### 3.2.1 å®šä¹‰
æ³¨æ„Stationary Distributionçš„å®šä¹‰æ²¡æœ‰å‡ºç°æé™ã€‚

> If the initial distributino is a stationary distribution, Then $X_0,X_1,\cdots,X_n$ is a sequence of identically distributed random variables. But it doesn't mean that the random variables are independent.

> Lemma 3.1: Limiting Distributions are stationary Distribution

The reverse is false, åä¾‹ï¼š

$$
  P = \begin{pmatrix}
    0 & 1 \\
    1 & 0
  \end{pmatrix}
  ï¼Œ\pi=(\frac{1}{2},\frac{1}{2}) 
$$

ä»¥åŠ

$$
   P = \begin{pmatrix}
    1 & 0 \\
    0 & 1
  \end{pmatrix}
$$

#### 3.2.2 Regular Matrices

ä¸€ä¸ªè‡ªç„¶çš„æƒ³æ³•æ˜¯é—®ï¼Œä»€ä¹ˆæ ·çš„æ¡ä»¶ä¸‹ï¼Œä¸€ä¸ªé©¬å°”å¯å¤«é“¾æœ‰æé™åˆ†å¸ƒï¼Œè€Œä¸”æé™åˆ†å¸ƒå°±æ˜¯å¹³ç¨³åˆ†å¸ƒå‘¢ã€‚

æ»¡è¶³å¦‚ä¸‹æ€§è´¨çš„é©¬å°”å¯å¤«é“¾æ˜¯ç¬¦åˆè¿™ä¸ªè¦æ±‚çš„

> Regular Transition Matrix
> A transition matrix $\boldsymbol{P}$ is said to be regular if some power of $\boldsymbol{P}$ is positive. That is $\boldsymbol{P}^n > 0 $, for some $n\ge 1$

æœ‰å®šç†ï¼š

> Theorem 3.2: A markov chain whose transition matrix $\boldsymbol{P}$ is regular has a limiting distribution, which is teh unique, positive, stationary distribution of the chanin.

Ex 3.3-3.4 å…·ä½“ç®—ä¾‹ï¼Œ

#### 3.2.3 Finding the stationary distribution

æœ¬è´¨ä¸Šè¿™æ˜¯ä¸€ä¸ªç‰¹å¾å€¼é—®é¢˜ã€‚

```r
### Stationary distribution of discrete-time Markov chain
###  (uses eigenvectors)
###
stationary <- function(mat) {
x = eigen(t(mat))$vectors[,1]
as.double(x/sum(x))
}
```

Ex 3.5-3.6; è®¡ç®—æŠ€å·§ï¼Œä»¤$x_1=1$

Ex 3.7 The Ehrenfest dog-flea model

Ex 3.8 Random walk on a graph;

On weighted graph

> Stationiary Distribution for Random walk on a weighted graph
> 
> Let $G=(V,E)$ be  a weighted graph with edge weight function $w(i,j)$. For random walk on G, the stationary distribution $pi$ is proportion to the sum of teh edge weights incident to each vertex. That is.
> $$ \pi = \frac{w(v)}{\sum_{z}w(z)},\forall v\in V$$ 
> where
> $$ w(v) = \sum_{z \sim v }w(v,z) $$

On simple graph

> Stationary Distribution for simple Random Walk on a graph
> 
> For simple random walk on a weighted graph, set $w(i,j)=1,\forall i,j \in V $, then, $w(v)=deg(v)$,which gives
> $$ \pi_{v}=\frac{\deg(v)}{\sum_z \deg(z)}=\frac{\deg(v)}{2e} $$

Ex 3.9-3.10 å¦‚ä½•è®¡ç®—çš„æ¡ˆä¾‹ï¼›

#### 3.2.4 The Eigenvalue Connection

è½¬ç½®ï¼Œçœ‹å‡ºä¸ç‰¹å¾å€¼çš„å…³è”ã€‚

Ex 3.11 æ•°å€¼æ¡ˆä¾‹ã€‚

