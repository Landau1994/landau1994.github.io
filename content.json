{"meta":{"title":"Coding for Life Sciences","subtitle":"从数据，模型中获取生物知识","description":"关注从数据和模型中获取生物知识的博客","author":"Longteng Wang","url":"https://landau1994.github.io"},"pages":[{"title":"学习，研究，创新，分享","date":"2020-04-08T13:50:00.000Z","updated":"2025-01-11T17:16:31.892Z","comments":false,"path":"about/index.html","permalink":"https://landau1994.github.io/about/index.html","excerpt":"","text":"为何建站 科研从兴趣出发，用良好的习惯坚持和成长。本站旨在记录成长点滴。 为何写作 写作可以抵抗遗忘和衰朽，古人云： 盖文章，经国之大业，不朽之盛事。年寿有时而尽，荣乐止乎其身，二者必至之常期，未若文章之无穷。 ——曹丕《典论·论文》节选 而在科研中，写作可以整理文献综述、材料方法，已经取得的数据结果。更重要的是理清下一步研究思路和技术路线。 此外，勤练写作，可以提高研究者表达和推广自己观点和研究成果的能力。 涵盖主题 本站最关注的是基因组学和生物信息学的各项研究以及相关的生物学，信息学，数学和统计学（将来可能还会有物理学和化学）的基础知识的学习。更多见话题标签 关于作者 生物信息学博士研究生在读。知乎主页[https://www.zhihu.com/people/landau1994]。"},{"title":"QA","date":"2020-04-08T13:32:22.000Z","updated":"2025-01-11T17:16:32.274Z","comments":false,"path":"help/index.html","permalink":"https://landau1994.github.io/help/index.html","excerpt":"","text":"Q: 这网站怎么弄的，还挺好看的啊？ A: 本站是静态博客，通过hexo生成，主题为jsimple,做了个性化的定制（换了白天和晚上的图片，修改了配置支持数学公式）。 Q: 为什么博客有时候打开速度很慢，一直在加载，或者有时压根打不开呢？ A: 本站尚无独立域名，暂时使用Github Page。所以github卡或者崩的时候就gg了。不过这都是小概率事件。开源万岁，github万岁,拥抱开源的微软万岁。 Q: 我也想搭个博客，不知道怎么弄？ A: 参考问题1，学会看官网教程，以及自己动手修改和调试配置文档。 Q: 本站是否接受投稿或转载？ 站长本人之外的投稿和转载暂不支持。 Q: 其他的... 本站为站长自己的学习记录，因个人知识水平所限，如有错误，还望批评指正。"},{"title":"tags","date":"2020-04-05T14:04:00.000Z","updated":"2025-01-11T17:16:32.280Z","comments":false,"path":"tags/index.html","permalink":"https://landau1994.github.io/tags/index.html","excerpt":"","text":""},{"title":"timeline","date":"2020-04-08T14:33:55.000Z","updated":"2025-01-11T17:16:32.289Z","comments":false,"path":"timeline/index.html","permalink":"https://landau1994.github.io/timeline/index.html","excerpt":"","text":"暂时没有，可以看标签和归档。"},{"title":"links","date":"2020-04-08T14:20:45.000Z","updated":"2025-01-11T17:16:32.276Z","comments":false,"path":"links/index.html","permalink":"https://landau1994.github.io/links/index.html","excerpt":"","text":"以下摘录有趣、有意义、有影响力的链接 持续更新中。 此处不做网址导航，排序不分先后... 基本资源篇 github; google; PubMed; CNS的官网； stackoverflow 一些站点篇 实用生物信息技术 CBI forum 生信技能树 生信坑 微信公众号篇 biobabble"}],"posts":[{"title":"artin_review","slug":"artin-review","date":"2025-01-11T17:37:44.000Z","updated":"2025-01-11T17:41:18.906Z","comments":true,"path":"2025/01/12/artin-review/","link":"","permalink":"https://landau1994.github.io/2025/01/12/artin-review/","excerpt":"","text":"2024.03-2025.01 # 缘起 见：能说一本或几本在你在学数学路上对你影响最大的一本书吗？ - 万物皆数数海拾贝的回答 - 知乎 https://www.zhihu.com/question/555672024/answer/3418569722 如何从群，环，到，再到Galois理论。你可以将这篇书评视为关于Artin一书的一个学习纲领，特别是在这篇书评的末尾，我们还附上一些近年来出现在国内外的数学考试中的习题以及解答，这些习题没有超过Artin一书包含的内容。 Artin的编排对初学者不是特别友好，比如第二版一开始就是线性代数，或许会让一些已经被线性代数产生审美疲劳的读者劝退，但是等仔细耐着性子读完之后，你会发现，这些线性代数的知识，其实与后面的抽象代数的知识并不是割裂的。笔者在将Artin的书通读了三遍之后，呈现给一个笔者认为较为容易理解的目次。笔者觉得Artin这本书，仅管缺点诸多，与Artin风格类似的，如Dummit，我觉得也很好。但是Artin这本书最大的优点，是将线性代数和抽象代数融合为一体，具体就是通过表示论的知识穿插将两者结合起来，几乎没有一本面向本科的教材，能够做的这么好。","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}]},{"title":"learn_python_001","slug":"learn-python-001","date":"2021-12-04T13:19:59.000Z","updated":"2025-01-11T17:16:31.837Z","comments":true,"path":"2021/12/04/learn-python-001/","link":"","permalink":"https://landau1994.github.io/2021/12/04/learn-python-001/","excerpt":"","text":"Learn_python_001 Top K problem 🟧❓ The problem Top K question: 输入整数数组 arr ，找出其中最小的 k 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。 示例 1： 输入：arr = [3,2,1], k = 2 输出：[1,2] 或者 [2,1] 示例 2： 输入：arr = [0,1,2,1], k = 1 输出：[0] 限制： 0 &lt;= k &lt;= arr.length &lt;= 10000 0 &lt;= arr[i] &lt;= 10000 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明 📄 code 有三种解法，解法二，三，是符合题目要求的两种（因为题目也考察了排序算法）。详解见https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/solution/jian-zhi-offer-40-zui-xiao-de-k-ge-shu-j-9yze/ class Solution1: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: lstStd = arr lstStd.sort() res = lstStd[:k] return res ### solution2: ### wirte your own quick sort ### This was taken from https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/solution/jian-zhi-offer-40-zui-xiao-de-k-ge-shu-j-9yze/ class Solution2: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: def quick_sort(arr, l, r): if l &gt;= r: return i, j = l, r while i &lt; j: while i &lt; j and arr[j] &gt;= arr[l]: j -= 1 while i &lt; j and arr[i] &lt;= arr[l]: i += 1 arr[i], arr[j] = arr[j], arr[i] arr[l], arr[i] = arr[i], arr[l] quick_sort(arr, l, i - 1) quick_sort(arr, i + 1, r) quick_sort(arr, 0, len(arr) - 1) return arr[:k] class Solution3: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: if k &gt;= len(arr): return arr def quick_sort(l, r): i, j = l, r while i &lt; j: while i &lt; j and arr[j] &gt;= arr[l]: j -= 1 while i &lt; j and arr[i] &lt;= arr[l]: i += 1 arr[i], arr[j] = arr[j], arr[i] arr[l], arr[i] = arr[i], arr[l] if k &lt; i: return quick_sort(l, i - 1) if k &gt; i: return quick_sort(i + 1, r) return arr[:k] return quick_sort(0, len(arr) - 1) 📏 测试 我们用如下代码测试： ### import require package import numpy as np import random import matplotlib.pyplot as plt import time import seaborn as sns from typing import List, Dict, Tuple, Sequence def ProgramTime(N,func): lst = [random.randrange(10**7) for n in range(N)] start = time.perf_counter() func(lst,10) runtime = (time.perf_counter() - start) return runtime ProgramTimeVec = np.vectorize(ProgramTime) ### define theory function def f1(n, k): return k*n def f2(n, k): return k*n*np.log(n) ### plot test curve n = np.arange(1, 2000) colors = sns.color_palette(\"Set1\") plt.plot(n, f1(n, 1e-7), c=colors[0]) plt.plot(n, f2(n, 1e-7), c=colors[1]) plt.plot(n, ProgramTimeVec(n,sol1.getLeastNumbers),c=colors[2]) plt.plot(n, ProgramTimeVec(n,sol2.getLeastNumbers),c=colors[3]) plt.plot(n, ProgramTimeVec(n,sol3.getLeastNumbers),c=colors[4]) plt.xlabel('Size of input (n)', fontsize=16) plt.ylabel('Time', fontsize=16) #plt.legend(['$\\mathcal{O}(n^2)$', '$\\mathcal{O}(n \\log n)$'], loc='best', fontsize=20) plt.legend(['$\\mathcal{O}(n)$', '$\\mathcal{O}(n \\log n)$','sol1', 'sol2','sol3'], loc='best', fontsize=20) fig = plt.gcf() fig.set_size_inches(8, 6) plt.savefig(\"../fig/test.png\",dpi=300) 结果如下, 可以看出，使用解法三，也就是基于快速排序的数组划分，可以实现线性时间： figure","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"Python","slug":"Python","permalink":"https://landau1994.github.io/tags/Python/"}]},{"title":"Epigenome_track_plot","slug":"Epigenome-track-plot","date":"2021-10-27T11:06:50.000Z","updated":"2025-01-11T17:16:31.806Z","comments":true,"path":"2021/10/27/Epigenome-track-plot/","link":"","permalink":"https://landau1994.github.io/2021/10/27/Epigenome-track-plot/","excerpt":"","text":"Epigenome track visulalization by R Recently, I create a new repo to visulizaiton Epigenome track by ggplot2() ecosytem. Details can be found at https://github.com/Landau1994/PlotEpiTrackByR","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}]},{"title":"reading_note_20201206","slug":"reading-note-20201206","date":"2020-12-06T12:49:41.000Z","updated":"2025-01-11T17:16:31.856Z","comments":true,"path":"2020/12/06/reading-note-20201206/","link":"","permalink":"https://landau1994.github.io/2020/12/06/reading-note-20201206/","excerpt":"","text":"题目：[3D] bioRxiv 2020 3D Genome Contributes to Protein-Protein Interactome - 生物问题：3D 基因组的与蛋白质互作是否存在关系？ 实验设计： PPI数据：收集不同数据库蛋白质互作数据，作为正样本；从不同亚细胞定位的非PPI互作蛋白中抽样，作为负样本； HiC数据：不同细胞系的HiC数据，采用相同方法重新处理，使得互作矩阵分辨率相同； 从3D基因组信息中，重建基因的空间信息，采用不同的机器学习方法预测PPI数据 分析思路： 分组比较PPI gene counterparts 组和 Non-PPI组的分布图，HiCHeatmap，Gene-gene pair projections of PPIs overlaid on Hi-C heatmaps.，发现了PPI gene counterparts 在空间更为邻近；（Figure2,3,4）； 分析至少一个蛋白有信号肽的PPI（SigPep PPI）与无信号肽PPI(Non-SigPep PPI)的关系，得到结论是：“This can be explained that for the interacting proteins that are brought together by signal peptides, their gene counterparts can be more freely located on the 3D genome, with larger spatial distances“ 用3维基因组的信息在不同的模型中预测PPI，发现引入3维基因组的信息之后，” the prediction accuracy in terms of AUC can be significantly improved if 3D genome information is employed“（Table1)，由于是预印本，特征工程的那一部分作者并没有详细写； 评论： 目前有很多研究组致力于解析3D基因组结构和疾病的关系，报道了一些3D基因组结构改变，影响转录，从而影响疾病的案例；本文的分析虽然简单，但是给出了3D基因组结构对于更为下游的蛋白质互作有影响的可能性。但是这种可能性，还需要更为solid的技术，数据和分析方法来证明； alphafold是基于序列信息来预测蛋白质结构，目前已经取得重大突破。目前也陆续有基于机器学习的方法，整合不同基因组学的数据进行功能基因组学研究的报道。可能在未来的研究中，结合多组学数据，像alphafold这样的AI框架，才能实现更为深刻的蛋白动态功能的预测；","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}]},{"title":"mmet 2020 Age-related loss of gene-to-gene transcriptional coordination among single-cells","slug":"readnote","date":"2020-12-06T03:07:29.000Z","updated":"2025-01-11T17:16:31.858Z","comments":true,"path":"2020/12/06/readnote/","link":"","permalink":"https://landau1994.github.io/2020/12/06/readnote/","excerpt":"","text":"在HSC中没有观察到cell-cell variation随着衰老的改变；For example, despite observations of genetic and epigenteic damage in ageing haematopoietic stem cells(HSCs); cell to cell transcriptional variability is not observed. 基因共表达方法的缺陷： First, co-expression networks estimates the direct or indirect correlations between pairs of genes, while an individual gene may be controlled by multiple regulators. Second, each co-expression measure is designed to capture a specific feature that is not necessarily optimal for depicting all types of gene-to-gene transcriptional interrelations ( PCC, linear relatiosnhips) Third, large calculated coexpresion matrices contain a considerable amount of noise, which raises an additional difficulty in explporing their differentiation across cohorts Gcl 本质上是对bcdcorr的bootstrap. 一个重要的观察和建设： As an illustration of the coordination measured by the GCL, consider the expression profiles of cells with N genes, that are represented as points in an N-dimensional space. If the gene expression levels are not independent, the set of points do not fill the N- dimensional space but are rather located near lower-dimensional manifold. The GCL measures has two main advantages. The dependency level is defined with respect to a general dependency form, not specific relations ( such as linear) It can include high-order dependencies between multiple variables","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}]},{"title":"Learn-igraph-More about igraph","slug":"Learnigraph-2-MoreOnIgraph","date":"2020-07-29T15:23:30.000Z","updated":"2025-01-11T17:16:31.826Z","comments":true,"path":"2020/07/29/Learnigraph-2-MoreOnIgraph/","link":"","permalink":"https://landau1994.github.io/2020/07/29/Learnigraph-2-MoreOnIgraph/","excerpt":"","text":"0. 说明 我们接着讲更多关于对igraph对象的操作，参考Statistical Network Analysis with igraph第一章。 1. 创建igraph 对象 使用管道 library(igraph) library(igraphdata) library(magrittr) library(tidyverse) library(ggraph) library(ggnetwork) # Notable graphs # make_graph can create some notable graphs. The name of the graph (case insensitive), a character scalar must be suppliced as the edges argument, and other arguments are ignored. (A warning is given is they are specified.) # eg. # Cubical # The Platonic graph of the cube. A convex regular polyhedron with 8 vertices and 12 edges. g &lt;- make_graph(\"Cubical\") %&gt;% set_vertex_attr(\"name\",value = LETTERS[1:4]) g %&gt;% add_layout_(with_fr()) %&gt;% plot() 补充：更为实际的案例中，需要使用数据集来创建图。igraph作者提供了一些根据数据集创建好的igraph对象： library(igraphdata) ### data:Loads specified data sets, or list the available data sets. data(package=\"igraphdata\") # Data sets in package ‘igraphdata’: # # Koenigsberg Bridges of Koenigsberg from Euler's times # UKfaculty Friendship network of a UK university faculty # USairports US airport network, 2010 December # enron Enron Email Network # foodwebs A collection of food webs # immuno Immunoglobulin interaction network # karate Zachary's karate club network # kite Krackhardt's kite # macaque Visuotactile brain areas and connections # rfid Hospital encounter network data # yeast Yeast protein interaction network 2. 使用iraph对象查看边和点的信息 ### already data(\"macaque\") macaque ## IGRAPH f7130f3 DN-- 45 463 -- ## + attr: Citation (g/c), Author (g/c), shape (v/c), name (v/c) ## + edges from f7130f3 (vertex names): ## [1] V1 -&gt;V2 V1 -&gt;V3 V1 -&gt;V3A V1 -&gt;V4 V1 -&gt;V4t V1 -&gt;MT ## [7] V1 -&gt;PO V1 -&gt;PIP V2 -&gt;V1 V2 -&gt;V3 V2 -&gt;V3A V2 -&gt;V4 ## [13] V2 -&gt;V4t V2 -&gt;VOT V2 -&gt;VP V2 -&gt;MT V2 -&gt;MSTd/p V2 -&gt;MSTl ## [19] V2 -&gt;PO V2 -&gt;PIP V2 -&gt;VIP V2 -&gt;FST V2 -&gt;FEF V3 -&gt;V1 ## [25] V3 -&gt;V2 V3 -&gt;V3A V3 -&gt;V4 V3 -&gt;V4t V3 -&gt;MT V3 -&gt;MSTd/p ## [31] V3 -&gt;PO V3 -&gt;LIP V3 -&gt;PIP V3 -&gt;VIP V3 -&gt;FST V3 -&gt;TF ## [37] V3 -&gt;FEF V3A-&gt;V1 V3A-&gt;V2 V3A-&gt;V3 V3A-&gt;V4 V3A-&gt;VP ## [43] V3A-&gt;MT V3A-&gt;MSTd/p V3A-&gt;MSTl V3A-&gt;PO V3A-&gt;LIP V3A-&gt;DP ## + ... omitted several edges 原作者是这么解释的： This is the standard way of showing (printing) an igraph graph object on the screen. The top line of the output declares that the object is an igraph graph, and also lists its most important properties. A four-character long code is printed first: ‘D/U’ The first character is either ‘D’ or ‘U’ and encodes whether the graph is directed or undireted. ‘N’ The second letter is ‘N’ for named graphs (see Section 1.2.5). A dash here means that the graph is not named. ‘W’ The third letter is ‘W’ if the graph is weighted (in other words, if the graph is a valued graph, Section 2.4). Unweighted graphs have a dash in this position. ‘B’ Finally, the fourth is ‘B’ if the graph is bipartite (two-mode, Section ??). For unipartite (one-mode) graphs a dash is printed here. This notation might seem quite dense at first, but it is easy to get used to and conveys much information in a small space. Then two numbers are printed, these are the number of vertices and the number of edges in the graph, 45 and 463 in our case. At the end of the line the name of the graph is printed, if there is any. The next line(s) list attributes, meta-data that belong to the vertices, edges or the graph itself. Finally, the edges of the graph are listed. Except for very small graphs, this list is truncated, so that it fits to the screen. 一些基本量的展示，之前讲过，此外，还有更多关于边的操作： ###|V| gorder(macaque) ###[1] 45 ###|E| gsize(macaque) ###[1] 463 V(macaque) # + 45/45 vertices, named, from f7130f3: # [1] V1 V2 V3 V3A V4 V4t VOT VP MT MSTd/p MSTl # [12] PO LIP PIP VIP DP 7a FST PITd PITv CITd CITv # [23] AITd AITv STPp STPa TF TH FEF 46 3a 3b 1 # [34] 2 5 Ri SII 7b 4 6 SMA Ig Id 35 # [45] 36 E(macaque) # + 463/463 edges from f7130f3 (vertex names): # [1] V1 -&gt;V2 V1 -&gt;V3 V1 -&gt;V3A V1 -&gt;V4 V1 -&gt;V4t V1 -&gt;MT # [7] V1 -&gt;PO V1 -&gt;PIP V2 -&gt;V1 V2 -&gt;V3 V2 -&gt;V3A V2 -&gt;V4 # [13] V2 -&gt;V4t V2 -&gt;VOT V2 -&gt;VP V2 -&gt;MT V2 -&gt;MSTd/p V2 -&gt;MSTl # [19] V2 -&gt;PO V2 -&gt;PIP V2 -&gt;VIP V2 -&gt;FST V2 -&gt;FEF V3 -&gt;V1 # [25] V3 -&gt;V2 V3 -&gt;V3A V3 -&gt;V4 V3 -&gt;V4t V3 -&gt;MT V3 -&gt;MSTd/p # [31] V3 -&gt;PO V3 -&gt;LIP V3 -&gt;PIP V3 -&gt;VIP V3 -&gt;FST V3 -&gt;TF # [37] V3 -&gt;FEF V3A-&gt;V1 V3A-&gt;V2 V3A-&gt;V3 V3A-&gt;V4 V3A-&gt;VP # [43] V3A-&gt;MT V3A-&gt;MSTd/p V3A-&gt;MSTl V3A-&gt;PO V3A-&gt;LIP V3A-&gt;DP # [49] V3A-&gt;FST V3A-&gt;FEF V4 -&gt;V1 V4 -&gt;V2 V4 -&gt;V3 V4 -&gt;V3A # [55] V4 -&gt;V4t V4 -&gt;VOT V4 -&gt;VP V4 -&gt;MT V4 -&gt;LIP V4 -&gt;PIP # + ... omitted several edges macaque %&gt;% ends(\"V1|V2\") # # [,1] [,2] # [1,] \"V1\" \"V2\" macaque %&gt;% tail_of(\"V1|V2\") # + 1/45 vertex, named, from f7130f3: # [1] V1 macaque %&gt;% head_of(\"V1|V2\") # + 1/45 vertex, named, from f7130f3: # [1] V2 macaque %&gt;% neighbors(\"V1\",mode = \"out\") # + 8/45 vertices, named, from f7130f3: # [1] V2 V3 V3A V4 V4t MT PO PIP macaque %&gt;% neighbors(\"V1\",mode = \"in\") # + 8/45 vertices, named, from f7130f3: # [1] V2 V3 V3A V4 V4t MT PO PIP E(macaque)[.from(\"V1\")] 3. 子图 创建子图 V(macaque)[\"V1\",\"V2\",.nei(\"V1\"),.nei(\"V2\")] %&gt;% induced_subgraph(graph = macaque) %&gt;% summary() ## IGRAPH cb88d15 DN-- 16 156 -- ## + attr: Citation (g/c), Author (g/c), shape (v/c), name (v/c) 连通 is_connected(macaque,mode = \"weak\") ## [1] TRUE is_connected(macaque,mode = \"strong\") ## [1] TRUE 边和点的筛选： V(macaque)[1:4] # + 4/45 vertices, named, from f7130f3: # [1] V1 V2 V3 V3A V(macaque)[c(\"V1\",\"V2\",\"V3\",\"V3A\")] # + 4/45 vertices, named, from f7130f3: # [1] V1 V2 V3 V3 建立边或者点的索引向量： E(macaque)[1:10] %&gt;% as_ids() # [1] \"V1|V2\" \"V1|V3\" \"V1|V3A\" \"V1|V4\" \"V1|V4t\" \"V1|MT\" \"V1|PO\" \"V1|PIP\" # [9] \"V2|V1\" \"V2|V3\" V(macaque)[1:10] %&gt;% as_ids() # [1] \"V1\" \"V2\" \"V3\" \"V3A\" \"V4\" \"V4t\" \"VOT\" \"VP\" # [9] \"MT\" \"MSTd/p\" 类似于算数操作，关于点的操作汇总： data(\"kite\") V(kite) # + 10/10 vertices, named, from 6b7ddad: # [1] A B C D E F G H I J V(kite)[1:3,7:10] # + 7/10 vertices, named, from 6b7ddad: # [1] A B C G H I J V(kite)[degree(kite) &lt; 2] # + 1/10 vertex, named, from 6b7ddad: # [1] J V(kite)[.nei(\"D\")] # + 6/10 vertices, named, from 6b7ddad: # [1] A B C E F G V(kite)[.innei(\"D\")] # + 6/10 vertices, named, from 6b7ddad: # [1] A B C E F G V(kite)[.outnei(\"D\")] # + 6/10 vertices, named, from 6b7ddad: # [1] A B C E F G V(kite)[.inc(\"A|D\")] # + 2/10 vertices, named, from 6b7ddad: # [1] A D c(V(kite)[\"A\"],V(kite)[\"D\"]) # + 2/10 vertices, named, from 6b7ddad: # [1] A D rev(V(kite)) # + 10/10 vertices, named, from 6b7ddad: # [1] J I H G F E D C B A unique(V(kite)[\"A\",\"A\",\"C\",\"C\"]) # + 2/10 vertices, named, from 6b7ddad: # [1] A C ### Set operation union(V(kite)[1:5],v(kite)[6:10]) # + 2/10 vertices, named, from 6b7ddad: # [1] A C intersection(V(kite)[1:7],V(kite)[5:10]) # + 3/10 vertices, named, from 6b7ddad: # [1] E F G difference(V(kite),V(kite)[1:5]) # + 5/10 vertices, named, from 6b7ddad: # [1] F G H I J E(kite) # + 18/18 edges from 6b7ddad (vertex names): # [1] A--B A--C A--D A--F B--D B--E B--G C--D C--F D--E D--F D--G E--G F--G F--H G--H # [17] H--I I--J E(kite,path = c(\"A\",\"D\",\"C\")) # + 2/18 edges from 6b7ddad (vertex names): # [1] A--D C--D E(kite)[ V(kite)[1:2] %--% V(kite)[3:4] ] # + 3/18 edges from 6b7ddad (vertex names): # [1] A--C A--D B--D E(kite)[1:3,7:10] # + 7/18 edges from 6b7ddad (vertex names): # [1] A--B A--C A--D B--G C--D C--F D--E E(kite)[seq_len(gsize(kite))[seq_len(gsize(kite)) %%2 == 0]] # + 9/18 edges from 6b7ddad (vertex names): # [1] A--C A--F B--E C--D D--E D--G F--G G--H I--J E(kite)[seq_len(gsize(kite)) %%2 == 0] # + 9/18 edges from 6b7ddad (vertex names): # [1] A--C A--F B--E C--D D--E D--G F--G G--H I--J E(kite)[seq_len(gsize(kite)) %%2] # + 9/18 edges from 6b7ddad (vertex names): # [1] A--B A--B A--B A--B A--B A--B A--B A--B A--B E(kite)[.inc(\"D\")] # + 6/18 edges from 6b7ddad (vertex names): # [1] A--D B--D C--D D--E D--F D--G E(macaque)[.from(\"V1\")] # + 8/463 edges from f7130f3 (vertex names): # [1] V1-&gt;V2 V1-&gt;V3 V1-&gt;V3A V1-&gt;V4 V1-&gt;V4t V1-&gt;MT V1-&gt;PO V1-&gt;PIP E(macaque)[.to(\"V1\")] # + 8/463 edges from f7130f3 (vertex names): # [1] V2 -&gt;V1 V3 -&gt;V1 V3A-&gt;V1 V4 -&gt;V1 V4t-&gt;V1 MT -&gt;V1 PO -&gt;V1 PIP-&gt;V1 ### The remains are same as Vertices operations","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"Graph","slug":"Graph","permalink":"https://landau1994.github.io/tags/Graph/"},{"name":"Network","slug":"Network","permalink":"https://landau1994.github.io/tags/Network/"}]},{"title":"LearnSeurat_Intergrate","slug":"LearnSeurat-Intergrate","date":"2020-05-27T03:44:09.000Z","updated":"2025-01-11T17:16:31.816Z","comments":true,"path":"2020/05/27/LearnSeurat-Intergrate/","link":"","permalink":"https://landau1994.github.io/2020/05/27/LearnSeurat-Intergrate/","excerpt":"","text":"0. 说明 更为详细的使用，可以参考Seurat官方教程，或者Seurat进行单细胞RNA-seq数据整合。 1. 快速进行 实际分析中，如果细胞数目很多的话，进行整合分析的时候就会很慢，一种方式是将任务提交通过命令行提交到服务器或者集群上运行，并输出。 传递命令行的参数的脚本可以这么写： #### reference base Integration .libPaths(\"/home/user/lib/R/library\") library(Seurat) args = commandArgs(trailingOnly=TRUE) # test if there is at least one argument: if not, return an error if (length(args)==0) { stop(\"At least one argument must be supplied (input file).n\", call.=FALSE) } ###args[1] seu.list.rds ###args[2] seu.intergrated.rds ###args[3] UMAPplot.pdf ## program... seu.list &lt;- readRDS(file = args[1]) for (i in names(seu.list)) { seu.list[[i]] &lt;- SCTransform(seu.list[[i]], verbose = FALSE) } seu.list.features &lt;- SelectIntegrationFeatures(object.list = seu.list, nfeatures = 3000) seu.list &lt;- PrepSCTIntegration(object.list = seu.list, anchor.features = seu.list.features) reference_dataset &lt;- 1 names(seu.list)[1] seu.list.anchors &lt;- FindIntegrationAnchors(object.list = seu.list, normalization.method = \"SCT\", anchor.features = seu.list.features, reference = reference_dataset) seu.list.integrated &lt;- IntegrateData(anchorset = seu.list.anchors, normalization.method = \"SCT\") seu.list.integrated &lt;- RunPCA(object = seu.list.integrated, verbose = FALSE) seu.list.integrated &lt;- RunUMAP(object = seu.list.integrated, umap.method = \"umap-learn\", dims = 1:30) saveRDS(seu.list.integrated,file = args[2]) #### show Integrated result plots &lt;- DimPlot(seu.list.integrated, group.by = c(\"orig.ident\", \"cell.type\")) plots &amp; theme(legend.position = \"top\") &amp; guides(color = guide_legend(nrow = 4, byrow = TRUE, override.aes = list(size = 2.5))) ggsave(filename = args[3],width = 12,height = 6) 将其命名为Integrated_ref_based.R 然后在终端输入nohup Rscript Integrated_ref_based.R seu.list.rds seu.intergrated.rds UMAPplot.pdf &gt; log.txt &amp;提交即可； 2. 评论 当然，这个脚本读者还可以根据自己需求加以完善。","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"}]},{"title":"如何定义细胞类型","slug":"如何定义细胞类型","date":"2020-05-16T06:20:28.000Z","updated":"2025-01-11T17:16:31.874Z","comments":true,"path":"2020/05/16/如何定义细胞类型/","link":"","permalink":"https://landau1994.github.io/2020/05/16/%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E7%BB%86%E8%83%9E%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"生物学家的传统艺能是进行分类，即使在进入了21世纪，研究的尺度和研究的手段和林奈已经有了很大的不同，但是分类这个古老的问题依然是众多生物研究领域的基础。作为分类这个大问题中的子问题，细胞类型的鉴定是当前细胞生物学研究的一个基础问题和前沿问题。 比如发育生物学和干细胞生物学的研究，确定细胞的谱系是研究细胞命运决定因素等基础研究以及相关临床转化的基础。这个基础有多重要的呢，假如某个大牛声称自己发现了某种神奇的细胞，这个细胞可以带来医学革命，然而这种类型的细胞很可能就不存在，所为的带来革命的宣传都是忽悠和骗局,基于这种类型的细胞的研究都是建在沙子上的高楼大厦。以上不是我们的想象，而是确实发生的现实案例哈佛大学由于心肌干细胞不存在而大量撤稿，国内所有阳性指标论文是否都涉嫌造假？ 最近，Cell Stem Cell杂志上发表了一篇综述，阐述了细胞身份(Cellular Identity)研究的目的，以及基于高通量测序（特别是单细胞测序），成像以及遗传学等新方法来确定细胞身份的方法。 在作者看来，细胞类型鉴定研究的目的分为三条：（图片和引用的话均来自于文献） Detecting features assoicated with a cell type from a pre-defined list of candidates; Identifying new features and cell types through unbiased approaches; Defining Cellular Relationships 从原理上，鉴定细胞身份的不同feature可以概括如下： Figure 1. Defining Cell Types 某个细胞类型的feature可以如何研究呢，见下： Figure 2. Strategies to Detect Molecular Features Associated with a Cell Type 不同类型之间的细胞之间的关系的研究见下： Figure 3. Strategies to Define Cellular Relationships 当然同一类型的细胞在不同组织或者生理条件下会呈现不同的功能。 Figure 4. Cellular Functions Vary with Context 讨论部分最喜欢的一段话是： &gt; Together, our rapidly expanding capability to detect features and functions are revealing that \"cell type\" that were percevied as monolithic and stable in fact represent composites of multiple cells with distinguishable molecular signatures and have teh capability to adopt new features and functions in new contexts 更多内容请阅读原文。","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"},{"name":"cell biology","slug":"cell-biology","permalink":"https://landau1994.github.io/tags/cell-biology/"},{"name":"sc-seq","slug":"sc-seq","permalink":"https://landau1994.github.io/tags/sc-seq/"}]},{"title":"Learn-SciBet","slug":"Learn-scibet","date":"2020-05-15T14:16:52.000Z","updated":"2025-01-11T17:16:31.815Z","comments":true,"path":"2020/05/15/Learn-scibet/","link":"","permalink":"https://landau1994.github.io/2020/05/15/Learn-scibet/","excerpt":"","text":"1. 背景介绍 细胞类型注释是scRNA-seq里非常基础的一步，常见的策略是将基于无监督分群结果的基因差异表达分析结果作为marker,结合先验知识，判断该分群为何种类型。 近年来，随着scRNA-seq的数据集的逐渐积累，也有很多研究组提出了一些基于已有分群结果进行有监督的细胞类型注释的方法，比如scmap，或者Seurat里的TransferData。此外，也有评估相关方法的benchmark研究： SciBet是张泽民老师组最近新发表的一个快捷（实测真的比Seurat的TransferData快，而且效果确实差不多），方便的进行有监督的细胞类型注释的方法。论文见SciBet as a portable and fast single cell type identifier，相关报道见Nature Communications | 张泽民课题组发表单细胞转录组数据快速注释新方法 2. 方法原理简介 如果读者只对软件使用感兴趣的本节可以略过。 根据上面提到的那篇报道，如果用一句话概括SciBet的原理，应该是这样的： 张泽民实验室的博士生李辰威、刘宝琳联合任仙文副研究员开发的SciBet则有效地解决了这一问题：他们从“同一类型的单细胞表达谱服从同一多项分布”这一基本假设出发，对训练集数据中不同细胞类型分别进行建模，进而通过极大似然估计来对测试集细胞进行有监督注释。 接下来我们根据作者论文的方法部分和补充材料，学习一下这个巧妙地思路。分为如下几个部分： 预备知识 单细胞表达谱的统计模型 根据表达谱计算信息熵 E-test 构建有监督的细胞类型分类模型 我们假定读者已经修过概率论等相关课程。 2.1 预备知识 预备知识1： 我们需要向读者回顾关于负二项分布的知识，如果一个离散随机变量的pmf(probability mass function)为: 那么我们称其服从负二项分布。记为。 预备知识2： 对于两个随机变量和，在给定下，Y的条件pmf为： 预备知识3： 关于负二项分布，有如下结论： 对于随机变量，若, 则 其中 证明： 因为： 所以 根据预备知识3，我们有： 预备知识4： 负二项分布是泊松分布和伽马分布的混合分布。 预备知识5(该结论为概率论和数理统计的常识)： 对于随机变量的pdf为，做变换,其中为单调函数，X和Y各自样本空间的和分别满足： 若在中连续且逆变换在中连续可微，则新的随机变量的pdf为： 该结论为Statistical Inference(Casella Berger著)中的定理2.1.5，证明见该书。 预备知识6（只有这个结论作者在补充材料里给了证明）： The scaling property of the Gamma distribution 若 , 则 证明: 由题设： 根据题设，由预备知识5,有： 故 预备知识6： 若独立同分布样本服从, 且观测值分别为，则参数的矩估计量和极大似然估计量相等，均为 证明很简单，在很多教材也能找到，故从略。 预备知识7： 若独立同分布样本服从, 且观测值分别为，则参数的极大似然估计满足： 证明： 由题设： 故取对数后极大似然函数为： 由 解得 预备知识8： 若随机变量的pdf为,样本空间为, 定义information generating function: 则： 证明：(严格证明的话，得要考虑函数和本身的性质，我们这里假定它们可以满足积分号下求导，如果要严格的话，请参考测度论相关教材) 而随机变量的信息熵的定义为： 故 预备知识9： 若，则其信息熵为 由预备知识8经过计算即可证明，从略。 预备知识10： 多项分布 注：更多关于伽马分布的知识可见：理解Gamma分布、Beta分布与Dirichlet分布 2.2 单细胞表达谱的统计模型 经过大量的统计分析和后续的实验验证（相关证据可参考这篇文献）有这样一个经验性的结论： 观察到单细胞基因表达的count(比如UMI count)的分布可以用负二项分布很好的拟合,且相同细胞类型的单细胞表达谱服从同一个分布。 结合2.1中的预备知识，我们可以将单细胞基因表达的count表示为泊松分布的伽马分布的混合分布。所以作者参考了SAVER可以进行如下建模： 假设我们现在有个细胞，个基因的原始表达谱数据，里面的数值为reads count或者是UMI count。如果我们记观察得到细胞c的某个基因i的UMI count为，那么对于同一类型的细胞而言，有： 其中表示基因在细胞中的真实表达量，表示这个细胞中的UMI总数，与测序深度有关。而则是两个参数表征某个细胞类型中的基因的真实表达分布的参数。 接下来的可以根据预备知识里的结论进行参数估计： 由预备知识6，我们很容易得到这也为我们常用的进行normalized的策略提供了一种依据。而由预备知识7，有。 2.3 根据表达数据计算信息熵 不是所有的基因都是对后续的统计学习有用的，需要进行特征选择，也就是说，挑选出那些能表示不同群细胞之间表达差异的基因。本文的新意是基于信息熵(也就是香农熵)的概念引入了新的进行特征选择的方法：E-test。在讲E-test之前，我们需要看看作者是如何实现从表达量中计算信息熵的。 根据2.2我们知道可以将观测得到单细胞表达gene count表示成与真实表达量的混合分布，真正能反映不同细胞之间表达差异的是的分布。所以接下来要计算的分布的信息熵。 对于相同类型的细胞而言，根据2.1中的结论9，真实表达量的信息熵为： 用代入（1）可得： 记： 并且记个细胞的平均normalized表达量为, 显然有 根据上述记号，（1）最终化简为： 接下来，我们考虑道不同的细胞类型。若细胞属于细胞类型，定义所有属于的细胞的平均标准化的表达量为，根据上面的结论，可得： 其中 是直接可以通过实验数据计算的，而则需要估计。作者假设是只是基因特异的参数，也就是。理由如下： 若为随机变量的观测值，如果我们记基因从细胞类型到细胞类型的表达量的fold change为, 并且假设，那么由2.1中的预备知识6，可知 。 故, 结合（6）， 最终，我们可以得到 2.4 E-test 首先，零假设为所有不同类型细胞都是从同一个细胞类型（记为 group 0）中均匀随机采样，那么基因的平均表达量为, 则group 0 的信息熵可以计算为： 接着计算基因在所有细胞类型中与group 0 的信息熵的差之和： (8)-(7)并求和，得： 其中 利用Jesen不等式可以证明，故 若要进行假设检验，还需要计算的显著性，作者的策略是基于置换检验的： 若所有预先定义分群的细胞类型的细胞均来自同一个样本，则对任意的标签为细胞类型的细胞的size-factor normalized的表达量，根据中心极限定理，单细胞数目足够多的时候，，很容易得到参数的无偏估计，所以置换被简化成了每次从分布n个不同的随机数。接下来就是这么生成一个的分布，然后计算这个分布中大于从真实数据中测得的比例，作为显著性。 默认的Feature为500个基因。 2.5 构建有监督学习的模型 根据2.4，在训练集中，我们可以进行特征选择选出一些“informative gene”进行模型训练。 作者假设从相同的转录出的mRNA是不可区分的，而且每个mRNA的产生是相互独立的，记录对于细胞类型为的细胞，基因产生一个mRNA的概率为,若有个informative gene 则对细胞类型,我们得到了一个随机向量其中且其服从多项式分布,则 对于属于细胞类型的细胞，其后验表达谱可以计算为： 其中概率可估计为 同样的，在测试集中，未知细胞类型的细胞属于细胞类型的概率也为 其中是训练集中学习到的参数。 如果，我们引入,由极大似然的原则可知，细胞最有可能的细胞类型为 2.6 方法总结 可以用原文献中的流图对SciBet进行总结： 3. 软件使用 3.1 在线版 在线版使用请按照官网的Online classification教程。 值得一提的是，作者提供了很从不同组织，不同实验条件的单细胞测序数据中训练好的Signature： 这些不同的signature可以供不同研究者结合自己的兴趣使用。 3.2 本地版 3.2.1 安装 if (!requireNamespace(\"devtools\", quietly = TRUE)) install.packages(\"devtools\") devtools::install_github(\"PaulingLiu/scibet\") 如果出现错误，请看相关issue 3.2.2 作者提供的测试数据 按照官网的教程E-test and SciBet；下载所需的数据；然后后按照其说明文档进行即可。 接下来，我们看如何用使用SciBet结合Seurat进行单细胞分析。 3.2.3 SciBet结合Seurat 为了说明问题，我们选择Seurat自带的pbmcsca数据集, 该数据集已经提供了预先定义好的细胞标签，代码如下： library(Seurat) library(pbmcsca.SeuratData) library(ggplot2) library(scibet) library(tidyverse) library(viridis) ####0.---define utilized function-------- ####---Export expr data from 10x to tibble---- #' @param seuv3 a seuv3 object #' myGetExpr &lt;- function(seuv3,...){ expr &lt;- GetAssayData(object = seuv3, slot = \"data\") expr &lt;- as_tibble(t(as.matrix(expr)),rownames = NA) return(expr) } ###1.load data and preprocessing data(\"pbmcsca\") ###---avoid warning----- pbmcsca &lt;- UpdateSeuratObject(pbmcsca) ###---show predifined cell type------ table(pbmcsca$CellType) # B cell CD14+ monocyte # 5020 5550 # CD16+ monocyte CD4+ T cell # 804 7391 # Cytotoxic T cell Dendritic cell # 9071 433 # Megakaryocyte Natural killer cell # 977 1565 # Plasmacytoid dendritic cell Unassigned # 164 46 ###---split data----- pbmc.list &lt;- SplitObject(pbmcsca, split.by = \"Method\") ###---normalize------- for (i in names(pbmc.list)) { pbmc.list[[i]] &lt;- NormalizeData(pbmc.list[[i]], verbose = FALSE) } names(pbmc.list) [1] \"Smart-seq2\" \"CEL-Seq2\" \"10x Chromium (v2) A\" [4] \"10x Chromium (v2) B\" \"10x Chromium (v3)\" \"Drop-seq\" [7] \"Seq-Well\" \"inDrops\" \"10x Chromium (v2)\" 测试 reference base模式的效果 ###----2. test scibet---- ###----define reference and query----- reference &lt;- pbmc.list[[1]] query &lt;- pbmc.list[[2]] ###----test query reference mode---- reference.expr &lt;- myGetExpr(reference) query.expr &lt;- myGetExpr(query) reference.label &lt;- as.character(reference$CellType) test.label &lt;- as.character(query$CellType) reference.expr &lt;- cbind(reference.expr,label=reference.label) prd.label &lt;- SciBet(train = reference.expr, test = query.expr) Confusion_heatmap(test.label, prd.label) ggsave(filename = \"res/fig/learn_scibet_confusionheatmap_refmode.pdf\", width = 6,height = 6) 准确率为 num1 &lt;- length(test.label) num2 &lt;- tibble( ori = test.label, prd = prd.label ) %&gt;% dplyr::filter(ori == prd) %&gt;% nrow(.) num2/num1 0.851711 测试用作者提供的训练好的模型 ###----test load_model mode----- ###using 30 major cell types signature---- model &lt;- readr::read_csv(file = \"http://scibet.cancer-pku.cn/major_human_cell_types.csv\") model &lt;- pro.core(model) prd &lt;- LoadModel(model) prd.label &lt;- prd(query.expr) Confusion_heatmap(test.label,prd.label) ggsave(filename = \"res/fig/learn_scibet_confusionheatmap_signaturemode.pdf\", width = 6,height = 6)","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"}]},{"title":"LearnSeurat_PBMC3k","slug":"LearnSeurat-PBMC3k","date":"2020-05-10T11:55:56.000Z","updated":"2025-01-11T17:16:31.818Z","comments":true,"path":"2020/05/10/LearnSeurat-PBMC3k/","link":"","permalink":"https://landau1994.github.io/2020/05/10/LearnSeurat-PBMC3k/","excerpt":"","text":"本系列假定读者对于单细胞测序的数据分析和Seurat的官方教程有所了解。 本篇研究最基础的PBMC3k。其实这里只有2700个外周血的细胞。注意到，由于取样是外周血，没有干细胞的存在，所以可以认为样品处于稳态。这个教程就是讲稳态下的单细胞测序分析是如何进行的。Seurat的官方教程的缺点之一就是没有涉及动态过程的单细胞分析如何进行。 如无特殊说明，本系列的代码均可以在自己的笔记本电脑上运行； 1. 构建Seurat object 使用作者已经构建好的数据进行构建。关于Seurat更详细的文档可见satijalab的wiki library(Seurat) library(SeuratData) library(ggplot2) library(igraph) library(tidyverse) library(patchwork) ### AvailableData() check avaliable data: we choose cbmc ### InstallData('pbmc3k') library(pbmc3k.SeuratData) ### how this dataset generate? # ## Not run: # if (requireNamespace(Seurat, quietly = TRUE)) { # url &lt;- 'http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz' # curl::curl_download(url = url, destfile = basename(path = url)) # untar(tarfile = basename(path = url)) # pbmc.data &lt;- Seurat::Read10X(data.dir = 'filtered_gene_bc_matrices/hg19/') # pbmc3k &lt;- Seurat::CreateSeuratObject(counts = pbmc.data, project = 'pbmc3k', min.cells = 3, min.features = 200) # # Annotations come from Seurat's PBMC3k Guided Clustering Tutorial # # https://satijalab.org/seurat/v3.0/pbmc3k_tutorial.html # annotations &lt;- readRDS(file = system.file('extdata/annotations/annotations.Rds', package = 'pbmc3k.SeuratData')) # pbmc3k &lt;- Seurat::AddMetaData(object = pbmc3k, metadata = annotations) # # Clean up downloaded files # file.remove(basename(path = url)) # unlink(x = 'filtered_gene_bc_matrices/', recursive = TRUE) # } # # ## End(Not run) ### how Create Seurat object work? ### by run `Seurat::CreateSeuratObject` you can get the source function # ## Not run: # Seurat::CreateSeuratObject # function (counts, project = \"SeuratProject\", assay = \"RNA\", # min.cells = 0, min.features = 0, names.field = 1, names.delim = \"_\", # meta.data = NULL) # { # if (!is.null(x = meta.data)) { # if (is.null(x = rownames(x = meta.data))) { # stop(\"Row names not set in metadata. Please ensure that rownames of metadata match column names of data matrix\") # } # if (length(x = setdiff(x = rownames(x = meta.data), y = colnames(x = counts)))) { # warning(\"Some cells in meta.data not present in provided counts matrix.\") # meta.data &lt;- meta.data[intersect(x = rownames(x = meta.data), # y = colnames(x = counts)), ] # } # if (is.data.frame(x = meta.data)) { # new.meta.data &lt;- data.frame(row.names = colnames(x = counts)) # for (ii in 1:ncol(x = meta.data)) { # new.meta.data[rownames(x = meta.data), colnames(x = meta.data)[ii]] &lt;- meta.data[, # ii, drop = FALSE] # } # meta.data &lt;- new.meta.data # } # } # assay.data &lt;- CreateAssayObject(counts = counts, min.cells = min.cells, # min.features = min.features) # Key(object = assay.data) &lt;- paste0(tolower(x = assay), \"_\") # assay.list &lt;- list(assay.data) # names(x = assay.list) &lt;- assay # init.meta.data &lt;- data.frame(row.names = colnames(x = assay.list[[assay]])) # idents &lt;- factor(x = unlist(x = lapply(X = colnames(x = assay.data), # FUN = ExtractField, field = names.field, delim = names.delim))) # if (any(is.na(x = idents))) { # warning(\"Input parameters result in NA values for initial cell identities. Setting all initial idents to the project name\") # } # ident.levels &lt;- length(x = unique(x = idents)) # if (ident.levels &gt; 100 || ident.levels == 0 || ident.levels == # length(x = idents)) { # idents &lt;- rep.int(x = factor(x = project), times = ncol(x = assay.data)) # } # names(x = idents) &lt;- colnames(x = assay.data) # object &lt;- new(Class = \"Seurat\", assays = assay.list, # meta.data = init.meta.data, active.assay = assay, active.ident = idents, # project.name = project, version = packageVersion(pkg = \"Seurat\")) # object[[\"orig.ident\"]] &lt;- idents # n.calc &lt;- CalcN(object = assay.data) # if (!is.null(x = n.calc)) { # names(x = n.calc) &lt;- paste(names(x = n.calc), assay, # sep = \"_\") # object[[names(x = n.calc)]] &lt;- n.calc # } # if (!is.null(x = meta.data)) { # object &lt;- AddMetaData(object = object, metadata = meta.data) # } # return(object) # } # # Seurat:: CreateAssayObject # function (counts, data, min.cells = 0, min.features = 0) # { # if (missing(x = counts) &amp;&amp; missing(x = data)) { # stop(\"Must provide either 'counts' or 'data'\") # } # else if (!missing(x = counts) &amp;&amp; !missing(x = data)) { # stop(\"Either 'counts' or 'data' must be missing; both cannot be provided\") # } # else if (!missing(x = counts)) { # if (anyDuplicated(rownames(x = counts))) { # warning(\"Non-unique features (rownames) present in the input matrix, making unique\", # call. = FALSE, immediate. = TRUE) # rownames(x = counts) &lt;- make.unique(names = rownames(x = counts)) # } # if (anyDuplicated(colnames(x = counts))) { # warning(\"Non-unique cell names (colnames) present in the input matrix, making unique\", # call. = FALSE, immediate. = TRUE) # colnames(x = counts) &lt;- make.unique(names = colnames(x = counts)) # } # if (is.null(x = colnames(x = counts))) { # stop(\"No cell names (colnames) names present in the input matrix\") # } # if (any(rownames(x = counts) == \"\")) { # stop(\"Feature names of counts matrix cannot be empty\", # call. = FALSE) # } # if (nrow(x = counts) &gt; 0 &amp;&amp; is.null(x = rownames(x = counts))) { # stop(\"No feature names (rownames) names present in the input matrix\") # } # if (!inherits(x = counts, what = \"dgCMatrix\")) { # counts &lt;- as(object = as.matrix(x = counts), Class = \"dgCMatrix\") # } # if (min.features &gt; 0) { # nfeatures &lt;- Matrix::colSums(x = counts &gt; 0) # counts &lt;- counts[, which(x = nfeatures &gt;= min.features)] # } # if (min.cells &gt; 0) { # num.cells &lt;- Matrix::rowSums(x = counts &gt; 0) # counts &lt;- counts[which(x = num.cells &gt;= min.cells), # ] # } # data &lt;- counts # } # else if (!missing(x = data)) { # if (anyDuplicated(rownames(x = data))) { # warning(\"Non-unique features (rownames) present in the input matrix, making unique\", # call. = FALSE, immediate. = TRUE) # rownames(x = data) &lt;- make.unique(names = rownames(x = data)) # } # if (anyDuplicated(colnames(x = data))) { # warning(\"Non-unique cell names (colnames) present in the input matrix, making unique\", # call. = FALSE, immediate. = TRUE) # colnames(x = data) &lt;- make.unique(names = colnames(x = data)) # } # if (is.null(x = colnames(x = data))) { # stop(\"No cell names (colnames) names present in the input matrix\") # } # if (any(rownames(x = data) == \"\")) { # stop(\"Feature names of data matrix cannot be empty\", # call. = FALSE) # } # if (nrow(x = data) &gt; 0 &amp;&amp; is.null(x = rownames(x = data))) { # stop(\"No feature names (rownames) names present in the input matrix\") # } # if (min.cells != 0 | min.features != 0) { # warning(\"No filtering performed if passing to data rather than counts\", # call. = FALSE, immediate. = TRUE) # } # counts &lt;- new(Class = \"matrix\") # } # if (!is.vector(x = rownames(x = counts))) { # rownames(x = counts) &lt;- as.vector(x = rownames(x = counts)) # } # if (!is.vector(x = colnames(x = counts))) { # colnames(x = counts) &lt;- as.vector(x = colnames(x = counts)) # } # if (!is.vector(x = rownames(x = data))) { # rownames(x = data) &lt;- as.vector(x = rownames(x = data)) # } # if (!is.vector(x = colnames(x = data))) { # colnames(x = data) &lt;- as.vector(x = colnames(x = data)) # } # if (any(grepl(pattern = \"_\", x = rownames(x = counts))) || # any(grepl(pattern = \"_\", x = rownames(x = data)))) { # warning(\"Feature names cannot have underscores ('_'), replacing with dashes ('-')\", # call. = FALSE, immediate. = TRUE) # rownames(x = counts) &lt;- gsub(pattern = \"_\", replacement = \"-\", # x = rownames(x = counts)) # rownames(x = data) &lt;- gsub(pattern = \"_\", replacement = \"-\", # x = rownames(x = data)) # } # if (any(grepl(pattern = \"|\", x = rownames(x = counts), # fixed = TRUE)) || any(grepl(pattern = \"|\", x = rownames(x = data), # fixed = TRUE))) { # warning(\"Feature names cannot have pipe characters ('|'), replacing with dashes ('-')\", # call. = FALSE, immediate. = TRUE) # rownames(x = counts) &lt;- gsub(pattern = \"|\", replacement = \"-\", # x = rownames(x = counts), fixed = TRUE) # rownames(x = data) &lt;- gsub(pattern = \"|\", replacement = \"-\", # x = rownames(x = data), fixed = TRUE) # } # init.meta.features &lt;- data.frame(row.names = rownames(x = data)) # assay &lt;- new(Class = \"Assay\", counts = counts, data = data, # scale.data = new(Class = \"matrix\"), meta.features = init.meta.features) # return(assay) # } ###update object to avoid warning. data(\"pbmc3k\") pbmc &lt;- UpdateSeuratObject(pbmc3k) rm(pbmc3k) pbmc ## An object of class Seurat ## 13714 features across 2700 samples within 1 assay ## Active assay: RNA (13714 features) 2. 基本预处理 作者在原教程说： The steps below encompass the standard pre-processing workflow for scRNA-seq data in Seurat. These represent the selection and filtration of cells based on QC metrics, data normalization and scaling, and the detection of highly variable features. 2.1 细胞质控 三种基本的QC metrics The number of unique genes detected in each cell. Low-quality cells or empty droplets will often have very few genes Cell doublets or multiplets may exhibit an aberrantly high gene count Similarly, the total number of molecules detected within a cell (correlates strongly with unique genes) The percentage of reads that map to the mitochondrial genome Low-quality / dying cells often exhibit extensive mitochondrial contamination We calculate mitochondrial QC metrics with the PercentageFeatureSet function, which calculates the percentage of counts originating from a set of features We use the set of all genes starting with MT- as a set of mitochondrial genes 注意，人的线粒体基因是“MT-”开头，而小鼠的线粒体基因是“mt-”开头 # The [[ operator can add columns to object metadata. This is a great place to stash QC stats ### how does PercentageFeatureSet work # PercentageFeatureSet # function (object, pattern = NULL, features = NULL, col.name = NULL, # assay = NULL) # { # assay &lt;- assay %||% DefaultAssay(object = object) # if (!is.null(x = features) &amp;&amp; !is.null(x = pattern)) { # warning(\"Both pattern and features provided. Pattern is being ignored.\") # } # features &lt;- features %||% grep(pattern = pattern, x = rownames(x = object[[assay]]), # value = TRUE) # percent.featureset &lt;- colSums(x = GetAssayData(object = object, # assay = assay, slot = \"counts\")[features, , drop = FALSE])/object[[paste0(\"nCount_\", # assay)]] * 100 # if (!is.null(x = col.name)) { # object &lt;- AddMetaData(object = object, metadata = percent.featureset, # col.name = col.name) # return(object) # } # return(percent.featureset) # } pbmc[[\"percent.mt\"]] &lt;- PercentageFeatureSet(pbmc, pattern = \"^MT-\") # Show QC metrics for the first 5 cells head(pbmc@meta.data, 5) ## orig.ident nCount_RNA nFeature_RNA seurat_annotations percent.mt ## AAACATACAACCAC pbmc3k 2419 779 Memory CD4 T 3.0177759 ## AAACATTGAGCTAC pbmc3k 4903 1352 B 3.7935958 ## AAACATTGATCAGC pbmc3k 3147 1129 Memory CD4 T 0.8897363 ## AAACCGTGCTTCCG pbmc3k 2639 960 CD14+ Mono 1.7430845 ## AAACCGTGTATGCG pbmc3k 980 521 NK 1.2244898 由于我们用的是作者给了metadata的数据，里面已经出现了细胞类型的注释，见seurat_annotation这一项； QC metric的可视化： # Visualize QC metrics as a violin plot VlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3) # FeatureScatter is typically used to visualize feature-feature relationships, but can be used # for anything calculated by the object, i.e. columns in object metadata, PC scores etc. plot1 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\") plot2 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\") plot1 + plot2 最终选择的质控标准为： We filter cells that have unique feature counts over 2,500 or less than 200 We filter cells that have &gt;5% mitochondrial counts pbmc &lt;- subset(pbmc, subset = nFeature_RNA &gt; 200 &amp; nFeature_RNA &lt; 2500 &amp; percent.mt &lt; 5) 2.2 标准化 After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. Normalized values are stored in pbmc[[“RNA”]]@data. pbmc &lt;- NormalizeData(pbmc, normalization.method = \"LogNormalize\", scale.factor = 10000) 2.3 特征选择 哪些基因能反应不同细胞之间的异质性？是那些表达差异大的基因； 注意FindVariableFeatures是S3 generic，泛型函数。 如何查看一个泛型函数的源代码呢，我们先用methods函数匹配该范型函数的名字： methods(FindVariableFeatures) ## [1] FindVariableFeatures.Assay* FindVariableFeatures.default* ## [3] FindVariableFeatures.Seurat* ## see '?methods' for accessing help and source code 星号表明我们不能直接通过运行函数名字来查看其源代码，但是我们可以通过运行 getAnywhere函数来获取这个函数， getAnywhere(FindVariableFeatures.Seurat) ## A single object matching 'FindVariableFeatures.Seurat' was found ## It was found in the following places ## registered S3 method for FindVariableFeatures from namespace Seurat ## namespace:Seurat ## with value ## ## function (object, assay = NULL, selection.method = \"vst\", loess.span = 0.3, ## clip.max = \"auto\", mean.function = FastExpMean, dispersion.function = FastLogVMR, ## num.bin = 20, binning.method = \"equal_width\", nfeatures = 2000, ## mean.cutoff = c(0.1, 8), dispersion.cutoff = c(1, Inf), verbose = TRUE, ## ...) ## { ## assay &lt;- assay %||% DefaultAssay(object = object) ## assay.data &lt;- GetAssay(object = object, assay = assay) ## assay.data &lt;- FindVariableFeatures(object = assay.data, selection.method = selection.method, ## loess.span = loess.span, clip.max = clip.max, mean.function = mean.function, ## dispersion.function = dispersion.function, num.bin = num.bin, ## binning.method = binning.method, nfeatures = nfeatures, ## mean.cutoff = mean.cutoff, dispersion.cutoff = dispersion.cutoff, ## verbose = verbose, ...) ## object[[assay]] &lt;- assay.data ## object &lt;- LogSeuratCommand(object = object) ## return(object) ## } ## &lt;bytecode: 0x0000000022fa2410&gt; ## &lt;environment: namespace:Seurat&gt; 我们可以发现，默认的FindVariableFeatures.Seuratmethod调用了FindVariableFeatures.Assay： getAnywhere(FindVariableFeatures.Assay) ## A single object matching 'FindVariableFeatures.Assay' was found ## It was found in the following places ## registered S3 method for FindVariableFeatures from namespace Seurat ## namespace:Seurat ## with value ## ## function (object, selection.method = \"vst\", loess.span = 0.3, ## clip.max = \"auto\", mean.function = FastExpMean, dispersion.function = FastLogVMR, ## num.bin = 20, binning.method = \"equal_width\", nfeatures = 2000, ## mean.cutoff = c(0.1, 8), dispersion.cutoff = c(1, Inf), verbose = TRUE, ## ...) ## { ## if (length(x = mean.cutoff) != 2 || length(x = dispersion.cutoff) != ## 2) { ## stop(\"Both 'mean.cutoff' and 'dispersion.cutoff' must be two numbers\") ## } ## if (selection.method == \"vst\") { ## data &lt;- GetAssayData(object = object, slot = \"counts\") ## if (IsMatrixEmpty(x = data)) { ## warning(\"selection.method set to 'vst' but count slot is empty; will use data slot instead\") ## data &lt;- GetAssayData(object = object, slot = \"data\") ## } ## } ## else { ## data &lt;- GetAssayData(object = object, slot = \"data\") ## } ## hvf.info &lt;- FindVariableFeatures(object = data, selection.method = selection.method, ## loess.span = loess.span, clip.max = clip.max, mean.function = mean.function, ## dispersion.function = dispersion.function, num.bin = num.bin, ## binning.method = binning.method, verbose = verbose, ...) ## object[[names(x = hvf.info)]] &lt;- hvf.info ## hvf.info &lt;- hvf.info[which(x = hvf.info[, 1, drop = TRUE] != ## 0), ] ## if (selection.method == \"vst\") { ## hvf.info &lt;- hvf.info[order(hvf.info$vst.variance.standardized, ## decreasing = TRUE), , drop = FALSE] ## } ## else { ## hvf.info &lt;- hvf.info[order(hvf.info$mvp.dispersion, decreasing = TRUE), ## , drop = FALSE] ## } ## selection.method &lt;- switch(EXPR = selection.method, mvp = \"mean.var.plot\", ## disp = \"dispersion\", selection.method) ## top.features &lt;- switch(EXPR = selection.method, mean.var.plot = { ## means.use &lt;- (hvf.info[, 1] &gt; mean.cutoff[1]) &amp; (hvf.info[, ## 1] &lt; mean.cutoff[2]) ## dispersions.use &lt;- (hvf.info[, 3] &gt; dispersion.cutoff[1]) &amp; ## (hvf.info[, 3] &lt; dispersion.cutoff[2]) ## rownames(x = hvf.info)[which(x = means.use &amp; dispersions.use)] ## }, dispersion = head(x = rownames(x = hvf.info), n = nfeatures), ## vst = head(x = rownames(x = hvf.info), n = nfeatures), ## stop(\"Unkown selection method: \", selection.method)) ## VariableFeatures(object = object) &lt;- top.features ## vf.name &lt;- ifelse(test = selection.method == \"vst\", yes = \"vst\", ## no = \"mvp\") ## vf.name &lt;- paste0(vf.name, \".variable\") ## object[[vf.name]] &lt;- rownames(x = object[[]]) %in% top.features ## return(object) ## } ## &lt;bytecode: 0x000000002dc5d050&gt; ## &lt;environment: namespace:Seurat&gt; 千层饼的最后一层； getAnywhere(FindVariableFeatures.default) ## A single object matching 'FindVariableFeatures.default' was found ## It was found in the following places ## registered S3 method for FindVariableFeatures from namespace Seurat ## namespace:Seurat ## with value ## ## function (object, selection.method = \"vst\", loess.span = 0.3, ## clip.max = \"auto\", mean.function = FastExpMean, dispersion.function = FastLogVMR, ## num.bin = 20, binning.method = \"equal_width\", verbose = TRUE, ## ...) ## { ## CheckDots(...) ## if (!inherits(x = object, \"Matrix\")) { ## object &lt;- as(object = as.matrix(x = object), Class = \"Matrix\") ## } ## if (!inherits(x = object, what = \"dgCMatrix\")) { ## object &lt;- as(object = object, Class = \"dgCMatrix\") ## } ## if (selection.method == \"vst\") { ## if (clip.max == \"auto\") { ## clip.max &lt;- sqrt(x = ncol(x = object)) ## } ## hvf.info &lt;- data.frame(mean = rowMeans(x = object)) ## hvf.info$variance &lt;- SparseRowVar2(mat = object, mu = hvf.info$mean, ## display_progress = verbose) ## hvf.info$variance.expected &lt;- 0 ## hvf.info$variance.standardized &lt;- 0 ## not.const &lt;- hvf.info$variance &gt; 0 ## fit &lt;- loess(formula = log10(x = variance) ~ log10(x = mean), ## data = hvf.info[not.const, ], span = loess.span) ## hvf.info$variance.expected[not.const] &lt;- 10^fit$fitted ## hvf.info$variance.standardized &lt;- SparseRowVarStd(mat = object, ## mu = hvf.info$mean, sd = sqrt(hvf.info$variance.expected), ## vmax = clip.max, display_progress = verbose) ## colnames(x = hvf.info) &lt;- paste0(\"vst.\", colnames(x = hvf.info)) ## } ## else { ## if (!inherits(x = mean.function, what = \"function\")) { ## stop(\"'mean.function' must be a function\") ## } ## if (!inherits(x = dispersion.function, what = \"function\")) { ## stop(\"'dispersion.function' must be a function\") ## } ## feature.mean &lt;- mean.function(object, verbose) ## feature.dispersion &lt;- dispersion.function(object, verbose) ## names(x = feature.mean) &lt;- names(x = feature.dispersion) &lt;- rownames(x = object) ## feature.dispersion[is.na(x = feature.dispersion)] &lt;- 0 ## feature.mean[is.na(x = feature.mean)] &lt;- 0 ## data.x.breaks &lt;- switch(EXPR = binning.method, equal_width = num.bin, ## equal_frequency = c(-1, quantile(x = feature.mean[feature.mean &gt; ## 0], probs = seq.int(from = 0, to = 1, length.out = num.bin))), ## stop(\"Unknown binning method: \", binning.method)) ## data.x.bin &lt;- cut(x = feature.mean, breaks = data.x.breaks) ## names(x = data.x.bin) &lt;- names(x = feature.mean) ## mean.y &lt;- tapply(X = feature.dispersion, INDEX = data.x.bin, ## FUN = mean) ## sd.y &lt;- tapply(X = feature.dispersion, INDEX = data.x.bin, ## FUN = sd) ## feature.dispersion.scaled &lt;- (feature.dispersion - mean.y[as.numeric(x = data.x.bin)])/sd.y[as.numeric(x = data.x.bin)] ## names(x = feature.dispersion.scaled) &lt;- names(x = feature.mean) ## hvf.info &lt;- data.frame(feature.mean, feature.dispersion, ## feature.dispersion.scaled) ## rownames(x = hvf.info) &lt;- rownames(x = object) ## colnames(x = hvf.info) &lt;- paste0(\"mvp.\", c(\"mean\", \"dispersion\", ## \"dispersion.scaled\")) ## } ## return(hvf.info) ## } ## &lt;bytecode: 0x0000000023f13fd0&gt; ## &lt;environment: namespace:Seurat&gt; 忽略这些技术细节，进行特征选择； pbmc &lt;- FindVariableFeatures(pbmc, selection.method = \"vst\", nfeatures = 2000) # Identify the 10 most highly variable genes top10 &lt;- head(VariableFeatures(pbmc), 10) # plot variable features with and without labels plot1 &lt;- VariableFeaturePlot(pbmc) plot2 &lt;- LabelPoints(plot = plot1, points = top10, repel = TRUE) plot1 + plot2 2.4 Scaling the data 这步的目的是为了后续的PCA： Next, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData function: + Shifts the expression of each gene, so that the mean expression across cells is 0 + Scales the expression of each gene, so that the variance across cells is 1 + This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate + The results of this are stored in pbmc[[“RNA”]]@scale.data 回归掉percent.mt对于PCA的影响。这步是一步限速步骤； all.genes &lt;- rownames(pbmc) pbmc &lt;- ScaleData(pbmc, features = all.genes,vars.to.regress = \"percent.mt\") 有一个问题后面的marker基因一定是HVG吗？ 2.5 线性降维(PCA) Next we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset. pbmc &lt;- RunPCA(pbmc, features = VariableFeatures(object = pbmc)) # Examine and visualize PCA results a few different ways print(pbmc[[\"pca\"]], dims = 1:5, nfeatures = 5) ## PC_ 1 ## Positive: CST3, TYROBP, LST1, AIF1, FTL ## Negative: MALAT1, LTB, IL32, IL7R, CD2 ## PC_ 2 ## Positive: CD79A, MS4A1, TCL1A, HLA-DQA1, HLA-DQB1 ## Negative: NKG7, PRF1, CST7, GZMA, GZMB ## PC_ 3 ## Positive: HLA-DQA1, CD79A, CD79B, HLA-DQB1, HLA-DPA1 ## Negative: PPBP, PF4, SDPR, SPARC, GNG11 ## PC_ 4 ## Positive: HLA-DQA1, CD79B, CD79A, MS4A1, HLA-DQB1 ## Negative: VIM, IL7R, S100A6, S100A8, IL32 ## PC_ 5 ## Positive: GZMB, FGFBP2, S100A8, NKG7, GNLY ## Negative: LTB, IL7R, CKB, MS4A7, RP11-290F20.3 VizDimLoadings(pbmc, dims = 1:2, reduction = \"pca\") DimPlot(pbmc, reduction = \"pca\") In particular DimHeatmap allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses. Both cells and features are ordered according to their PCA scores. Setting cells to a number plots the ‘extreme’ cells on both ends of the spectrum, which dramatically speeds plotting for large datasets. Though clearly a supervised analysis, we find this to be a valuable tool for exploring correlated feature sets. ### Plot an equal number of genes with both + and - scores. mypal &lt;- rev(colorRampPalette(RColorBrewer::brewer.pal(11,\"RdBu\"))(256)) DimHeatmap(pbmc, dims = 1, cells = 500, balanced = TRUE,fast = F)+scale_fill_gradientn(colors = mypal) DimHeatmap(pbmc, dims = 1:15, cells = 500, balanced = TRUE) 2.6 Determine the ‘dimensionality’ of the dataset To overcome the extensive technical noise in any single feature for scRNA-seq data, Seurat clusters cells based on their PCA scores, with each PC essentially representing a ‘metafeature’ that combines information across a correlated feature set. The top principal components therefore represent a robust compression of the dataset. However, how many componenets should we choose to include? 10? 20? 100? 两种统计方法，JackStraw和ElbowPlot，前者比较耗时，不再展示了，用后者 ElbowPlot(pbmc) 作者给出了更进一步的解释 Identifying the true dimensionality of a dataset – can be challenging/uncertain for the user. We therefore suggest these three approaches to consider. The first is more supervised, exploring PCs to determine relevant sources of heterogeneity, and could be used in conjunction with GSEA for example. The second implements a statistical test based on a random null model, but is time-consuming for large datasets, and may not return a clear PC cutoff. The third is a heuristic that is commonly used, and can be calculated instantly. In this example, all three approaches yielded similar results, but we might have been justified in choosing anything between PC 7-12 as a cutoff. We chose 10 here, but encourage users to consider the following: Dendritic cell and NK aficionados may recognize that genes strongly associated with PCs 12 and 13 define rare immune subsets (i.e. MZB1 is a marker for plasmacytoid DCs). However, these groups are so rare, they are difficult to distinguish from background noise for a dataset of this size without prior knowledge. We encourage users to repeat downstream analyses with a different number of PCs (10, 15, or even 50!). As you will observe, the results often do not differ dramatically. We advise users to err on the higher side when choosing this parameter. For example, performing downstream analyses with only 5 PCs does signifcanltly and adversely affect results. 3. 后续分析 3.1 聚类 FindNeighbors构建构建SNN-graph, 而FindClusters用来实现Louvain algorithm，进行图聚类； methods(FindNeighbors) ## [1] FindNeighbors.Assay* FindNeighbors.default* FindNeighbors.dist* ## [4] FindNeighbors.Seurat* ## see '?methods' for accessing help and source code getAnywhere(FindNeighbors.Seurat) ## A single object matching 'FindNeighbors.Seurat' was found ## It was found in the following places ## registered S3 method for FindNeighbors from namespace Seurat ## namespace:Seurat ## with value ## ## function (object, reduction = \"pca\", dims = 1:10, assay = NULL, ## features = NULL, k.param = 20, compute.SNN = TRUE, prune.SNN = 1/15, ## nn.method = \"rann\", annoy.metric = \"euclidean\", nn.eps = 0, ## verbose = TRUE, force.recalc = FALSE, do.plot = FALSE, graph.name = NULL, ## ...) ## { ## CheckDots(...) ## if (!is.null(x = dims)) { ## assay &lt;- DefaultAssay(object = object[[reduction]]) ## data.use &lt;- Embeddings(object = object[[reduction]]) ## if (max(dims) &gt; ncol(x = data.use)) { ## stop(\"More dimensions specified in dims than have been computed\") ## } ## data.use &lt;- data.use[, dims] ## neighbor.graphs &lt;- FindNeighbors(object = data.use, k.param = k.param, ## compute.SNN = compute.SNN, prune.SNN = prune.SNN, ## nn.method = nn.method, annoy.metric = annoy.metric, ## nn.eps = nn.eps, verbose = verbose, force.recalc = force.recalc, ## ...) ## } ## else { ## assay &lt;- assay %||% DefaultAssay(object = object) ## data.use &lt;- GetAssay(object = object, assay = assay) ## neighbor.graphs &lt;- FindNeighbors(object = data.use, features = features, ## k.param = k.param, compute.SNN = compute.SNN, prune.SNN = prune.SNN, ## nn.method = nn.method, annoy.metric = annoy.metric, ## nn.eps = nn.eps, verbose = verbose, force.recalc = force.recalc, ## ...) ## } ## graph.name &lt;- graph.name %||% paste0(assay, \"_\", names(x = neighbor.graphs)) ## for (ii in 1:length(x = graph.name)) { ## DefaultAssay(object = neighbor.graphs[[ii]]) &lt;- assay ## object[[graph.name[[ii]]]] &lt;- neighbor.graphs[[ii]] ## } ## if (do.plot) { ## if (!\"tsne\" %in% names(x = object@reductions)) { ## warning(\"Please compute a tSNE for SNN visualization. See RunTSNE().\") ## } ## else { ## if (nrow(x = Embeddings(object = object[[\"tsne\"]])) != ## ncol(x = object)) { ## warning(\"Please compute a tSNE for SNN visualization. See RunTSNE().\") ## } ## else { ## net &lt;- graph.adjacency(adjmatrix = as.matrix(x = neighbor.graphs[[2]]), ## mode = \"undirected\", weighted = TRUE, diag = FALSE) ## plot.igraph(x = net, layout = as.matrix(x = Embeddings(object = object[[\"tsne\"]])), ## edge.width = E(graph = net)$weight, vertex.label = NA, ## vertex.size = 0) ## } ## } ## } ## object &lt;- LogSeuratCommand(object = object) ## return(object) ## } ## &lt;bytecode: 0x000000001e49f8e0&gt; ## &lt;environment: namespace:Seurat&gt; pbmc &lt;- FindNeighbors(pbmc, dims = 1:10) pbmc &lt;- FindClusters(pbmc, resolution = 0.5) ## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck ## ## Number of nodes: 2638 ## Number of edges: 95930 ## ## Running Louvain algorithm... ## Maximum modularity in 10 random starts: 0.8737 ## Number of communities: 9 ## Elapsed time: 0 seconds 3.2 Run UMAP/tsne run tsne pbmc &lt;- RunTSNE(pbmc,dims = 1:10) DimPlot(pbmc,label = T, reduction = \"tsne\") draw snn graph on tsne-embeding test &lt;- pbmc[[\"RNA_snn\"]] net &lt;- graph.adjacency(adjmatrix = as.matrix(x = test), mode = \"undirected\", weighted = TRUE, diag = FALSE) plot.igraph(x = net, layout = as.matrix(x = Embeddings(object = pbmc[[\"tsne\"]])), edge.width = E(graph = net)$weight, vertex.label = NA, vertex.size = 0) run umap # If you haven't installed UMAP, you can do so via reticulate::py_install(packages = # 'umap-learn') pbmc &lt;- RunUMAP(pbmc,umap.method = \"umap-learn\", dims = 1:10) # note that you can set `label = TRUE` or use the LabelClusters function to help label # individual clusters DimPlot(pbmc,label = T, reduction = \"umap\") test &lt;- pbmc[[\"RNA_snn\"]] net &lt;- graph.adjacency(adjmatrix = as.matrix(x = test), mode = \"undirected\", weighted = TRUE, diag = FALSE) plot.igraph(x = net, layout = as.matrix(x = Embeddings(object = pbmc[[\"umap\"]])), edge.width = E(graph = net)$weight, vertex.label = NA, vertex.size = 0) 3.3 Finding differentially expressed features (cluster biomarkers) 之前分群结果做差异表达； Seurat can help you find markers that define clusters via differential expression. By default, it identifes positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells. The min.pct argument requires a feature to be detected at a minimum percentage in either of the two groups of cells, and the thresh.test argument requires a feature to be differentially expressed (on average) by some amount between the two groups. You can set both of these to 0, but with a dramatic increase in time - since this will test a large number of features that are unlikely to be highly discriminatory. As another option to speed up these computations, max.cells.per.ident can be set. This will downsample each identity class to have no more cells than whatever this is set to. While there is generally going to be a loss in power, the speed increases can be significiant and the most highly differentially expressed features will likely still rise to the top. # find markers for every cluster compared to all remaining cells, report only the positive ones pbmc.markers &lt;- FindAllMarkers(pbmc, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25) pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(n = 2, wt = avg_logFC) ## # A tibble: 18 x 7 ## # Groups: cluster [9] ## p_val avg_logFC pct.1 pct.2 p_val_adj cluster gene ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;chr&gt; ## 1 1.88e-117 0.748 0.913 0.588 2.57e-113 0 LDHB ## 2 5.01e- 85 0.931 0.437 0.108 6.88e- 81 0 CCR7 ## 3 0. 3.86 0.996 0.215 0. 1 S100A9 ## 4 0. 3.80 0.975 0.121 0. 1 S100A8 ## 5 2.61e- 81 0.886 0.981 0.65 3.58e- 77 2 LTB ## 6 1.22e- 59 0.886 0.669 0.25 1.68e- 55 2 CD2 ## 7 0. 2.99 0.939 0.042 0. 3 CD79A ## 8 1.06e-269 2.49 0.623 0.022 1.45e-265 3 TCL1A ## 9 5.98e-221 2.23 0.987 0.226 8.20e-217 4 CCL5 ## 10 1.42e-173 2.08 0.572 0.051 1.94e-169 4 GZMK ## 11 3.51e-184 2.30 0.975 0.134 4.82e-180 5 FCGR3A ## 12 2.03e-125 2.14 1 0.315 2.78e-121 5 LST1 ## 13 3.17e-267 3.35 0.961 0.068 4.35e-263 6 GZMB ## 14 1.04e-189 3.66 0.961 0.132 1.43e-185 6 GNLY ## 15 1.48e-220 2.68 0.812 0.011 2.03e-216 7 FCER1A ## 16 1.67e- 21 1.99 1 0.513 2.28e- 17 7 HLA-DPB1 ## 17 7.73e-200 5.02 1 0.01 1.06e-195 8 PF4 ## 18 3.68e-110 5.94 1 0.024 5.05e-106 8 PPBP 可视化： VlnPlot(pbmc, features = c(\"MS4A1\", \"CD79A\")) # you can plot raw counts as well VlnPlot(pbmc, features = c(\"MS4A1\", \"CD79A\"), slot = \"counts\", log = TRUE) 使用FeatureScatter获得和流式图一样的效果； FeatureScatter(object = pbmc, feature1 = \"MS4A1\", feature2 = \"CD79A\")+ ggtitle(label = NULL) 用FeaturePlot在Embeding上展示表达量； FeaturePlot(pbmc, features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\", \"PPBP\", \"CD8A\")) 气泡图DotPlot DotPlot(object = pbmc, features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\", \"PPBP\", \"CD8A\"))+ coord_flip() RidgePlot RidgePlot(object = pbmc, features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\", \"PPBP\", \"CD8A\")) 热图DoHeatmap top10 &lt;- pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(n = 10, wt = avg_logFC) DoHeatmap(pbmc, features = top10$gene) + scale_fill_gradientn(colors = mypal) 3.4 Assigning cell type identity to clusters new.cluster.ids &lt;- c(\"Naive CD4 T\",\"CD14+ Mono\", \"Memory CD4 T\", \"B\", \"CD8 T\", \"FCGR3A+ Mono\", \"NK\", \"DC\", \"Platelet\") names(new.cluster.ids) &lt;- levels(pbmc) pbmc &lt;- RenameIdents(pbmc, new.cluster.ids) DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5) + NoLegend() 4. Seurat object 详解 这一部分来自wiki 4.1 The Seurat object 一个Seurat对象有如下的slots: Slot Function assays A list of assays within this object meta.data Cell-level meta data active.assay Name of active, or default, assay active.ident Identity classes for the current object graphs A list of nearest neighbor graphs reductions A list of DimReduc objects project.name User-defined project name (optional) tools Empty list. Tool developers can store any internal data from their methods here misc Empty slot. User can store additional information here version Seurat version used when creating the object 这个对象把单细胞数据的所有的基本信息都包含进去了，可以用基本的一些函数去获取这些信息。例如，我们想要知道这个数据对应多少细胞，多少基因，可以用dim;ncol;nrow;细胞或者feature的名字，可以用rownames;colnames; 我们也可以通过names知道里面存储的如原始表达矩阵，或者降维后对象的名字。 names(x = pbmc) ## [1] \"RNA\" \"RNA_nn\" \"RNA_snn\" \"pca\" \"tsne\" \"umap\" rna &lt;- pbmc[['RNA']] 对于Seurat对象，有一系列的函数可以对其进行操作。这些函数可以称为其所属的methods。多说一句，Seurat采取的是S3对象的面向对象的数据结构。 可以使用如下命令访问与Seurat对象相关的操作。 utils::methods(class = 'Seurat') ## [1] $ $&lt;- [ ## [4] [[ [[&lt;- AddMetaData ## [7] as.CellDataSet as.loom as.SingleCellExperiment ## [10] Command DefaultAssay DefaultAssay&lt;- ## [13] dim dimnames droplevels ## [16] Embeddings FindClusters FindMarkers ## [19] FindNeighbors FindVariableFeatures GetAssay ## [22] GetAssayData HVFInfo Idents ## [25] Idents&lt;- Key levels ## [28] levels&lt;- Loadings merge ## [31] Misc Misc&lt;- names ## [34] NormalizeData OldWhichCells Project ## [37] Project&lt;- RenameCells RenameIdents ## [40] ReorderIdent RunALRA RunCCA ## [43] RunICA RunLSI RunPCA ## [46] RunTSNE RunUMAP ScaleData ## [49] ScoreJackStraw SetAssayData SetIdent ## [52] show StashIdent Stdev ## [55] subset SubsetData Tool ## [58] Tool&lt;- VariableFeatures VariableFeatures&lt;- ## [61] WhichCells ## see '?methods' for accessing help and source code 4.2 Assay The Assay class stores single cell data. For typical scRNA-seq experiments, a Seurat object will have a single Assay (“RNA”). This assay will also store multiple ‘transformations’ of the data, including raw counts (@counts slot), normalized data (@data slot), and scaled data for dimensional reduction (@scale.data slot). For more complex experiments, an object could contain multiple assays. These could include multi-modal data types (CITE-seq antibody-derived tags, ADTs), or imputed/batch-corrected measurements. Each of those assays has the option to store the same data transformations as well. 一个Assay 所含有的Slots Slot Function counts Stores unnormalized data such as raw counts or TPMs data Normalized data matrix scale.data Scaled data matrix key A character string to facilitate looking up features from a specific Assay var.features A vector of features identified as variable meta.features Feature-level meta data Assay对象也可以使用以下方法 Summary information about Assay objects can be had quickly and easily using standard R functions. Object shape/dimensions can be found using the dim, ncol, and nrow functions; cell and feature names can be found using the colnames and rownames functions, respectively, or the dimnames function. 更多的方法见 utils::methods(class = 'Assay') ## [1] [ [[ [[&lt;- ## [4] AddMetaData DefaultAssay DefaultAssay&lt;- ## [7] dim dimnames FindNeighbors ## [10] FindVariableFeatures GetAssayData HVFInfo ## [13] Key Key&lt;- merge ## [16] Misc Misc&lt;- NormalizeData ## [19] OldWhichCells RenameCells RunICA ## [22] RunLSI RunPCA ScaleData ## [25] SetAssayData show subset ## [28] SubsetData VariableFeatures VariableFeatures&lt;- ## [31] WhichCells ## see '?methods' for accessing help and source code Data Access # GetAssayData allows pulling from a specific slot rather than just data GetAssayData(object = rna, slot = 'scale.data')[1:3, 1:3] ## AAACATACAACCAC AAACATTGAGCTAC AAACATTGATCAGC ## AL627309.1 -0.06433822 -0.06968772 -0.04966479 ## AP006222.2 -0.02663018 -0.02065038 -0.04303249 ## RP11-206L10.2 -0.03015459 -0.02024084 -0.05734758 head(x = HVFInfo(object = rna,selection.method = \"vst\")) ## mean variance variance.standardized ## AL627309.1 0.003411676 0.003401325 0.9330441 ## AP006222.2 0.001137225 0.001136363 0.9924937 ## RP11-206L10.2 0.001895375 0.001892500 0.9627290 ## RP11-206L10.9 0.001137225 0.001136363 0.9924937 ## LINC00115 0.006823351 0.006779363 0.9062135 ## NOC2L 0.107278241 0.159514698 0.7849309 The key # Key both accesses and sets the key slot for an Assay object &gt; Key(object = rna) \"rna_\" &gt; Key(object = rna) &lt;- 'myRNA_' &gt; Key(object = rna) \"myRNA_\" # Pull a feature from the RNA assay on the Seurat level &gt; head(x = FetchData(object = pbmc, vars.fetch = 'rna_MS4A1')) rna_MS4A1 AAACATACAACCAC 0.000000 AAACATTGAGCTAC 2.583047 AAACATTGATCAGC 0.000000 AAACCGTGCTTCCG 0.000000 AAACCGTGTATGCG 0.000000 AAACGCACTGGTAC 0.000000 The DimReduc object represents a dimensional reduction taken upon the Seurat object. 4.3 The DimReduc object The DimReduc object represents a dimensional reduction taken upon the Seurat object. Slot Function cell.embeddings A matrix with cell embeddings feature.loadings A matrix with feature loadings feature.loadings.projected A matrix with projected feature loadings assay.used Assay used to calculate this dimensional reduction stdev Standard deviation for the dimensional reduction key A character string to facilitate looking up features from a specific DimReduc jackstraw Results from the JackStraw function misc … 和之前的很类似 pca &lt;- pbmc[[\"pca\"]] # The following examples use the PCA dimensional reduction from the PBMC 3k dataset &gt; pca A dimensional reduction object with key PC Number of dimensions: 20 Projected dimensional reduction calculated: FALSE Jackstraw run: FALSE # nrow and ncol provide the number of features and cells, respectively # dim provides both nrow and ncol at the same time &gt; dim(x = pca) [1] 1838 2638 # length provides the number of dimensions calculated &gt; length(x = pca) [1] 20 # In addtion to rownames and colnames, one can use dimnames # which provides a two-length list with both rownames and colnames &gt; head(x = rownames(x = rna)) [1] \"TNFRSF4\" \"CPSF3L\" \"ATAD3C\" \"C1orf86\" \"RER1\" \"TNFRSF25\" &gt; head(x = colnames(x = rna)) [1] \"AAACATACAACCAC\" \"AAACATTGAGCTAC\" \"AAACATTGATCAGC\" \"AAACCGTGCTTCCG\" [5] \"AAACCGTGTATGCG\" \"AAACGCACTGGTAC\" Access data # The key can be used to pull cell embeddings for specific dimensions from the Seurat level &gt; Key(object = pca) \"PC\" &gt; head(x = FetchData(object = pbmc, vars.fetch = 'PC1')) PC1 AAACATACAACCAC 5.569384 AAACATTGAGCTAC 7.216456 AAACATTGATCAGC 2.706629 AAACCGTGCTTCCG -10.134042 AAACCGTGTATGCG -1.099311 AAACGCACTGGTAC 1.455335 # DefaultAssay gets the name of the Assay object used to calculate the DimReduc &gt; DefaultAssay(object = pca) [1] \"RNA\" # Stdev gets the vector of standard deviations for each dimension embedded. Stdev(object = pca) [1] 5.666584 4.326466 3.952192 3.638124 2.191529 1.996551 1.877891 1.798251 [9] 1.766873 1.753684 1.731568 1.720525 1.718079 1.715879 1.707009 1.702660 [17] 1.697318 1.692549 1.686149 1.683967 在其上可以执行的method有 utils::methods(class = \"DimReduc\") ## [1] [ [[ Cells DefaultAssay DefaultAssay&lt;- ## [6] dim dimnames Embeddings IsGlobal JS ## [11] JS&lt;- Key Key&lt;- length Loadings ## [16] Loadings&lt;- names print RenameCells RunTSNE ## [21] ScoreJackStraw show Stdev subset ## see '?methods' for accessing help and source code 4.4 R面向对象编程的更多细节； 关于面向对象，以及S3对象的教程，更多可见： R深入|面向对象——泛型函数 OO field guide R语言面向对象编程","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"}]},{"title":"Dobrow-chap3","slug":"Dobrow-chap3","date":"2020-05-06T14:15:53.000Z","updated":"2025-01-11T17:16:31.803Z","comments":true,"path":"2020/05/06/Dobrow-chap3/","link":"","permalink":"https://landau1994.github.io/2020/05/06/Dobrow-chap3/","excerpt":"","text":"This is a note of the textbook Introduction to stochastic processes with R There exists everywhere a medium in things, determined by equilibrium. —Dmitri Mendeleev 承接上章最后的数值案例，本章主要讲转移步数趋于无穷时马尔可夫链的性质。 3.1 Limiting Distribution 3.1.1 定义 作者给了有一个定义和三个等价定义。这个含义最清楚： A limiting distribution for the Markov chain is a probability distribution 𝝀 with the property that, for any initial distribution : 这个定义与原定义的等价性也很容易理解： 若对某一马尔可夫链的状态转移矩阵有： 并且设初始分布,状态总数为 则有： $$\\begin{aligned} _{n}^n &amp;=(_1,,_n) \\ &amp; = \\begin{pmatrix} 1{i=1}^n_i \\ 2{i=1}^n_i \\ \\ m{i=1}^n_i \\end{pmatrix} \\ &amp; = \\ &amp; = \\end{aligned} $$ Ex3.1 Two state Markov Chain 计算案例； 3.1.2 Proportion of Time in Each State 利用计算条件期望的技术，来从状态在过程中所占的比例来理解Limit distribution Ex3.2 ###### Simulate discrete-time Markov chain ######################## # Simulates n steps of a Markov chain # markov(init,mat,n,states) # Generates X0, ..., Xn for a Markov chain with initiial # distribution init and transition matrix mat # Labels can be a character vector of states; default is 1, .... k markov &lt;- function(init,mat,n,labels) { if (missing(labels)) labels &lt;- 1:length(init) simlist &lt;- numeric(n+1) states &lt;- 1:length(init) simlist[1] &lt;- sample(states,1,prob=init) for (i in 2:(n+1)) { simlist[i] &lt;- sample(states,1,prob=mat[simlist[i-1],]) } labels[simlist] } #################################################### P &lt;- matrix(c(0.1,0.2,0.4,0.3,0.4,0,0.4,0.2,0.3,0.3,0,0.4,0.2,0.1,0.4,0.3), nrow=4, byrow=TRUE) lab &lt;- c(\"Aerobics\",\"Massage\",\"Weights\",\"Yoga\") rownames(P) &lt;- lab colnames(P) &lt;- lab P init &lt;- c(1/4,1/4,1/4,1/4) # initial distribution states &lt;- c(\"a\",\"m\",\"w\",\"y\") # simulate chain for 100 steps simlist &lt;- markov(init,P,100,states) simlist table(simlist)/100 steps &lt;- 1000000 simlist &lt;- markov(init,P,steps,states) table(simlist)/steps 3.2 Stationary Distribution 3.2.1 定义 注意Stationary Distribution的定义没有出现极限。 If the initial distributino is a stationary distribution, Then is a sequence of identically distributed random variables. But it doesn't mean that the random variables are independent. Lemma 3.1: Limiting Distributions are stationary Distribution The reverse is false, 反例： ， 以及 3.2.2 Regular Matrices 一个自然的想法是问，什么样的条件下，一个马尔可夫链有极限分布，而且极限分布就是平稳分布呢。 满足如下性质的马尔可夫链是符合这个要求的 Regular Transition Matrix A transition matrix is said to be regular if some power of is positive. That is , for some 有定理： Theorem 3.2: A markov chain whose transition matrix is regular has a limiting distribution, which is teh unique, positive, stationary distribution of the chanin. Ex 3.3-3.4 具体算例， 3.2.3 Finding the stationary distribution 本质上这是一个特征值问题。 ### Stationary distribution of discrete-time Markov chain ### (uses eigenvectors) ### stationary &lt;- function(mat) { x = eigen(t(mat))$vectors[,1] as.double(x/sum(x)) } Ex 3.5-3.6; 计算技巧，令 Ex 3.7 The Ehrenfest dog-flea model Ex 3.8 Random walk on a graph; On weighted graph Stationiary Distribution for Random walk on a weighted graph Let be a weighted graph with edge weight function . For random walk on G, the stationary distribution is proportion to the sum of teh edge weights incident to each vertex. That is. where On simple graph Stationary Distribution for simple Random Walk on a graph For simple random walk on a weighted graph, set , then, ,which gives Ex 3.9-3.10 如何计算的案例； 3.2.4 The Eigenvalue Connection 转置，看出与特征值的关联。 Ex 3.10 理论案例： random walk in regular graph.。 3.3 Can you find the way to state 3.3.1 状态可到达与状态互通 Say that state is accessible from state i, if . That is,there is positive probability of reaching from in a finite number of steps. State and communicate if is accessible from and is accessible from eg 3.11 本例讲述了用 Transition graphs 展示 Communication classes 3.3.2 不可约 Irreducibility A Markov chain is called irreducible if it has exactly one cmmunication class. That is, all states communicate with each other Ex 3.12 一个不可约链的例子； 3.3.3 Recurrence and Transience Given a Markov chain , let be the first passage time to state . If , see. Let be the probability started in eventually returns to . State is said to be recurrent if the Markov chain started in eventually revists . That is State is said to be transient if there is positive probability that the Markov chain started in j never returns to . That is 如何根据状态转移矩阵判定，某一个状态是Recurrent或Transient States。用示性函数， 由此可以推出另外一个判定条件； Recurrence, Transience State is recurrent if and only if State j is transient if and only if Recuurence and Transience are Class Properties Theorem 3.3 The states of a communication class are either all recurrent or all transient. Corollary 3.4 For a finite irreducible Markov chain, all states are recuurent. Ex 3.13 接下来的例子是简单的一维随机游走；这个例子可以推广到高维。 3.3.4 Canonical Decomposition Closed Communication Class Lemma 3.5 A communication class is closed if it consists of all recurrent states. A finite communication class is closed only if it consits of all recurrent states. 反证法即可证得；最后便可以得到，我们想定义的； The state space S of a finite Markov chain can be partitioned into transient and reccurent states as , where T is the set of all transient states and are closed communiction classes of recurrent states. This is called the canonical decomposition. 注：由等价类的定义可以保障这么重排状态转移矩阵，是与原矩阵等价的。 Given a canonical decomposition, the state space can be reordered so that the Markov transition matrix has the block matrix form 其中 Ex3.14 具体 case; 更进一步有： edit: 2020-05-06 3.7 Time reversibility 3.7.1 Definition The property of time reversibility can be explained intuitively as follows. If you were to take a movie of Markov chain moving forward in time and then run the movie backwards, you could not tell the difference between the two. 换成数学上的语言就是，如果假设马尔可夫链处于稳态，这时存在： 由全概率公式可知； Time Reversibility An irreducible Markov chain with transition matrix P and stationary distribution , if Ex 3.23; Ex 3.24；Simple random walk on a graph is time 3.7.2 Reversible Markov Chains and Radom walk Every reversible Markov chain can be considered as a random walk on a weighted graph Ex 3.25 算例； 3.7.3 The key benifit of reversibility Proposition 3.9 Let be the transition matrix of a Markov chain. If is a probability distribution which satisfies then is the stationary distribution, and the markov chain is reversible. Ex 3.26 Birth-and-death chain Case: random walk with a partialy relecting boundary. 3.8 Absorbing Chains 3.8.1 定义 Absorbing State, Absorbing Chain State is an absorbing state if . A Markov chain is called an absorbing chain if it has at leat one absorbing state. 根据这个定义，一个吸收的马尔可夫链的canoical decompostion可以写为： Ex 3.31 3.8.2 Expected Number of Visits to Transient States Theorem 3.11 Consider an absorbing Markov chain with t transient states. Let be a matrix indexed by transient states. where is the expected number of visits to given that the chain starts in , Then, 3.8.3 Expected Time to Absorption Absorbing Markov Chains For an absorbing Markov chain with all states either transient or absorbing. Let 1. (Absorption probability) The probability that from transient state the chain is absorbed in state is 2. (Absorption time) The expected number of steps from transient state until the chain is absorbed in some absorbing state is 3.8.4 Expected Hitting Time for Irreducible chain 3.8.5 Patterns in Sequences 3.9 Regenration and strong Markov property 3.10 Proofs of limiting Theorem 剩下的都是常规内容。不再赘述。 总的来说，这一章的章节组织很有条理，对初学者友好。而且选的例子很有启发性。 题外话： 有个值得思考的问题，这种偏向应用的数学内容的教材，如何平衡论述的逻辑，理论以及思考的深度，以及应用的广度，以及对于读者的吸引性和实用性，都是很需要功底的。但是这方面做的好的教材真的太少了。 理想的大学教师，是学术成就和教学成就都很出色，但是这毕竟是少数。 有一对儿相互矛盾的命题： 大学生应该提高自学能力，不要指望老师手把手的教？ 国家给了大学老师工资，大学生也付了学费，如果都靠自学的话，要大学干什么？ 依笔者看来，大学提供的是一套适合学习和研究的硬件设施，一张平静的书桌，一群志同道合的良师益友。这些环境和人，是任何其它机构或者网课代替不了的。","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"},{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}]},{"title":"","slug":"networkdata-quickstart","date":"2020-05-04T15:33:30.000Z","updated":"2025-01-11T17:16:31.839Z","comments":true,"path":"2020/05/04/networkdata-quickstart/","link":"","permalink":"https://landau1994.github.io/2020/05/04/networkdata-quickstart/","excerpt":"","text":"所选例子出自Modern Statistics for Modern Biology(Susan Holmes, Wolfgang Huber) 无向图的邻接矩阵是一个0-1矩阵： library(igraph) library(ggplot2) library(ggnetwork) library(network) edges1 &lt;- matrix(c(1,3,2,3,3,4,4,5,4,6),byrow = TRUE,ncol = 2) ### generate adjacency matrix edges1 &lt;- as.data.frame(edges1) mat &lt;- matrix(data = 0,nrow = 6,ncol = 6) for(ii in 1:6){ mat[edges1[ii,1],edges1[ii,2]] &lt;- 1 mat[edges1[ii,2],edges1[ii,1]] &lt;- 1 } ### Prepare data to plot dat_long &lt;- reshape2::melt(mat) dat_long$value &lt;- as.factor(dat_long$value) colnames(dat_long) &lt;- c(\"V1\",\"V2\",\"value\") ### plot gg &lt;- ggplot(dat_long)+ geom_tile(aes(V1,V2,fill=value), color=\"#7f7f7f\")+ scale_fill_manual(values=c(\"white\", \"black\"))+ coord_equal()+ labs(x=NULL, y=NULL)+ scale_x_continuous(breaks = 1:6)+ scale_y_reverse(breaks=1:6)+ theme_bw()+ theme(panel.grid=element_blank())+ theme(panel.border=element_blank()) gg 从邻接矩阵得到Graph: g1 &lt;- graph_from_adjacency_matrix(mat,mode = \"undirected\") plot(g1,vertex.size=25,edge.width=5,vertex.color=\"coral\") 给定edgelist，得到Graph edges1 &lt;- matrix(c(1,3,2,3,3,4,4,5,4,6),byrow = TRUE,ncol = 2) g1 &lt;- graph_from_edgelist(edges1,directed = F) plot(g1,vertex.size=25,edge.width=5,vertex.color=\"coral\") 更为高级的是，从数据中计算出邻接矩阵，并且自定义可视化的layout。 library(rworldmap) ### obtain data; get the binary matrix load(\"D:/tmp/Moderstatdata/data/dist2009c.RData\") country09 = attr(dist2009c, \"Label\") mstree2009 = ape::mst(dist2009c) ### calculate layout from world map mat = match(country09, countriesLow$NAME) coords2009 = data.frame( lat = countriesLow$LAT[mat], lon = countriesLow$LON[mat], country = country09) layoutCoordinates = cbind( x = jitter(coords2009$lon, amount = 15), y = jitter(coords2009$lat, amount = 8)) labc = names(table(country09)[which(table(country09) &gt; 1)]) matc = match(labc, countriesLow$NAME) dfc = data.frame( latc = countriesLow$LAT[matc], lonc = countriesLow$LON[matc], labc) dfctrans = dfc dfctrans[, 1] = (dfc[,1] + 31) / 93 dfctrans[, 2] = (dfc[,2] + 105) / 238 ggeo09 = ggnetwork(mstree2009, arrow.gap = 0, layout = layoutCoordinates) ###plot ggplot(ggeo09, aes(x = x, y = y, xend = xend, yend = yend)) + geom_edges(color = \"black\", alpha = 0.5, curvature = 0.1) + geom_nodes(aes(color = vertex.names), size = 2) + theme_blank() + geom_label(data = dfctrans, aes(x = lonc, xend = lonc, y = latc, yend = latc, label = labc, fill = labc), colour = \"white\", alpha = 0.5, size = 3) + theme(legend.position = \"none\")","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"Graph","slug":"Graph","permalink":"https://landau1994.github.io/tags/Graph/"},{"name":"Network","slug":"Network","permalink":"https://landau1994.github.io/tags/Network/"}]},{"title":"Calculate pi in R quikstart","slug":"Calculate-pi-in-R-quikstart","date":"2020-04-24T14:25:00.000Z","updated":"2025-01-11T17:16:31.798Z","comments":true,"path":"2020/04/24/Calculate-pi-in-R-quikstart/","link":"","permalink":"https://landau1994.github.io/2020/04/24/Calculate-pi-in-R-quikstart/","excerpt":"","text":"R中也可以用Rmpfr包实现多精度的计算。例如，我们可以用如下代码实现AGM算法计算Pi到小数点后256位。 library(Rmpfr) piMpfr &lt;- function(prec=256, itermax = 100, verbose=TRUE) { m2 &lt;- mpfr(2, prec) # '2' as mpfr number ## -&gt; all derived numbers are mpfr (with precision 'prec') p &lt;- m2 + sqrt(m2) # 2 + sqrt(2) = 3.414.. y &lt;- sqrt(sqrt(m2)) # 2^ {1/4} x &lt;- (y+1/y) / m2 it &lt;- 0L repeat { p.old &lt;- p it &lt;- it+1L p &lt;- p * (1+x) / (1+y) if(verbose) cat(sprintf(\"it=%2d, pi^ = %s, |.-.|/|.|=%e\\n\", it, formatMpfr(p, min(50, prec/log2(10))), 1-p.old/p)) if (abs(p-p.old) &lt;= m2^(-prec)) break if(it &gt; itermax) { warning(\"not converged in\", it, \"iterations\") ; break } ## else s &lt;- sqrt(x) y &lt;- (y*s + 1/s) / (1+y) x &lt;- (s+1/s)/2 } p } piMpfr(prec = 256) ## it= 1, pi^ = 3.1426067539416226007907198236183018919713562462772, |.-.|/|.|=-8.642723e-02 ## it= 2, pi^ = 3.1415926609660442304977522351203396906792842568645, |.-.|/|.|=-3.227958e-04 ## it= 3, pi^ = 3.1415926535897932386457739917571417940347896238675, |.-.|/|.|=-2.347934e-09 ## it= 4, pi^ = 3.1415926535897932384626433832795028841972241204666, |.-.|/|.|=-5.829228e-20 ## it= 5, pi^ = 3.1415926535897932384626433832795028841971693993751, |.-.|/|.|=-1.741826e-41 ## it= 6, pi^ = 3.1415926535897932384626433832795028841971693993751, |.-.|/|.|=0.000000e+00 ## 1 'mpfr' number of precision 256 bits ## [1] 3.141592653589793238462643383279502884197169399375105820974944592307816406286163","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"}]},{"title":"A Hard Rain's A-Gonna Fall","slug":"A-Hard-Rain-s-A-Gonna-Fall","date":"2020-04-20T02:31:32.000Z","updated":"2025-01-11T17:16:31.795Z","comments":true,"path":"2020/04/20/A-Hard-Rain-s-A-Gonna-Fall/","link":"","permalink":"https://landau1994.github.io/2020/04/20/A-Hard-Rain-s-A-Gonna-Fall/","excerpt":"","text":"A Hard Rain's A-Gonna Fall是美国国宝级歌手，诗人，诺贝尔文学奖得主Bob Dylan的名曲之一，虽然原唱说不上多么好听，但是歌词很有意境，分享如下： A Hard Rain's A-Gonna Fall Bob Dylan Oh, where have you been, my blue-eyed son? Oh, where have you been, my darling young one? I've stumbled on the side of twelve misty mountains I've walked and I've crawled on six crooked highways I've stepped in the middle of seven sad forests I've been out in front of a dozen dead oceans I've been ten thousand miles in the mouth of a graveyard And it's a hard, and it's a hard, it's a hard, and it's a hard And it's a hard rain's a-gonna fall Oh, what did you see, my blue-eyed son? Oh, what did you see, my darling young one? I saw a newborn baby with wild wolves all around it I saw a highway of diamonds with nobody on it I saw a black branch with blood that kept drippin' I saw a room full of men with their hammers a-bleedin' I saw a white ladder all covered with water I saw ten thousand talkers whose tongues were all broken I saw guns and sharp swords in the hands of young children And it's a hard, and it's a hard, it's a hard, it's a hard And it's a hard rain's a-gonna fall And what did you hear, my blue-eyed son? And what did you hear, my darling young one? I heard the sound of a thunder, it roared out a warnin' Heard the roar of a wave that could drown the whole world Heard one person starve, I heard many people laughin' Heard the song of a poet who died in the gutter Heard the sound of a clown who cried in the alley And it's a hard, and it's a hard, it's a hard, it's a hard And it's a hard rain's a-gonna fall Oh, who did you meet, my blue-eyed son? Who did you meet, my darling young one? I met a young child beside a dead pony I met a white man who walked a black dog I met a young woman whose body was burning I met a young girl, she gave me a rainbow I met one man who was wounded in love I met another man who was wounded with hatred And it's a hard, it's a hard, it's a hard, it's a hard It's a hard rain's a-gonna fall Oh, what'll you do now, my blue-eyed son? Oh, what'll you do now, my darling young one? I'm a-goin' back out 'fore the rain starts a-fallin' I'll walk to the depths of the deepest black forest Where the people are many and their hands are all empty Where the pellets of poison are flooding their waters Where the home in the valley meets the damp dirty prison Where the executioner's face is always well-hidden Where hunger is ugly, where souls are forgotten Where black is the color, where none is the number And I'll tell it and think it and speak it and breathe it And reflect it from the mountain so all souls can see it Then I'll stand on the ocean until I start sinkin' But I'll know my song well before I start singin' And it's a hard, it's a hard, it's a hard, it's a hard It's a hard rain's a-gonna fall","categories":[{"name":"others","slug":"others","permalink":"https://landau1994.github.io/categories/others/"}],"tags":[{"name":"art","slug":"art","permalink":"https://landau1994.github.io/tags/art/"}]},{"title":"pheatmap_advanced","slug":"pheatmap_advanced","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.842Z","comments":true,"path":"2020/04/20/pheatmap_advanced/","link":"","permalink":"https://landau1994.github.io/2020/04/20/pheatmap_advanced/","excerpt":"","text":"Case 1 The datasets were provided by data-to-viz library(tidyverse) library(pheatmap) library(ggplot2) library(viridis) library(kableExtra) ### dataset 1 data &lt;- read.table(\"https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/13_AdjacencyDirectedWeighted.csv\", header=TRUE) # show data data %&gt;% head(3) %&gt;% select(1:3) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = \"striped\", full_width = F) Africa East.Asia Europe Africa 3.142471 0.000000 2.107883 East Asia 0.000000 1.630997 0.601265 Europe 0.000000 0.000000 2.401476 ### the following function were embeded in pheatmap source code scale_rows = function(x){ m = apply(x, 1, mean, na.rm = T) s = apply(x, 1, sd, na.rm = T) return((x - m) / s) } scale_mat = function(mat, scale){ if(!(scale %in% c(\"none\", \"row\", \"column\"))){ stop(\"scale argument shoud take values: 'none', 'row' or 'column'\") } mat = switch(scale, none = mat, row = scale_rows(mat), column = t(scale_rows(t(mat)))) return(mat) } generate_breaks = function(x, n, center = F){ if(center){ m = max(abs(c(min(x, na.rm = T), max(x, na.rm = T)))) res = seq(-m, m, length.out = n + 1) } else{ res = seq(min(x, na.rm = T), max(x, na.rm = T), length.out = n + 1) } return(res) } data.plot &lt;- scale_mat(mat = data,scale = \"column\") breaks &lt;- generate_breaks(data.plot,n = 256,center = F) pheatmap::pheatmap(mat = data.plot, cluster_cols = F, cluster_rows = F, scale = \"column\",border_color = \"white\", color = viridis(n = 256, alpha = 1, begin = 0, end = 1, option = \"viridis\"), breaks = breaks) case 2 the codes were adapted from slowkow Sort dendrogram is very important set.seed(42) random_string &lt;- function(n) { substr(paste(sample(letters), collapse = \"\"), 1, n) } mat &lt;- matrix(rgamma(1000, shape = 1) * 5, ncol = 50) colnames(mat) &lt;- paste( rep(1:3, each = ncol(mat) / 3), replicate(ncol(mat), random_string(5)), sep = \"\" ) rownames(mat) &lt;- replicate(nrow(mat), random_string(3)) mat %&gt;% as.data.frame %&gt;% head(3) %&gt;% select(1:3) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = \"striped\", full_width = F) 1jrqxa 1pskvw 1ojvwz abv 9.6964789 9.172811 2.827695 nft 0.9020955 15.575853 4.328376 xha 2.6721643 3.127039 1.765077 split data into 3 groups, and increase the values in group1 col_groups &lt;- substr(colnames(mat), 1, 1) mat[,col_groups == \"1\"] &lt;- mat[,col_groups == \"1\"] * 5 making the heatmap # install.packages(\"pheatmap\", \"RColorBrewer\", \"viridis\") library(pheatmap) library(RColorBrewer) library(viridis) # Data frame with column annotations. mat_col &lt;- data.frame(group = col_groups) rownames(mat_col) &lt;- colnames(mat) # List with colors for each annotation. mat_colors &lt;- list(group = brewer.pal(3, \"Set1\")) names(mat_colors$group) &lt;- unique(col_groups) pheatmap( mat = mat, color = inferno(10), border_color = NA, show_colnames = FALSE, show_rownames = FALSE, annotation_col = mat_col, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 14, main = \"Default Heatmap\" ) The default color breaks in pheatmap are uniformly distributed across the range of the data. We can see that values in group 1 are larger than values in groups 2 and 3. However, we can’t distinguish different values within groups 2 and 3. ## ----uniform-color-breaks------------------------------------------------ mat_breaks &lt;- seq(min(mat), max(mat), length.out = 10) dat &lt;- data.frame(values = as.numeric(mat)) ## ----uniform-color-breaks-detail, fig.height=2, echo=FALSE--------------- dat_colors &lt;- data.frame( xmin = mat_breaks[1:(length(mat_breaks)-1)], xmax = mat_breaks[2:length(mat_breaks)], ymin = 0, ymax = max(density(mat, bw = \"SJ\")$y), fill = rev(inferno(length(mat_breaks) - 1)), stringsAsFactors = FALSE ) ggplot() + geom_rect( data = dat_colors, mapping = aes( xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill ) ) + geom_density( data = dat, mapping = aes(values), bw = \"SJ\", color = \"cyan\" ) + scale_fill_manual(values = dat_colors$fill) + cowplot::theme_cowplot()+ theme(legend.position = \"none\") + labs(title = \"Uniform breaks\") there are 6 data points greater than or equal to 100 are represented with 4 different colors. dat2 &lt;- as.data.frame(table(cut( mat, mat_breaks ))) dat2$fill &lt;- inferno(nrow(dat2)) ggplot() + geom_bar( data = dat2, mapping = aes(x = Var1, weight = Freq, fill = Var1), color = \"black\", size = 0.1 ) + coord_flip() + scale_fill_manual(values = dat2$fill) + cowplot::theme_cowplot()+ theme(legend.position = \"none\") + labs(y = \"data points\", x = \"breaks\", title = \"Number of data points per color\") If we reposition the breaks at the quantiles of the data, then each color will represent an equal proportion of the data: quantile_breaks &lt;- function(xs, n = 10) { breaks &lt;- quantile(xs, probs = seq(0, 1, length.out = n)) breaks[!duplicated(breaks)] } mat_breaks &lt;- quantile_breaks(mat, n = 11) lets see dat_colors &lt;- data.frame( xmin = mat_breaks[1:(length(mat_breaks)-1)], xmax = mat_breaks[2:length(mat_breaks)], ymin = 0, ymax = max(density(mat, bw = \"SJ\")$y), fill = rev(inferno(length(mat_breaks) - 1)), stringsAsFactors = FALSE ) ggplot() + geom_rect( data = dat_colors, mapping = aes( xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill ) ) + geom_density( data = dat, mapping = aes(values), bw = \"SJ\", color = \"cyan\" ) + scale_fill_manual(values = dat_colors$fill) + theme(legend.position = \"none\") + labs(title = \"Quantile breaks\") dat2 &lt;- as.data.frame(table(cut( mat, mat_breaks ))) dat2$fill &lt;- inferno(nrow(dat2)) ggplot() + geom_bar( data = dat2, mapping = aes(x = Var1, weight = Freq, fill = Var1), color = \"black\", size = 0.1 ) + coord_flip() + scale_fill_manual(values = dat2$fill) + theme(legend.position = \"none\") + labs(y = \"data points\", x = \"breaks\", title = \"Number of data points per color\") When we use quantile breaks in the heatmap, we can clearly see that group 1 values are much larger than values in groups 2 and 3, and we can also distinguish different values within groups 2 and 3: pheatmap( mat = mat, color = inferno(length(mat_breaks) - 1), breaks = mat_breaks, border_color = NA, show_colnames = FALSE, show_rownames = FALSE, annotation_col = mat_col, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 14, main = \"Quantile Color Scale\" ) We can also transform data pheatmap( mat = log10(mat), color = inferno(10), border_color = NA, show_colnames = FALSE, show_rownames = FALSE, annotation_col = mat_col, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 14, main = \"Log10 Transformed Values\" ) sort dendrograms library(dendsort) mat_cluster_cols &lt;- hclust(dist(t(mat))) sort_hclust &lt;- function(...) as.hclust(dendsort(as.dendrogram(...))) mat_cluster_cols &lt;- sort_hclust(mat_cluster_cols) plot(mat_cluster_cols, main = \"Sorted Dendrogram\", xlab = \"\", sub = \"\") sort Dendrogram heatmap mat_cluster_rows &lt;- sort_hclust(hclust(dist(mat))) pheatmap( mat = mat, color = inferno(length(mat_breaks) - 1), breaks = mat_breaks, border_color = NA, cluster_cols = mat_cluster_cols, cluster_rows = mat_cluster_rows, show_colnames = FALSE, show_rownames = FALSE, annotation_col = mat_col, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 14, main = \"Sorted Dendrograms\" ) change colnames angle pheatmap( mat = mat, color = inferno(length(mat_breaks) - 1), breaks = mat_breaks, border_color = NA, cluster_cols = mat_cluster_cols, cluster_rows = mat_cluster_rows, show_colnames = TRUE, show_rownames = FALSE, annotation_col = mat_col, angle_col = 90, fontsize_col = 8, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 10, main = \"Sorted Dendrograms\" )","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"}]},{"title":"Learn-igraph-Basic","slug":"Learnigraph-1-ManuNetworkDataBasic","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.824Z","comments":true,"path":"2020/04/20/Learnigraph-1-ManuNetworkDataBasic/","link":"","permalink":"https://landau1994.github.io/2020/04/20/Learnigraph-1-ManuNetworkDataBasic/","excerpt":"","text":"Learn-igraph系列是对Statistical Analysis of Network Data with R一书的学习笔记，介绍如何使用R进行网络数据分析，网络数据的处理主要是基于igraph包，可视化用的是ggnet 0. 基本概念 一些需要知道的基本概念； Network; Graph; Order of a graph; Size of a graph; directed graph; undirected graph; subgraph; 1. 创建igraph class 1.1 无向图 igraph包处理网络图的数据结构为igraph class, 最基础的创建方式如下： library(igraph) library(ggraph) library(ggnetwork) g &lt;- graph.formula(1-2,1-3,2-3,2-4,3-5,4-5,4-6,4-7,5-6,6-7) l &lt;- layout.auto(g) plot(g, layout=l, vertex.color=\"skyblue\") 该网络的基本信息可以通过如下方式获得： V(g) ###+ 7/7 vertices, named, from 27d8280: ###[1] 1 2 3 4 5 6 7 E(g) ###+ 10/10 edges from 27d8280 (vertex names): ###[1] 1--2 1--3 2--3 2--4 3--5 4--5 4--6 4--7 5--6 6--7 ###str(g) get.adjedgelist(g) # $`1` # + 2/10 edges from f3f6e64 (vertex names): # [1] 1--2 1--3 # # $`2` # + 3/10 edges from f3f6e64 (vertex names): # [1] 1--2 2--3 2--4 # # $`3` # + 3/10 edges from f3f6e64 (vertex names): # [1] 1--3 2--3 3--5 # # $`4` # + 4/10 edges from f3f6e64 (vertex names): # [1] 2--4 4--5 4--6 4--7 # # $`5` # + 3/10 edges from f3f6e64 (vertex names): # [1] 3--5 4--5 5--6 # # $`6` # + 3/10 edges from f3f6e64 (vertex names): # [1] 4--6 5--6 6--7 # # $`7` # + 2/10 edges from f3f6e64 (vertex names): # [1] 4--7 6--7 get.edgelist(g) # [,1] [,2] # [1,] \"1\" \"2\" # [2,] \"1\" \"3\" # [3,] \"2\" \"3\" # [4,] \"2\" \"4\" # [5,] \"3\" \"5\" # [6,] \"4\" \"5\" # [7,] \"4\" \"6\" # [8,] \"4\" \"7\" # [9,] \"5\" \"6\" # [10,] \"6\" \"7\" print(g, e=TRUE, v=TRUE) # IGRAPH f673c51 UN-- 7 10 -- # + attr: name (v/c) # + edges from f673c51 (vertex names): # [1] 1--2 1--3 2--3 2--4 3--5 4--5 4--6 4--7 5--6 6--7 get.adjacency(g) # 7 x 7 sparse Matrix of class \"dgCMatrix\" # 1 2 3 4 5 6 7 # 1 . 1 1 . . . . # 2 1 . 1 1 . . . # 3 1 1 . . 1 . . # 4 . 1 . . 1 1 1 # 5 . . 1 1 . 1 . # 6 . . . 1 1 . 1 # 7 . . . 1 . 1 . 1.2 有向图 同样的方法，也可以用来创建有向图； dg &lt;- graph.formula(1-+2,1-+3,2++3) op &lt;- par(mfrow=c(1,2)) plot(g, vertex.size=10,layout=l, vertex.color=\"skyblue\") plot(dg,vertex.size=10,vertex.color=\"skyblue\") par(op) 1.3 从邻接矩阵导入图； 我们选择一个神奇的数据Arecibo_message[https://en.wikipedia.org/wiki/Arecibo_message], 来说明,有时候,信息所对应的矩阵，可能就是一张图片，而不是一个图。 ###python command comes from ###https://codegolf.stackexchange.com/questions/182924/output-the-arecibo-message mat &lt;- reticulate::py_eval(\"''.join(bin(i)[3:]for i in b'`UP@JB`IDQKJjjd`@@@@@L@@Ah@@CP@@J`@@_@@@@@LNLLP@FPtXpu}}}|@@@@`@@`@@@A@@A~@@~@@@CCCcDA@DMCGM____@@@@HF@H@L@@PX@_`pO`A`@HA@HHF@`LLB@FHX@@s@@Xa`CC@`HD@``L@b@XAD@PDDA@PD@C@F@X@ck@A@P@BCx@DKi[@gI\\x7f\\\\NC\\\\@TGY@hOrAPXDFp@@@@@\\\\D@@zbjipAU@@B`@Gp@@\\x7fx@G@\\\\@X@LAh@lFXCLHhJHQHdPBJH@DHP@H@`@Dh@OOix')[1:]\") mat &lt;- as.integer(unlist(strsplit(mat,split = \"\"))) mat &lt;- matrix(data = mat,nrow = 23,ncol = 73) expand.matrix &lt;- function(A){ m &lt;- nrow(A) n &lt;- ncol(A) B &lt;- matrix(0,nrow = m, ncol = m) C &lt;- matrix(0,nrow = n, ncol = n) cbind(rbind(B,t(A)),rbind(A,C)) } g1 &lt;- graph_from_adjacency_matrix(expand.matrix(mat),mode = \"undirected\") plot(g1,vertex.size=10,edge.width=2,layout=layout.circle,vertex.color=\"coral\") 如果直接可视化这个图，我们什么也看不出来，然而，如果我们用将原数据视为栅格数据，那么，我们能看出这个数据的内涵是很丰富的 dat_long &lt;- reshape2::melt(mat) dat_long$value &lt;- as.factor(dat_long$value) colnames(dat_long) &lt;- c(\"V1\",\"V2\",\"value\") ### plot gg &lt;- ggplot(dat_long)+ geom_tile(aes(V1,V2,fill=value), color=\"#7f7f7f\")+ scale_fill_manual(values=c(\"black\", \"white\"))+ coord_equal()+ labs(x=NULL, y=NULL)+ scale_x_continuous(breaks = 1:6)+ scale_y_reverse(breaks=1:6)+ theme_bw()+ theme(panel.grid=element_blank())+ theme(panel.border=element_blank(), axis.ticks=element_blank(), axis.text = element_blank(), legend.position = \"none\") gg 1.4 从data.frame中创建图 需要两个输入，一个是边的信息，一个是节点的信息 ## A simple example with a couple of actors ## The typical case is that these tables are read in from files.... actors &lt;- data.frame(name=c(\"Alice\", \"Bob\", \"Cecil\", \"David\", \"Esmeralda\"), age=c(48,33,45,34,21), gender=c(\"F\",\"M\",\"F\",\"M\",\"F\")) relations &lt;- data.frame(from=c(\"Bob\", \"Cecil\", \"Cecil\", \"David\", \"David\", \"Esmeralda\"), to=c(\"Alice\", \"Bob\", \"Alice\", \"Alice\", \"Bob\", \"Alice\"), same.dept=c(FALSE,FALSE,TRUE,FALSE,FALSE,TRUE), friendship=c(4,5,5,2,1,1), advice=c(4,5,5,4,2,3)) g &lt;- graph_from_data_frame(relations, directed=TRUE, vertices=actors) ## The opposite operation as_data_frame(g, what=\"vertices\") ## name age gender ## Alice Alice 48 F ## Bob Bob 33 M ## Cecil Cecil 45 F ## David David 34 M ## Esmeralda Esmeralda 21 F as_data_frame(g, what=\"edges\") ## from to same.dept friendship advice ## 1 Bob Alice FALSE 4 4 ## 2 Cecil Bob FALSE 5 5 ## 3 Cecil Alice TRUE 5 5 ## 4 David Alice FALSE 2 4 ## 5 David Bob FALSE 1 2 ## 6 Esmeralda Alice TRUE 1 3 可视化， plot(g,vertex.size=10,vertex.color=\"skyblue\") 1.5 用预定义的函数生成 igraph里有很多带make的函数，是可以生成图的 # ls.str and lsf.str return an object of class \"ls_str\", basically the character vector of matching names (functions only for lsf.str), similarly to ls, with a print() method that calls str() on each object. ###head(lsf.str(\"package:igraph\")) grep(pattern = \"^make\",x=ls(\"package:igraph\"),value = T) ## [1] \"make_\" \"make_bipartite_graph\" ## [3] \"make_chordal_ring\" \"make_clusters\" ## [5] \"make_de_bruijn_graph\" \"make_directed_graph\" ## [7] \"make_ego_graph\" \"make_empty_graph\" ## [9] \"make_full_bipartite_graph\" \"make_full_citation_graph\" ## [11] \"make_full_graph\" \"make_graph\" ## [13] \"make_kautz_graph\" \"make_lattice\" ## [15] \"make_line_graph\" \"make_ring\" ## [17] \"make_star\" \"make_tree\" ## [19] \"make_undirected_graph\" 我们展示其中的一些图： g1 &lt;- make_tree(10, 2) g2 &lt;- make_bipartite_graph( rep(0:1,length=10), c(1:10)) g3 &lt;- make_star(10, mode = \"out\") g4 &lt;- make_star(10, mode = \"in\") op &lt;- par(mfrow=c(2,2)) plot(g1,vertex.size=20,vertex.color=\"skyblue\") plot(g2,vertex.size=20,vertex.color=\"skyblue\") plot(g3,vertex.size=20,vertex.color=\"skyblue\") plot(g4,vertex.size=20,vertex.color=\"skyblue\") par(op) 2. 基本操作 诱导子图 g &lt;- graph.formula(1-2,1-3,2-3,2-4,3-5,4-5,4-6,4-7,5-6,6-7) h &lt;- induced.subgraph(g,1:5) print(h) ## IGRAPH d91ee38 UN-- 5 6 -- ## + attr: name (v/c) ## + edges from d91ee38 (vertex names): ## [1] 1--2 1--3 2--3 2--4 3--5 4--5 Exclusion： h &lt;- g - vertices(c(6,7)) print(h) ## IGRAPH d923ec9 UN-- 5 6 -- ## + attr: name (v/c) ## + edges from d923ec9 (vertex names): ## [1] 1--2 1--3 2--3 2--4 3--5 4--5 Inclusion: h &lt;- h + vertices(c(6,7)) g &lt;- h + edges(c(4,6),c(4,7),c(5,6),c(6,7)) print(g) ## IGRAPH d928f5d UN-- 7 10 -- ## + attr: name (v/c) ## + edges from d928f5d (vertex names): ## [1] 1--2 1--3 2--3 2--4 3--5 4--5 4--6 4--7 5--6 6--7 union: h1 &lt;- h h2 &lt;- graph.formula(4-6,4-7,5-6,6-7) g &lt;- graph.union(h1,h2) print(g) ## IGRAPH d92f82f UN-- 7 10 -- ## + attr: name (v/c) ## + edges from d92f82f (vertex names): ## [1] 6--7 5--6 4--7 4--6 4--5 3--5 2--4 2--3 1--3 1--2 3. 查看/添加/修改 属性 首先创建一个示例的图， ## A simple example with a couple of actors ## The typical case is that these tables are read in from files.... actors &lt;- data.frame(name=c(\"Alice\", \"Bob\", \"Cecil\", \"David\", \"Esmeralda\"), age=c(48,33,45,34,21), gender=c(\"F\",\"M\",\"F\",\"M\",\"F\")) relations &lt;- data.frame(from=c(\"Bob\", \"Cecil\", \"Cecil\", \"David\", \"David\", \"Esmeralda\"), to=c(\"Alice\", \"Bob\", \"Alice\", \"Alice\", \"Bob\", \"Alice\"), same.dept=c(FALSE,FALSE,TRUE,FALSE,FALSE,TRUE), friendship=c(4,5,5,2,1,1), advice=c(4,5,5,4,2,3)) g &lt;- graph_from_data_frame(relations, directed=TRUE, vertices=actors) 我们可以通过$运算符来查看，添加，修改属性 ###check edge attribute names(edge_attr(g)) ###[1] \"same.dept\" \"friendship\" \"advice\" ###vertext names(vertex_attr(g)) ###[1] \"name\" \"age\" \"gender\" ###Vertex # list.vertex.attributes(g) # list.edge.attributes(g) V(g)$name ###[1] \"Alice\" \"Bob\" \"Cecil\" \"David\" \"Esmeralda\" edge_attr(g)$same.dept ###[1] FALSE FALSE TRUE FALSE FALSE TRUE edge_attr(g)$friendship ###[1] 4 5 5 2 1 1 可视化如下： ## A simple example with a couple of actors ## The typical case is that these tables are read in from files.... actors &lt;- data.frame(name=c(\"Alice\", \"Bob\", \"Cecil\", \"David\", \"Esmeralda\"), age=c(48,33,45,34,21), gender=c(\"F\",\"M\",\"F\",\"M\",\"F\")) relations &lt;- data.frame(from=c(\"Bob\", \"Cecil\", \"Cecil\", \"David\", \"David\", \"Esmeralda\"), to=c(\"Alice\", \"Bob\", \"Alice\", \"Alice\", \"Bob\", \"Alice\"), same.dept=c(FALSE,FALSE,TRUE,FALSE,FALSE,TRUE), friendship=c(4,5,5,2,1,1), advice=c(4,5,5,4,2,3)) g &lt;- graph_from_data_frame(relations, directed=TRUE, vertices=actors) V(g)$gender &lt;- plyr::revalue(x=V(g)$gender, replace=c(\"F\"=\"Female\",\"M\"=\"Male\")) V(g)$gender ## [1] \"Female\" \"Male\" \"Female\" \"Male\" \"Female\" g$name &lt;- \"Toy Graph\" set.seed(42) tmp.df &lt;- layout.graphopt(g) V(g)$color &lt;- plyr::revalue(x=V(g)$gender, replace=c(\"Female\"=\"skyblue\", \"Male\"=\"coral\")) plot(g,layout=tmp.df,vertex.size=20, vertex.color=V(g)$color,main=\"Toy Graph\") legend('right',legend=unique(V(g)$gender),pch=c(19,19),col = c(\"skyblue\",\"coral\")) set.seed(42) tmp.df &lt;- layout.graphopt(g) gg.net = ggnetwork(g, arrow.gap = 0.05, layout = tmp.df) ggplot(gg.net, aes(x = x, y = y, xend = xend, yend = yend)) + geom_edges(color = \"black\", alpha = 0.5, curvature = 0, arrow = arrow(length = unit(6, \"pt\"), type = \"closed\")) + geom_nodes(aes(color = gender), size = 10) + geom_nodetext(aes(label = name))+ scale_color_manual(values = c(\"skyblue\",\"coral\"))+ ggtitle(\"Toy Graph\")+ theme_blank() 4. 更多关于图的概念和术语 4.1 概念 下述概念不搬运书里的定义；忘记就查书。后面的章节会再用到这些概念，进行图的可视化与统计分析。 multi-graph simple-graph: 可以用is.simple()判定，可以用simplify()将multi-graph转换为simple-graph. neighbors degree: The degree of a vertex v defined as the number of edges incident on v; in-degree out-degree walk trails circuit &amp; cylce; reachable graph connected component of a graph strong connected weak connected distance/geodesic distance diameter 4.2 一些特殊的图 与第一节有重叠 complet graph clique regular graph tree forest root ancestor descendant parents, children k-star dirrected acyclic graph(DAG) bipartite graph g.bip &lt;- graph.formula(actor1:actor2:actor3, movie1:movie2, actor1:actor2 - movie1, actor2:actor3 - movie2) V(graph = g.bip)$type &lt;- grepl(pattern = \"^movie\",V(graph = g.bip)$name) V(g.bip)$category &lt;- ifelse(V(graph = g.bip)$type,\"Movie\",\"Actor\") V(g.bip)$category ## [1] \"Actor\" \"Actor\" \"Actor\" \"Movie\" \"Movie\" g &lt;- g.bip set.seed(42) ### using matrxi product to do layout rotate 3/2pi tmp.df &lt;- layout.bipartite(g) %*% matrix(data = c(0,-1,1,0),nrow = 2) gg.net = ggnetwork(g, arrow.gap = 0.05, layout = tmp.df) head(gg.net) ## x y name type category xend yend ## 1 0 0.0 actor1 FALSE Actor 0.9514929 0.2378732 ## 2 0 0.5 actor2 FALSE Actor 0.9514929 0.2621268 ## 3 0 0.5 actor2 FALSE Actor 0.9514929 0.7378732 ## 4 0 1.0 actor3 FALSE Actor 0.9514929 0.7621268 ## 5 0 0.0 actor1 FALSE Actor 0.0000000 0.0000000 ## 6 0 0.5 actor2 FALSE Actor 0.0000000 0.5000000 ggplot(gg.net, aes(x = x, y = y, xend = xend, yend = yend)) + geom_edges(color = \"black\", alpha = 0.5, curvature = 0 # ,arrow = arrow(length = unit(6, \"pt\"), # type = \"closed\") ) + geom_nodes(aes(color = category), size = 16) + geom_nodetext(aes(label = name))+ scale_color_manual(values = c(\"skyblue\",\"coral\"))+ ggtitle(\"bipartite graph example\")+ theme_blank() igraph自带的例子： # Random bipartite graph inc &lt;- matrix(sample(0:1, 50, replace = TRUE, prob=c(2,1)), 10, 5) g &lt;- graph_from_incidence_matrix(inc) plot(g, layout = layout_as_bipartite,vertex.size=20, vertex.color=c(\"skyblue\",\"coral\")[V(g)$type+1]) 附录：R配色 基本颜色： #### code provided by ####http://bc.bojanorama.pl/2013/04/r-color-reference-sheet/ m &lt;- matrix(1:660, 60, 11) kol &lt;- colors()[m] #op &lt;- par(mar=c(.1, .1, 2, .1)) image(1:11, 1:60, t(m), col=kol, axes=FALSE, ann=FALSE) txtcol &lt;- ifelse( apply(col2rgb(kol), 2, mean) &lt; 70, \"white\", \"black\") text( as.numeric(col(m)), as.numeric(row(m)), kol, cex=.8, col=txtcol) mtext(\"grDevices::colors\", 3, cex=2) 调色版 RColorBrewer::display.brewer.all() mtext(\"RColorBrewer\", 3, cex=2) 渐变色 library(RColorBrewer) library(colorRamps) library(viridis) ### manu rdylbu &lt;- colorRampPalette(rev(brewer.pal(n = 11, name =\"RdYlBu\"))) rdbu &lt;- colorRampPalette(rev(brewer.pal(n = 11, name =\"RdBu\"))) navy &lt;- colorRampPalette(c(\"navy\", \"white\", \"firebrick3\")) jet.colors &lt;- colorRampPalette(c(\"#00007F\", \"blue\", \"#007FFF\", \"cyan\", \"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\")) cold &lt;- colorRampPalette(c('#f7fcf0','#41b6c4','#253494','#081d58','#081d58')) warm &lt;- colorRampPalette(c('#ffffb2','#fecc5c','#e31a1c','#800026','#800026')) warmcold &lt;- colorRampPalette(c(rev(cold(21)), warm(20))) ### add manu with package function N &lt;- 100 # ramp length funnames &lt;- rev(c(\"manu::rdylbu\",\"manu::rdbu\",\"manu::navy\",\"manu::jet.colors\",\"manu::warmcold\", \"viridis::viridis\", \"grDevices::rainbow\", \"grDevices::heat.colors\", \"grDevices::terrain.colors\", \"grDevices::topo.colors\", \"grDevices::cm.colors\", \"colorRamps::blue2red\", \"colorRamps::blue2green\", \"colorRamps::green2red\", \"colorRamps::blue2yellow\", \"colorRamps::cyan2yellow\", \"colorRamps::magenta2green\", \"colorRamps::matlab.like\", \"colorRamps::matlab.like2\", \"colorRamps::primary.colors\", \"colorRamps::ygobb\")) spl &lt;- strsplit(funnames, \"::\") pkgs &lt;- sapply(spl, \"[\", 1) funs &lt;- sapply(spl, \"[\", 2) kolmat &lt;- sapply(funs, do.call, list(N)) mat &lt;- matrix( seq(1, length(kolmat)), nrow(kolmat), ncol(kolmat)) image(seq(1, nrow(mat)), seq(1, ncol(mat)), mat, col=kolmat, axes=FALSE, ann=FALSE) text( nrow(mat)/2, seq(1, ncol(mat)), funnames) mtext(\"Color Ramps function\", 3, cex=2)","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"Graph","slug":"Graph","permalink":"https://landau1994.github.io/tags/Graph/"},{"name":"Network","slug":"Network","permalink":"https://landau1994.github.io/tags/Network/"}]},{"title":"LearnSeurat_CITE_seq","slug":"LearnSeurat_CITEseq","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.823Z","comments":true,"path":"2020/04/20/LearnSeurat_CITEseq/","link":"","permalink":"https://landau1994.github.io/2020/04/20/LearnSeurat_CITEseq/","excerpt":"","text":"前言 CITE-seq是Rahul Satija和Peter Smibert两个组合作开发的在单细胞精度，同时测量细胞表面蛋白表达和转录组的技术。该技术原理如下： CITE-seq原理图，用抗体来源标签，实现细胞表面蛋白定量 该项技术可以用于免疫相关的单细胞测序研究中。例如, 有研究表明称： 他们在人和小鼠非小细胞肺癌中进行单细胞RNA测序，鉴定了一群DC，并将其命名为“富含免疫调节分子的成熟DC”（mregDC），这是由于它们共表达了免疫调节基因（Cd274，Pdcd1lg2和Cd200）和成熟基因（Cd40，Ccr7和Il12b）。 这段中文报道来自小柯机器人 Rahul Satija组开发的软件Seurat有一个教程，可以分析CITE-seq数据。本文基于该教程对该类型数据的分析进行说明。 数据载入 首先我们需要获取数据，该数据集取样为8617个脐带血单核细胞，包含了表达谱数据和11个抗体来源标签数据（antibody-derived tags ,ADT)。 library(Seurat) library(SeuratData) library(ggplot2) library(patchwork) ### AvailableData() check avaliable data: we choose cbmc ### InstallData('cbmc') library(cbmc.SeuratData) data(\"cbmc\") ### expression matrix cbmc[[\"RNA\"]]@counts[1:10,1:10] ## 10 x 10 sparse Matrix of class \"dgCMatrix\" ## ## A1BG . . . . . . . . . . ## A1BG-AS1 . . . . . . . . . . ## A1CF . . . . . . . . . . ## A2M . . . . . . . . . . ## A2M-AS1 . . . . . . . 1 . . ## A2ML1 . . . . . . . . . . ## A4GALT . . . . . . . . . . ## A4GNT . . . . . . . . . . ## AAAS . . . . . . . . . 1 ## AACS . . . . . . . . . . ### ADT count matrix ### Actually there are just 10 surface protein cbmc[[\"ADT\"]]@counts[1:10,1:10] ## 10 x 10 sparse Matrix of class \"dgCMatrix\" ## ## CD3 60 52 89 55 63 82 53 42 103 56 ## CD4 72 49 112 66 80 78 63 59 122 70 ## CD8 76 59 61 56 94 57 61 55 64 80 ## CD45RA 575 3943 682 378 644 479 487 472 540 535 ## CD56 64 68 87 58 104 44 64 48 136 91 ## CD16 161 107 117 82 168 92 77 99 235 131 ## CD11c 77 65 65 44 92 63 70 75 106 69 ## CD14 206 129 169 136 164 122 112 111 206 204 ## CD19 70 665 79 49 81 44 60 58 61 107 ## CD34 179 79 78 83 152 103 79 86 144 193 ### show default assay DefaultAssay(cbmc) ## [1] \"RNA\" 根据基因表达进行聚类 注意在默认参数的情况下，下述操作时对Default Assay进行的 # standard log-normalization cbmc &lt;- NormalizeData(cbmc) # choose ~1k variable features cbmc &lt;- FindVariableFeatures(cbmc) # standard scaling (no regression) cbmc &lt;- ScaleData(cbmc) # Run PCA, select 13 PCs for tSNE visualization and graph-based clustering cbmc &lt;- RunPCA(cbmc, verbose = FALSE) 下面的图是根据标准差来选择PCs ElbowPlot(cbmc, ndims = 50) 聚类和t-SNE降维 cbmc &lt;- FindNeighbors(cbmc, dims = 1:25) cbmc &lt;- FindClusters(cbmc, resolution = 0.8) ## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck ## ## Number of nodes: 8617 ## Number of edges: 347548 ## ## Running Louvain algorithm... ## Maximum modularity in 10 random starts: 0.8592 ## Number of communities: 19 ## Elapsed time: 3 seconds cbmc &lt;- RunTSNE(cbmc, dims = 1:25, method = \"FIt-SNE\") # Find the markers that define each cluster, and use these to annotate the clusters, we use # max.cells.per.ident to speed up the process cbmc.rna.markers &lt;- FindAllMarkers(cbmc, max.cells.per.ident = 100, min.diff.pct = 0.3, only.pos = TRUE) # Note, for simplicity we are merging two CD14+ Monocyte clusters (that differ in expression of # HLA-DR genes) and NK clusters (that differ in cell cycle stage) new.cluster.ids &lt;- c(\"Memory CD4 T\", \"CD14+ Mono\", \"Naive CD4 T\", \"NK\", \"CD14+ Mono\", \"Mouse\", \"B\", \"CD8 T\", \"CD16+ Mono\", \"T/Mono doublets\", \"NK\", \"CD34+\", \"Multiplets\", \"Mouse\", \"Eryth\", \"Mk\", \"Mouse\", \"DC\", \"pDCs\") names(new.cluster.ids) &lt;- levels(cbmc) cbmc &lt;- RenameIdents(cbmc, new.cluster.ids) 我们看看聚类结果： DimPlot(cbmc, label = TRUE) + NoLegend() ## Warning: Using `as.character()` on a quosure is deprecated as of rlang 0.3.0. ## Please use `as_label()` or `as_name()` instead. ## This warning is displayed once per session. 蛋白表达数据处理 Seurat3的assay实现多个组学或者模态的数据的存储和获取。 代码里的注释来自Seurat官网。 # Now we can repeat the preprocessing (normalization and scaling) steps that we typically run # with RNA, but modifying the 'assay' argument. For CITE-seq data, we do not recommend typical # LogNormalization. Instead, we use a centered log-ratio (CLR) normalization, computed # independently for each feature. This is a slightly improved procedure from the original # publication, and we will release more advanced versions of CITE-seq normalizations soon. cbmc &lt;- NormalizeData(cbmc, assay = \"ADT\", normalization.method = \"CLR\") cbmc &lt;- ScaleData(cbmc, assay = \"ADT\") 在RNA表达谱的降维Embedding中同时展示展示蛋白表达水平和基因表达水平： 散点图：横纵轴为降维的坐标： # in this plot, protein (ADT) levels are on top, and RNA levels are on the bottom FeaturePlot(cbmc, features = c(\"adt_CD3\", \"adt_CD11c\", \"adt_CD8\", \"adt_CD16\", \"CD3E\", \"ITGAX\", \"CD8A\", \"FCGR3A\"), min.cutoff = \"q05\", max.cutoff = \"q95\", ncol = 2) Ridge Plot: RidgePlot(cbmc, features = c(\"adt_CD3\", \"adt_CD8\", \"CD3E\",\"CD8A\"),ncol = 2) 散点图：横纵轴为表达量；这个类似于FACS # Draw ADT scatter plots (like biaxial plots for FACS). Note that you can even 'gate' cells if # desired by using HoverLocator and FeatureLocator FeatureScatter(cbmc, feature1 = \"adt_CD19\", feature2 = \"adt_CD3\") 我们也可以看看蛋白表达和基因表达的关系： # view relationship between protein and RNA FeatureScatter(cbmc, feature1 = \"adt_CD3\", feature2 = \"CD3E\") 我们可以看看T细胞： # Let's plot CD4 vs CD8 levels in T cells tcells &lt;- subset(cbmc, idents = c(\"Naive CD4 T\", \"Memory CD4 T\", \"CD8 T\")) FeatureScatter(tcells, feature1 = \"adt_CD4\", feature2 = \"adt_CD8\") 选没有标准化的原始数据我们看看，坐标轴的间距太大，会有misleading # # Let's look at the raw (non-normalized) ADT counts. You can see the values are quite high, # particularly in comparison to RNA values. This is due to the significantly higher protein copy # number in cells, which significantly reduces 'drop-out' in ADT data FeatureScatter(tcells, feature1 = \"adt_CD4\", feature2 = \"adt_CD8\", slot = \"counts\") 这里还是可以观察到dropouts现象的，据原作者说： &gt; If you look a bit more closely, you’ll see that our CD8 T cell cluster is enriched for CD8 T cells, but still contains many CD4+ CD8- T cells. This is because Naive CD4 and CD8 T cells are quite similar transcriptomically, and the RNA dropout levels for CD4 and CD8 are quite high. This demonstrates the challenge of defining subtle immune cell differences from scRNA-seq data alone. 画热图，Seurat3 加了 downsample的功能。 # Downsample the clusters to a maximum of 300 cells each (makes the heatmap easier to see for small clusters) cbmc.small &lt;- subset(cbmc, downsample = 300) # Find protein markers for all clusters, and draw a heatmap adt.markers &lt;- rownames(cbmc.small[[\"ADT\"]]@counts) 我们可以看看Seurat热图的默认配色（三个冒号可以看更为底层的函数）, 个人觉得并不好看。 # using code from RColorBrewer to demo the palette n = 200 par(mfrow=c(3,1)) image( 1:n, 1, as.matrix(1:n), col = Seurat:::PurpleAndYellow(k=n), xlab = \"PurpleAndYellow n\", ylab = \"\", xaxt = \"n\", yaxt = \"n\", bty = \"n\" ) image( 1:n, 1, as.matrix(1:n), col = colorRampPalette(c(\"navy\", \"white\", \"firebrick3\"))(n), xlab = \"NavyWhite3Firebrick3 n\", ylab = \"\", xaxt = \"n\", yaxt = \"n\", bty = \"n\" ) image( 1:n, 1, as.matrix(1:n), col = colorRampPalette(RColorBrewer::brewer.pal(11,\"RdBu\"))(n), xlab = \"RdBu n\", ylab = \"\", xaxt = \"n\", yaxt = \"n\", bty = \"n\" ) 把默认配色换掉,见 mypal &lt;- rev(colorRampPalette(RColorBrewer::brewer.pal(11,\"RdBu\"))(256)) #mypal2 &lt;- colorRampPalette(c(\"navy\", \"white\", \"firebrick3\"))(256) DoHeatmap(cbmc.small, features = unique(adt.markers), assay = \"ADT\", angle = 90,size = 3)+ scale_fill_gradientn(colors = mypal) ## Scale for 'fill' is already present. Adding another scale for 'fill', which ## will replace the existing scale. 去除细胞杂质， # You can see that our unknown cells co-express both myeloid and lymphoid markers (true at the # RNA level as well). They are likely cell clumps (multiplets) that should be discarded. We'll # remove the mouse cells now as well cbmc &lt;- subset(cbmc, idents = c(\"Multiplets\", \"Mouse\"), invert = TRUE) 直接根据蛋白质表达水平进行聚类 # Because we're going to be working with the ADT data extensively, we're going to switch the # default assay to the 'CITE' assay. This will cause all functions to use ADT data by default, # rather than requiring us to specify it each time DefaultAssay(cbmc) &lt;- \"ADT\" cbmc &lt;- RunPCA(cbmc, features = rownames(cbmc), reduction.name = \"pca_adt\", reduction.key = \"pca_adt_\", verbose = FALSE) 再来看PCA(其实这里算是degenrate到线性组合了) DimPlot(cbmc, reduction = \"pca_adt\") # Since we only have 10 markers, instead of doing PCA, we'll just use a standard euclidean # distance matrix here. Also, this provides a good opportunity to demonstrate how to do # visualization and clustering using a custom distance matrix in Seurat adt.data &lt;- GetAssayData(cbmc, slot = \"data\") adt.dist &lt;- dist(t(adt.data)) # Before we recluster the data on ADT levels, we'll stash the RNA cluster IDs for later cbmc[[\"rnaClusterID\"]] &lt;- Idents(cbmc) # Now, we rerun tSNE using our distance matrix defined only on ADT (protein) levels. cbmc[[\"tsne_adt\"]] &lt;- RunTSNE(adt.dist, assay = \"ADT\", reduction.key = \"adtTSNE_\") cbmc[[\"adt_snn\"]] &lt;- FindNeighbors(adt.dist)$snn cbmc &lt;- FindClusters(cbmc, resolution = 0.2, graph.name = \"adt_snn\") ## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck ## ## Number of nodes: 7895 ## Number of edges: 258146 ## ## Running Louvain algorithm... ## Maximum modularity in 10 random starts: 0.9491 ## Number of communities: 11 ## Elapsed time: 2 seconds # We can compare the RNA and protein clustering, and use this to annotate the protein clustering # (we could also of course use FindMarkers) clustering.table &lt;- table(Idents(cbmc), cbmc$rnaClusterID) clustering.table ## ## Memory CD4 T CD14+ Mono Naive CD4 T NK B CD8 T CD16+ Mono ## 0 1754 0 1217 29 0 27 0 ## 1 0 2189 0 4 0 0 30 ## 2 3 0 2 890 3 1 0 ## 3 0 4 0 2 319 0 2 ## 4 24 0 18 4 1 243 0 ## 5 1 27 4 157 2 2 10 ## 6 4 5 0 1 0 0 0 ## 7 4 59 4 0 0 0 9 ## 8 0 9 0 2 0 0 179 ## 9 0 0 1 0 0 0 0 ## 10 1 0 2 0 25 0 0 ## ## T/Mono doublets CD34+ Eryth Mk DC pDCs ## 0 5 2 4 24 1 2 ## 1 1 1 5 25 55 0 ## 2 0 1 3 7 2 1 ## 3 0 2 2 3 0 0 ## 4 0 0 1 2 0 0 ## 5 56 0 9 16 6 2 ## 6 1 113 81 16 5 0 ## 7 117 0 0 2 0 1 ## 8 0 0 0 1 0 0 ## 9 0 0 0 0 1 43 ## 10 2 0 0 0 0 0 下面这个embeding 还是根据ADT来的（不过只要marker连续，只有10个也没有关系？） new.cluster.ids &lt;- c(\"CD4 T\", \"CD14+ Mono\", \"NK\", \"B\", \"CD8 T\", \"NK\", \"CD34+\", \"T/Mono doublets\", \"CD16+ Mono\", \"pDCs\", \"B\") names(new.cluster.ids) &lt;- levels(cbmc) cbmc &lt;- RenameIdents(cbmc, new.cluster.ids) tsne_rnaClusters &lt;- DimPlot(cbmc, reduction = \"tsne_adt\", group.by = \"rnaClusterID\") + NoLegend() tsne_rnaClusters &lt;- tsne_rnaClusters + ggtitle(\"Clustering based on scRNA-seq\") + theme(plot.title = element_text(hjust = 0.5)) tsne_rnaClusters &lt;- LabelClusters(plot = tsne_rnaClusters, id = \"rnaClusterID\", size = 4) tsne_adtClusters &lt;- DimPlot(cbmc, reduction = \"tsne_adt\", pt.size = 0.5) + NoLegend() tsne_adtClusters &lt;- tsne_adtClusters + ggtitle(\"Clustering based on ADT signal\") + theme(plot.title = element_text(hjust = 0.5)) tsne_adtClusters &lt;- LabelClusters(plot = tsne_adtClusters, id = \"ident\", size = 4) # Note: for this comparison, both the RNA and protein clustering are visualized on a tSNE # generated using the ADT distance matrix. wrap_plots(list(tsne_rnaClusters, tsne_adtClusters), ncol = 2) 对于该结果，作者是这么解释的： The ADT-based clustering yields similar results, but with a few differences + Clustering is improved for CD4/CD8 T cell populations, based on the robust ADT data for + CD4, CD8, CD14, and CD45RA + However, some clusters for which the ADT data does not contain good distinguishing protein markers (i.e. Mk/Ery/DC) lose separation You can verify this using FindMarkers at the RNA level, as well 更多 pbmc 10k的细胞也提供了CITE-seq的多模态数据，具体细节，请看Seurat官方教程。","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"},{"name":"sc-seq","slug":"sc-seq","permalink":"https://landau1994.github.io/tags/sc-seq/"}]},{"title":"Combine pheatmap","slug":"combine_pheatmap","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.832Z","comments":true,"path":"2020/04/20/combine_pheatmap/","link":"","permalink":"https://landau1994.github.io/2020/04/20/combine_pheatmap/","excerpt":"","text":"Talk is cheap, this is code: library(grid) library(gridExtra) library(pheatmap) library(ggplot2) library(colormap) items=names(colormaps) plot_list=list() for (a in items[1:8]){ x= pheatmap(volcano, cluster_rows = F, cluster_cols = F, main = a, height = 3, width = 3, border_color = NA, color = colormap_pal(colormap = colormaps[[a]])(100),silent = T) plot_list[[a]] = x[[4]] ##to save each plot into a list. note the [[4]] } cowplot::plot_grid(plotlist = plot_list[1:8],ncol = 2,nrow = 4) test equation: ;","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"}]},{"title":"rmarkdown-test","slug":"rmarkdown-test","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.862Z","comments":true,"path":"2020/04/20/rmarkdown-test/","link":"","permalink":"https://landau1994.github.io/2020/04/20/rmarkdown-test/","excerpt":"","text":"This post test blogdown, reference this repo This post generate by blogdown::new_post(title = “Rmarkdown_test”,ext=“.Rmd”) R Markdown This is an R Markdown document. Please note this page was not rendered using the rmarkdown package or Pandoc. The R Markdown document is compiled to Markdown through knitr, and the Markdown document is rendered to HTML through Hexo’s Markdown renderer. You can embed an R code chunk like this: summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit &lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932 Including Plots You can also embed R plots: par(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'), col = c('#0292D8', '#F7EA39', '#C4B632'), init.angle = -50, border = NA )","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"}]},{"title":"阿里数学竞赛预赛2020年的一道概率题学习","slug":"阿里数学竞赛预赛2020年的一道概率题学习","date":"2020-04-18T07:41:15.000Z","updated":"2025-01-11T17:16:31.883Z","comments":true,"path":"2020/04/18/阿里数学竞赛预赛2020年的一道概率题学习/","link":"","permalink":"https://landau1994.github.io/2020/04/18/%E9%98%BF%E9%87%8C%E6%95%B0%E5%AD%A6%E7%AB%9E%E8%B5%9B%E9%A2%84%E8%B5%9B2020%E5%B9%B4%E7%9A%84%E4%B8%80%E9%81%93%E6%A6%82%E7%8E%87%E9%A2%98%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"阿里巴巴全球数学竞赛是阿里办的一项数学竞赛。出题范围和往届预选赛题目可以在其官网下查看 。 2020年的预选赛，有道题目是这样的： 考虑一个由从左道右的n个小方格组成的的区域，从左到右依次在每个小方格种一棵树，一共种棵。树的种类只有两种：胡杨和樟子松。假设在第一个小方格种植的数是胡杨的概率是r。后续的种树的规则为：如果前一个小方格种的是胡杨，则本格种胡杨的概率为;如果前一个小方格种的是樟子松，则本格种樟子松的概率为 假设。是否存在使得,在第个小方格种植的树是胡杨的概率都等于一个跟无关的常数？如果存在，请给出，满足的关系；如果不存在，请说明理由。 假设。假设我们观察到第2019个小方格里种植的树是胡杨，但我们观察不到其它小方格里种植的是哪种树。请问第一个小方格里种植的树是胡杨的概率是多少？ 这道题考察的其实是马尔科夫链相关的知识，第一问是说什么条件下，题目给定的马尔可夫链在第二步就能达到平稳分布；第二问是从第n步逆推最起始的概率。当然，直接的工具是条件概率和全概率公式。 解答（根据官方答案，有改动）： 首先，我们需要将文字信息转换为便于处理的数学记号，记“E”表示胡杨，“S” 表示樟子松。令表示种在第个方格的树的种类(根据题意，这是一个随机变量)，令,则由题设，有： 且由全概率公式 令, 我们有： 若成立，则, 整理可得 因为，所以当时， 题目给的不满足(a)中的条件，所以我们需要求出一般条件下的情况。 令,则需要求的概率是： (a)中已经求出了得递推式, 仿照(a)的步骤，我们可以求出 解上述递推式，可得： 类似的，由(2)可得 所以有： 将给入条件带入(其实不用计算，因为），可得","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"},{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"Probability","slug":"Probability","permalink":"https://landau1994.github.io/tags/Probability/"}]},{"title":"机器学习在生物学有应用吗","slug":"机器学习在生物学有应用吗","date":"2020-04-15T16:00:00.000Z","updated":"2025-01-11T17:16:31.875Z","comments":true,"path":"2020/04/16/机器学习在生物学有应用吗/","link":"","permalink":"https://landau1994.github.io/2020/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9C%A8%E7%94%9F%E7%89%A9%E5%AD%A6%E6%9C%89%E5%BA%94%E7%94%A8%E5%90%97/","excerpt":"","text":"说明：转自站长知乎回答。 当然有应用，而且是很广泛的应用，周志华老师的《机器学习》中的第1章的绪论的1.6节应用现状中这样写到： 机器学习还为许多交叉学科提供了重要的技术支撑。例如，“生物信息学”试图利用信息技术来研究生命现象和规律，而基因组计划的实施和基因药物的美好前景让人们为之心潮澎湃。生物信息学研究涉及从“生命现象”到“规律发现”的整个过程，其间必然包括数据获取、数据管理、数据分析、仿真实验等环节，而“数据分析”恰是机器学习技术的舞台，各种机器学习技术已经在这个舞台上大放异彩。 在本回答中，我们将结合具体的案例，分三部分论述机器学习（包含深度学习）在生物研究的应用。第一部分，我们先对机器学习在生命科学领域的研究做一个全景的介绍。第二部分，我们再结合具体案例如何应用机器学习推动相关生物研究，以及相关生物研究中出现的问题如何催生新的机器学习算法。第三部分我们将进行回顾和反思，探讨未来的机器学习将如何更好的推动生物研究。 在正式讨论之前，我们借用周志华老师的《机器学习》一书来对机器学习下一个描述性的定义： 机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经 验来玫善系统自身的性能在计算机系统中，\"经验\"通常以\"数据\"形式存 在，因此机器学习所研究的主要内容，是关于在计算机上从数据中产生\"模 型\" (model) 的算法，即\"学习算法\" (learning algorithm). 有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型;在面对新的情况时(例如看到一个没剖开的西瓜)，模型会给我们提供相应的判断(例如好瓜) .如果说 计算机科学是研究关于\"算法\"的学问，那么类似的，可以说机器学习是研究 关于\"学习算法\"的学问. 在下面的论述中，我们将从概况以及具体的生物场景看到这个定义还是很合理的。 本回答假定读者已经了解过一些机器学习和生物的概念。 一. 机器学习在生物研究中的应用概览 1. 基本流程 一般来说，在生物研究中，一项应用机器学习中的算法的研究可以分为如下五步流程： 1. 设计实验，收集数据 2. 数据清洗 3. 特征选择 4. 模型构建 5. 模型评估 如下面的流程图，来自Deep learning for computational biology所示 2. 有监督学习与无监督学习 模型构建的方法，按照研究的问题可以分为，有监督和无监督的。 有监督学习是指一类针对有标签的数据来预测无标签数据的标签的算法，如果我们把连续数值变量也视为标签的话，那么回归也是有监督学习。而无监督学习是指一类针对无标签的数据进行规律发现的算法。除此之外，也有半监督学习，即在 一个典型的有监督的问题是分类问题，一个典型的无监督问题是聚类问题。在这个回答我们将介绍这两类问题的具体的场景。下图来自综述Deep learning for computational biology 3. 三类基本数据 大多数生物研究主要对序列数据，矩阵或者张量数据，成像数据这三类基本的数据上进行机器学习算法的应用。 3.1 序列数据 最基本的生物数据之一，通常为DNA序列，RNA序列，蛋白质序列。 在人类基因组计划早期的问题是，如何快速进行基因组注释，该问题可以表示如下,图片来自Machine learning applications in genetics and genomics： 基因组注释是一个有监督或者半监督的问题，因为一段序列是不是基因可以通过EST(表达序列标签)来判定，其他特征可以通过一些生化或者分子实验来标定，所以我们可以得到数据标签。 此外，序列数据更为常见的是要分析一些分子演化的问题，例如最近大家关注的新冠病毒的分子演化。这方面的案例和相关讨论可见：剑桥大学研究称新冠病毒分三个变种，A 类病毒为「爆发根源」，更多发现于美国和澳洲，这一结论靠谱吗？ 这是一个无监督的问题，例如，我们其实并不知道新冠病毒可以分为几个变种，我们需要在数据中看出它能分成几类，然后再通过其他证据证明这种分类是合理的。 3.2 矩阵数据 芯片技术和后续的高通量测序技术带来了很多种矩阵数据,这类矩阵通常是对某类型生物特征（基因，蛋白，表观修饰，染色质互作）的丰度汇总而成的。最典型矩阵数据是基因表达谱，基因表达谱矩阵可以通过RNA-seq数据进行比对后的转录本定量产生，基本流程和常见分析策略如下（图片来自Enter the Matrix: Factorization Uncovers Knowledge from Omics)： 这类数据的分析通常是无监督或者半监督的，我们通常想通过矩阵数据去发现一些可用于诊断的分子marker。 3.3 成像数据 从数据存储的本质上讲，成像数据还是矩阵数据（不过考虑到多通道图像的存在，称为张量数据更为贴切），但是内涵上是不同的，成像数据表达更多的是生物体内部空间位置（还有形状或者结构）的信息。例如，一张蛋白亚细胞定位的图像，可以反映某标记的感兴趣的蛋白质位于细胞中的什么位置，如果我们有很多这样的图片，明智的方法是先标记一部分数据，训练一个卷积神经网络，然后再对剩下的图片进行预测，如下图所示，： 图片来自综述2 4. 关于深度学习及其在生物研究中的应用 深度学习到底是什么呢，按照Yann LeCun, Yoshua Bengio，Geoffrey Hinton三位专家合写的综述的定义： &gt; Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. With the composition of enough such transformations, very complex functions can be learned For. 拙译为：深度学习方法是一种基于多种层级进行表示的表示学习方法。其表示能力是通过组合简单的非线性的模块实现的。每一个小模块都可以把第一层的原始数据转换为更稍微抽像的特征。通过足够多的这样的转换进行组合，可以学习到非常复杂的函数(功能)。 目前，在基因组学的不同层级，均有深度学习的应用案例： 图片来自A primer on deep learning in genomics,想了解更多，请阅读这篇文章。 5. 常见不同机器算法的实现软件 针对不同的学习算法，在R中的可用的机器学习包如下，图片来自Machine learning for Big Data analytics in plants: python上的常用相关软件包如下.图片来自Best Python Libraries for Machine Learning and Deep Learning： Best Python Libraries for Machine Learning and Deep Learning 二. 机器学习在生物研究中的应用案例 1. 基于机器学习的差异表达网络分析 生物学家很感兴趣的一个问题是，不同条件下哪些基因表达会发生变化，这样他们可以深入研究其中的分子机制，进而找到一些可以找到一些增强或者减弱他们想要研究表型的靶点。 常见的思路是做假定基因表达服从一个分布，然后根据这个假设构建统计量，计算统计显著性，设置cutoff来筛选发生差异表达的基因。 但是这样做可能存在问题，例如cutoff为 ,那些被判定为统计不显著的基因就真的和表型相关的差异表达基因吗？有无更好的替代方法？ 文献Machine Learning–Based Differential Network Analysis: A Study of Stress-Responsive Transcriptomes in Arabidopsis提供了一种思路。假定我们对于模式植物拟南芥响应各种胁迫条件感兴趣，我们可以用基于机器学习的策略对于之前的差异表达方法做出改进，分为如下步骤： 1）数据收集，清洗以及正负样本构建： 收集不同胁迫条件下的基因表达谱(基因芯片数据），进行预处理和标准化，收集之前报导过的和相关的基因作为正样本，将表达谱中不发生变化的基因作为负样本，剩下的基因的表达谱作为无标签样本； 2）特征提取： 通过共表达网络的策略从表达谱中提取特征。在构建共表达网络的之后，采用随机森林的方法把未标签的样本中的“noninformative” genes（不表达，持续表达，与胁迫无关的基因)过滤掉了，减少了共表达网络构建的无用信息。计算每个基因在共表达网络中的PageRank等统计量，作为特征； 3）模型构建： 根据2）中计算的特征，从分好的正负样本中，再次随机森林构建模型； 4）模型评估 和limma等方法比较； 5）模型预测，并进行验证 将训练好的模型应用于无标记的基因上，预测出和新的胁迫相关的基因，并通过TDNA插入实验验证。 上述步骤可以概括如下， 图片来自Machine learning for Big Data analytics in plants 2. 干细胞分化路径重构与流形学习 案例1是有监督学习的例子，我们接下来看无监督学习的案例。 生物学有一个很著名的模型叫做waddington landscape，该模型描述了干细胞在分化过程可以类比于一个有质量的小球自发沿着山坡从山顶滚下山谷的过程，不同的山底表示了细胞的终末分化状态，而不同的分支点的存在则是细胞命运决定的节点。这个运动的过程中，细胞的基因表达会发生变化，如果我们假定基因表达“相近”的细胞在路径上也挨得很近，那么在基因表达的高维数据中应该嵌入了低维的分化路径，则我们能通过流形学习的技术从基因表达数据中重构出分化的路径，如下图所示， 图片来自Manifold learning-based methods for analyzing single-cell RNA-sequencing data 具体来说，流形学习是如何进行的呢？可以结合如下的案例进行理解。现在有两个变量组成的一个数据集，我们将其画在直角坐标系中，可以看出样本点中存在一个螺旋的趋势，也就是说这个二维数据集中似乎嵌入了一个一维流形。如何通过计算的方式将其找出来呢。直觉告诉我们，必须先计算每两个样本点之间距离。我们在样本点之间的距离之后呢，会发现这个距离里样本点的局部邻近关系和整体邻近关系混淆在了一起，这个时候，我们可以使用叫做核函数的技巧，将距离转换为邻近关系。得到局部的距离之后呢，我们把相邻的点连起来，这样便可以最终得到那个样本点中包含的螺旋的一维流形了。 图片来自Manifold learning-based methods for analyzing single-cell RNA-sequencing data 附注：粗浅的来说，所谓流形就是一个局部看起来像是欧几里得空间的拓扑空间。每个属于这个n维流形的点的邻域都可以与一个n维欧氏空间建立一一映射的关系。（更为严谨的定义请看拓扑学教材）。流形学习一般是用来学习高维数据内部的低维结构。最基础流形学习算法是PCA。 以最近发表的一种同时实现生物高维数据可视化和路径推断的算法PHATE为例，该算法的流程如下，（图片来自原文献）： 该算法的基本流程和其他的流形学习方法大致类似，但是他们的创新之处是引入了随机游走，计算扩散概率，以及最终讲欧式距离转化为信息距离来进行embeding。 篇幅所限，我们不会在这里谈很多该算法的计算细节，感兴趣的读者可看知乎上中文的介绍：Nat. Biotechnol | PHATE：高维生物数据的可视化方法，或者直接阅读原始文献。 3.冷冻电镜中的图像处理 这部分，笔者不是专家，只是为了拓展视野在里记录。 基础知识推荐大家看下coursera上面的加州理工的冷冻电镜的课程，尤其是Tomography那一节。 关于冷冻电镜的背景大家请看 为什么冷冻电镜 (Cryo-EM) 去年突然火了？是有什么技术突破吗？ 以及什么是2015年最受科学界关注的新技术？ 当然还有nature的新闻稿 根据nature这篇新闻稿，冷冻电镜取得突破性进展主要要归功于两个人：Richard Henderson和Sjors Scheres还有他们所在的实验室：UK Medical Research Council Laboratory of Molecular Biology (LMB)。Richard Henderson和他的同事 Nigel Unwin 在1975年的一片文章（Molecular structure determination by electron microscopy of unstained crystalline specimens）中为冷冻电镜技术做出了奠基性的贡献。而新发展的直接电子探测器使得对大分子的高速动态成像成为可能。新技术带来的大数据使得Sjors Scheres有了在方法学和软件上的突破。 那么，冷冻电镜带来的结构生物学的革命是如何实现的？答案是借用到机器学习的思想与方法的，如下面这张图所示： （来自How cryo-EM is revolutionizing structural biology) 第一步，将要解析的蛋白分离纯化制样之后，用高速动态成像的记录蛋白的各种构象; 第二步，处理图像数据，把取向相同的小颗粒re-align，借用贝叶斯的思想；从而将粗颗粒的模型精细化; 第三步，如果是混样的情况，也可以利用分类或者聚类的方法，将混样中存在的不同结构的蛋白构像解析出来。 第二步的基于贝叶斯的re-align和精细化可以概括如下： （图片来自A Bayesian View on Cryo-EM Structure Determination） 策略为通过傅里叶变换的方法用计算机重构出粗略的结构模型然后把这个粗略的结构模型与成千上万的成像数据比对，得到每个图像之间的相对位置。通过作者改进的机器学习中常用的贝叶斯方法，将粗略的结构模型调整为新的一个更精确的结构，如此迭代以精炼我们的模型，文章提到对于核糖体的结构的解析他们迭代了25次。这整个的过程就是所谓的取“平均”了，不过是基于机器学习的方法，结合先验的知识来取得“平均”和进行光滑，取得精细结构。 这部分不是很懂，写的不好，欢迎成像和图像处理方面的专家指正。 三. 回顾反思 在上述论述中，我们介绍的机器学习在生物研究应用案例都只在问这样一类型问题：”某一生物现象是什么？“，不过对于人类社会发展而言更有直接意义的问题是，”认识这一生物现象可能的模式之后我们该怎么办“，问这类问题的人一般都是医生或者药企的科学家。当然，目前也有这方面的成熟流程可以参考: （图片来自Applications of machine learning in drug discovery and development 最近也有科学家用深度学习的方法，发现了新的抗生素： 感兴趣的读者可以看这篇文献。 此外，个人理解，机器学习就是一种智能的数据挖掘技术，它依据先验的知识建立预测模型来识别大数据中的有用信息。所以只要有大数据和前期积累的先验知识，就有机器学习方法用武之地。 说几句与题目无关的话，个人感觉其实这个题目也可以回答学生物的人多学点基础的数学和物理知识有用吗？我觉得是有用的，比如你想搞清楚冷冻电镜成像的原理，你必须懂点物理知识（干涉衍射之类的）还得懂点数学物理方法（如傅里叶变换与它的逆）。当然想要进行机器学习，当然得有统计学和数据的可视化方法的数学基础和计算机编程基础（Python或者R）了。学科之间其实是可以互通有无的，然而这点常常被目光短浅的一些人忽略了，希望关注这个问题的人可以能多从这个角度来学习，思考问题，解决问题。 附：日志 2016.3 创建回答 2016.4.14 用周志华老师《机器学习》补充前言 2020.4.12 原回答因「违反知乎社区管理规定」被删除。 2020.4.13-15 按照知乎社区管理规定做出修订。重新提交。 2020.04.16 修改排版错误","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"machine learning","slug":"machine-learning","permalink":"https://landau1994.github.io/tags/machine-learning/"}]},{"title":"读关于增强子研究的现状与未来的一篇综述","slug":"读关于增强子研究的现状与未来的一篇综述","date":"2020-04-08T13:10:48.000Z","updated":"2025-01-11T17:16:31.880Z","comments":true,"path":"2020/04/08/读关于增强子研究的现状与未来的一篇综述/","link":"","permalink":"https://landau1994.github.io/2020/04/08/%E8%AF%BB%E5%85%B3%E4%BA%8E%E5%A2%9E%E5%BC%BA%E5%AD%90%E7%A0%94%E7%A9%B6%E7%9A%84%E7%8E%B0%E7%8A%B6%E4%B8%8E%E6%9C%AA%E6%9D%A5%E7%9A%84%E4%B8%80%E7%AF%87%E7%BB%BC%E8%BF%B0/","excerpt":"","text":"文章信息 题目：Towards a comprehensive catalogue of validated and target- linked human enhancers 内容 回顾了Enhancer biology的研究历史，概述了现有的研究技术，提出了target-linked的研究框架。 文章最有意思的一个总结图如下: 总结与评述： 像Enhancer biology这样的分子机制，带有很强的各方面的异质性，与其寻求一个comprehensive 的理解，不如做透彻在某一种非常重要的疾病，例如Cancer中的调控作用？Enhancer+single cell，细胞内部调控与细胞间调控的研究都很重要。 里面关于ENCODE的各种组学技术，以及3D genome的技术和CRISPR-screen的优缺点介绍很好。","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"sc-seq","slug":"sc-seq","permalink":"https://landau1994.github.io/tags/sc-seq/"},{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/tags/genomics/"},{"name":"genetics","slug":"genetics","permalink":"https://landau1994.github.io/tags/genetics/"},{"name":"ENCODE","slug":"ENCODE","permalink":"https://landau1994.github.io/tags/ENCODE/"},{"name":"HiC","slug":"HiC","permalink":"https://landau1994.github.io/tags/HiC/"},{"name":"ChIP-seq","slug":"ChIP-seq","permalink":"https://landau1994.github.io/tags/ChIP-seq/"},{"name":"ATAC-seq","slug":"ATAC-seq","permalink":"https://landau1994.github.io/tags/ATAC-seq/"}]},{"title":"关于肿瘤的免疫治疗靶点","slug":"关于肿瘤的免疫治疗靶点","date":"2020-04-08T12:58:13.000Z","updated":"2025-01-11T17:16:31.865Z","comments":true,"path":"2020/04/08/关于肿瘤的免疫治疗靶点/","link":"","permalink":"https://landau1994.github.io/2020/04/08/%E5%85%B3%E4%BA%8E%E8%82%BF%E7%98%A4%E7%9A%84%E5%85%8D%E7%96%AB%E6%B2%BB%E7%96%97%E9%9D%B6%E7%82%B9/","excerpt":"","text":"今天读到一个很清楚的综述的翻译笔记，讲肿瘤免疫治疗靶点的，读者可以移步到 生物信息学专业需要什么样的生物知识？阅读。 原文献里有张总结的图很不错： 可以作为本文的总结。","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"biology","slug":"biology","permalink":"https://landau1994.github.io/tags/biology/"},{"name":"immunology","slug":"immunology","permalink":"https://landau1994.github.io/tags/immunology/"}]},{"title":"quote_20200405","slug":"quote-20200405","date":"2020-04-05T13:52:53.000Z","updated":"2025-01-11T17:16:31.845Z","comments":true,"path":"2020/04/05/quote-20200405/","link":"","permalink":"https://landau1994.github.io/2020/04/05/quote-20200405/","excerpt":"","text":"时间就像一条河流， 在这我们顺流而下， 遇到现实， 需要决策， 但我们无法停留，也无法回避， 只能以最好的方式应付。——《原则》","categories":[{"name":"others","slug":"others","permalink":"https://landau1994.github.io/categories/others/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}]},{"title":"cxt_Chap6_Cytokines","slug":"cxt-Chap6-Cytokines","date":"2020-04-05T13:44:02.000Z","updated":"2025-01-11T17:16:31.834Z","comments":true,"path":"2020/04/05/cxt-Chap6-Cytokines/","link":"","permalink":"https://landau1994.github.io/2020/04/05/cxt-Chap6-Cytokines/","excerpt":"","text":"如无特别说明，引用部分出自《医学免疫学》（第七版，曹雪涛主编，人卫社出版）第六章，细胞因子。 1. 细胞因子的定义 细胞因子是由免疫细胞及组织细胞分泌的在细胞间发挥相互调控作用的的一类小分子可溶性蛋白质，通过结合响应受体调节细胞生长分化和效应，调控免疫应答，在一定条件下也参与炎症等多种疾病的发生。 作用方式：自分泌方式，旁分泌方式，内分泌方式； 功能特点：多效性，重叠性，协同性，拮抗性； 2. 细胞因子的种类 根据结构和功能可以分为如下六大类： - 白细胞介素(interleukin, IL)，IL1-IL38。 - 集落刺激因子(colony-stimulating factor, CSF)，是指能够刺激多能造血干细胞和不同分化阶段的造血祖细胞分化和增殖的细胞因子。主要包括粒细胞-巨噬细胞集落刺激因子(GM-CSF), 巨噬细胞集落刺激因子（M-CSF)，红细胞生成素(EPO)，干细胞因子(SCF)和血小板生成素(TPO)等。分别诱导造血干细胞或祖细胞分化增殖为相应的细胞。 - 干扰素（interferon, IFN), 因具有干扰病毒复制的功能而得名。IFN根据其结构特征及生物学活性可分为I型、II型和III型。I型IFN主要包括IFN-、IFN-, 主要由病毒感染的细胞、pDC细胞等产生；II型IFN即IFN-，主要由活化T细胞和NK细胞产生。III型IFN包括IFN-(IL-29)，IFN-(IL-28A)和IFN-(IL-28B)，主要由DC细胞产生。IFN具有抗病毒、抗细胞增殖、抗肿瘤和免疫调节等作用。 - 肿瘤坏死因子(tumor necrosis factor, TNF)家族。肿瘤坏死因子因最初被发现其能造成肿瘤组织坏死而得名，包括TNF-和TNF-，前者主要由活化的单核/巨噬细胞产生，后者主要由活化的T细胞产生，又称淋巴毒素(lymphotoxin, LT)。TNF家族目前已经发现TRAIL(TNF related apoptosis-inducing ligand)、FasL、CD40L等30余种细胞因子。TNF家族成员在调节免疫应答、杀伤靶细胞和诱导细胞凋亡等过程中发挥重要作用。 - 生长因子（growth factor，GF)泛指一类可促进相应细胞生长和分化的细胞因子。其种类较多，包括转化生长因子-(transforming growth factor-,TGF-)、血管内皮细胞生长因子(VEGF)、表皮生长因子(EGF)、成纤维细胞生长因子(FGF)、神经生长因子(NGF)、血小板生长因子(PDGF)等。 - 趋化因子(chemokine) 是一类结构相似，分子量约812kD，具有趋化功能的细胞因子。几乎所有的趋化因子都含有由2对或一对保守的半胱氨酸残基(C)形成的分子内二硫化键。可以根据靠近氨基端的C的个数以及排列顺序将趋化因子分为四个家族：1）C亚家族：氨基酸端只有1个C，该分子内只有一个分子内二硫化键；2）CC亚家族：氨基端2个C相邻；3）CXC亚家族：氨基酸2个C被1个氨基酸残基隔开；4）CX3C亚家族：氨基端2个C被3个氨基酸残基隔开，羧基端跨细胞膜。 已经发现的趋化因子有，CXCL116，CCL128，XCL12，CX3CL1. 3. 细胞因子受体 细胞因子受体可以根据其结构特点被分为如下六个家族： - I型细胞因子受体家族，也称为血细胞生辰素受体家族(hematopoietin receptor family)， 通过 JAK-STAT通路转导信号； - II型细胞因子受体家族，也称为干扰素受体家族(interferon receptor family)，也是通过JAK-STAT通路转导信号； - 肿瘤坏死因子受体家族(tumor necrosis factor family)，主要通过TRAF-NF-kB，TRAF-AP-1 通路转导信号； - 免疫球蛋白超家族受体(Ig superfamily receptor, IgSFR)，会结合集落刺激因子； - IL-17受体家族(IL-17 receptor family)，主要通过TRAF-NF-kB通路转导信号； - 趋化因子受体家族(chemokine receptor family) ，属于GPCR中的一员。 4.remark 可否从基因表达调控出发，来描述细胞因子的功能？","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"biology","slug":"biology","permalink":"https://landau1994.github.io/tags/biology/"},{"name":"immunology","slug":"immunology","permalink":"https://landau1994.github.io/tags/immunology/"}]},{"title":"HCL papar","slug":"HCL-papar","date":"2020-04-05T13:32:40.000Z","updated":"2025-01-11T17:16:31.813Z","comments":true,"path":"2020/04/05/HCL-papar/","link":"","permalink":"https://landau1994.github.io/2020/04/05/HCL-papar/","excerpt":"","text":"题目：Construction of human cell landscape at single-cell level 科学问题：如何构建人类细胞图谱 实验：用其自己开发的Microwell-seq，该研究充分利用Microwell-seq成本低廉，双细胞污染率低和细胞普适性广等优势，建立了70多万个单细胞的转录组数据库，鉴定了人体100余种细胞大类和800余种细胞亚类。基于该数据库，团队开发了scHCL单细胞比对系统用于人体细胞类型的识别，并搭建了人类细胞蓝图网站http://bis.zju.edu.cn/HCL/（国家基因库镜像https://db.cngb.org/HCL/）。 分析：“tSNE+图聚类”（fig1b,fig1c,fig1d); EC,Epi, Stromal cell分泌Ligand的能力（Fig2c)主要是Adult的细胞（微环境？）；路径分析（Fig3)；调控分析（Fig4) 讨论：图谱式工作；证明了概念的可行性；但是不如HCA那么激动人心？","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"},{"name":"biology","slug":"biology","permalink":"https://landau1994.github.io/tags/biology/"}]},{"title":"Dobrow-chap2","slug":"Dobrow-chap2","date":"2020-04-05T13:17:46.000Z","updated":"2025-01-11T17:16:31.801Z","comments":true,"path":"2020/04/05/Dobrow-chap2/","link":"","permalink":"https://landau1994.github.io/2020/04/05/Dobrow-chap2/","excerpt":"","text":"对于 Introduction to stochastic processes with R一书的笔记 Let us finish the article and the whole book with a good example of dependent trials, which approximately can be considered as a simple chain. –Andrei Andreyevich Markov Chap2: Markov Chains: First steps 本章讲马尔可夫链 Introduction 引入的案例： 这一节，用一个类似大富翁的游戏来引入马尔可夫夫性。 马尔可夫链的形式化定义为 &gt; Markov Chain &gt; Let be a discrete set. A Markov chain is a sequence of random variables taking values in with the property that &gt; &gt; for all The set is the state space of the Markov chain. 、 称为在时刻n到达状态i。 时间齐性马尔可夫链： transition matrix: n步转移矩阵计算（矩阵乘法） 若干例子： 收敛于一个各行相等的矩阵； 不收敛，进入跳跃的状态； 收敛于一个各行不相等的矩阵 第五部分从直观上为下一章铺路。","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"},{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}]},{"title":"Dobrow_chap1","slug":"Dobrow-chap1","date":"2020-04-04T11:41:57.000Z","updated":"2025-01-11T17:16:31.799Z","comments":true,"path":"2020/04/04/Dobrow-chap1/","link":"","permalink":"https://landau1994.github.io/2020/04/04/Dobrow-chap1/","excerpt":"","text":"This is a note of the textbook Introduction to stochastic processes with R We demand rigidly defined areas of doubt and uncertainty! –Douglas Adams, The Hitchhiker’s Guide to the Galaxy Introduction and preview We demand rigidly defined areas of doubt and uncertatinty –Douglas Adams, The Hitchhiker’s Guide to the Galaxy 1.1 DETERMINISTIC AND STOCHASTIC MODELS Consider a simple exponential growthmodel where the random arises？ The deterministic model does not address the uncertainty present in the reproduction rate of individual organisms. In many biological processes, the exponential distribution is a common choice for modeling the times of births and deaths. Ex1.1 PageRank: random walks on graphs Ex1.2 Spread of infectious disease SIR model: Susceptible-infected-removed Reed-Frost model: Stochastic SIR model in discrete time. 1.2 What is a stochastic process The author said &gt; A stochastic process, also called a random process, is simply one in which outcomes are uncertain. By contrast, in a deterministic system there is no randomness. In a deterministic system, the same output is always produced from a given input. A stochastic process is specified by its index and state sapce, and by the dependency relationships among its random variables &gt; Stochastic process: A stochastic process is a collection of random variables .The set I is the index set of the process. The random variables are defined on a commmon state space S. Ex 1.3 Monopoly EX 1.4 Discrete time, continous state space Ex 1.5 Continuous time, discrete state space arrival process, Poisson process Ex 1.6 Random walk and gambler's ruin: Random walk, discrete-time stochastic process whose state space is Ex 1.7 Brownian motion: Brownian motion is a continuous-time, contiuous state space stochastic process 1.3 Monte Carlo Simulation Given a random experiment and event A, a Monte Carlo estimate of is obtained by repeating random experiment many times and taking the proportion of trials in which A occurs as an approximation for Strong law of large numbers 1.4 Conditional Probability The simplest stochastic process is a sequence of i.i.d. random variables. Such sequences are often used to model random samples in statistics. However, most real-world systems exhibit some type of dependency between variables, and an independent sequence is often an unrealistic model. Thus, the study of stochastic processes really begins with conditional probability—conditional distributions and conditional expectation. These will become essential tools for all that follows. Conditional Probability: Law of Total probability: Let be a sequence of events that partition the sample space. That is, the are mutually exclusive(disjoint) and their union is equal to . Then, for many event A, Ex1.8 Disease tests Ex1.9 Find the probability that it is a heart Ex1.10 Gambler's ruin let denote the probability of reaching n when the gambler's fortune is k. or using we have The gambler's ruin is Bayes Rule Given a countable sequence of events which partition the sample space, a more general form of Bayes' rule is Ex 1.11 The probability that teh employee is in fact lying. Conditional Distribution joint density function: Discrete Case: P(Y=y|X=x)= Continuous Case: For continuous randomo variables X and Y, the conditional density function of Y given X=x is 1.5 Conditional Expectation of Y given X=x Conditional Expectation of Y given X=x","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"},{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}]},{"title":"几个重要假设检验的推导","slug":"几个重要假设检验的推导","date":"2018-08-01T07:16:53.000Z","updated":"2025-01-11T17:16:31.869Z","comments":true,"path":"2018/08/01/几个重要假设检验的推导/","link":"","permalink":"https://landau1994.github.io/2018/08/01/%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E6%8E%A8%E5%AF%BC/","excerpt":"","text":"前言 假设检验是我们在日常研究中，经常碰到的统计问题。对于追求实用与效率的科研人员来说，各种不同的假设检验是可以用软件，点点鼠标，或者写写代码，就可以完成的。 不过，对于我们这些想要在生物信息领域深入和进阶，并且最终有所建树的学生来说，我们光会拧螺丝和用板子，用轮子是不够的，当有新的技术，新的需求出来之后，我们得要造新轮子，开发新方法。因此，我们还是得学学火箭是咋飞起来和板子以及轮子是咋造出来的知识。 我们以学习和介绍研究中比较基础的三种检验的所对应的分布推导，开始我们的进阶之旅。 说明：本文的推导来自《概率统计讲义》第三版附录二，陈家鼎等编著，高等教育出版社出版。略微有所修改，阅读本文，只需修过本科阶段非数学专业的三门基础数学课：高等数学(不是很深，也不是很浅的数学分析)，线性代数，概率论与数理统计。 ## 正交矩阵与正态分布 在线性代数课程中，我们知道，若阶方阵满足，写成标量的形式就是： 此时，我们称方阵为正交矩阵。而且，通过线性代数的课程，我们知道，正交矩阵满足如下性质： + 1-1 设A是正交矩阵，则，并且结合（1）可得： 1-2 设A是正交矩阵，则也是正交矩阵，并且或，其中表示行列式。 1-3 若是正交矩阵，而是任意n个实数，对于 我们有 很抱歉，开头罗列了这么多线性代数的事实，不过，也没办法，要做菜，我们得先备料不是吗。下面我们开始做菜了。 定理1 设相互独立，且都服从，又是正交矩阵，构造随机变量 证明 因的分布密度是,且是独立同分布样本（i.i.d.），故联合密度为： 构造n维空间中的区域D: 则有： 注意到 于是（利用正交矩阵的性质） 容易验证，变换的雅可比式为 又故 故相互独立，且不难看出，都服从。定理1证毕。 定理2设相互独立，且。是n阶正交矩阵,构造随机变量， 则相互独立，且 证明令，则相互独立，都服从,根据定理1知，相互独立。 且 但是 故相互独立，且 关于分布 前面的的都是小菜，接下来上主菜。我们要开始证明一系列很fancy的定理 定理3 设相互独立，并且都服从,则服从个自由度的分布，其PDF(probability density function)为 证明 我们证明的策略是，先求出CDF(cumulative distribution function)，然后利用中值定理，证明。 显然，当 当时，由于相互独立，故联合密度为， 故 故对于,有 令 则 问题现在变为如何求 做代换,则 由此 有趣的是，我们可以看出 是维单位球体的体积。不过在我们的问题中，我们可以看出它只和有关的量。故 根据之前的不等式，结合中值定理： 所以 综上 由归一化条件知 而在数学分析的知识告诉我们 定理得证。 这个定理的一个副产物是，告诉了我们维单位球体的体积 推论 若，则有 证明 由定理1，结合数学期望的性质，知 定理4 若与相互独立，且，则 证明 设，的分布函数分别为，我们先分别不加证明的引用概率论和Gamma函数的两个结论： 1).已知(X,Y)的联合密度是，的PDF为： 2).(p,q为正整数) 下面开始证明： 当 时，,定理成立。 当 时， （ 综上： 定理5 若相互独立，且都服从分布,则有如下三条结论： 与相互独立 证明 构造正交矩阵 由此正交矩阵，我们可以构造随机变量： 有定理1可知，相互独立，且都服从， 我们发现，因此，第一条结论得证。 由于故 第二条结论得证。 由于相互独立，且 故与独立，第三条结论得证 推论 若相互独立，且都服从分布,则有如下三条结论： 与相互独立 关于t分布 定理6 设相互独立，且， 则，其PDF为： 证明 与定理3证明的思路类似，设证明, 由已知： 故 定理5,6可以用来证明下面这个在统计学里很有作用的定理： 定理7 设相互独立，且都服从,则其中 证明 构造随机变量 根据定理5的推论，我们知道相互独立，且 故根据定理6， 故 ## 关于F分布 定理8 设相互独立，且 则 其PDF为： 证明 跟之前一样，令 ，证明 当 , 故 定理9 设, 这个随机变量相互独立，且都服从,则 证明 构造随机变量 由之前的结论，我们知道, 接下来证明的独立性，构造随机变量： 则 由已知 相互独立，且都服从,于是其联合分布密度为 所以,对于任意的实数 独立性得证。 再结合定理8，","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"Probability","slug":"Probability","permalink":"https://landau1994.github.io/tags/Probability/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-07-29T03:35:19.000Z","updated":"2025-01-11T17:16:31.835Z","comments":false,"path":"2018/07/29/hello-world/","link":"","permalink":"https://landau1994.github.io/2018/07/29/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post $ hexo new &quot;My New Post&quot; More info: Writing Run server $ hexo server More info: Server Generate static files $ hexo generate More info: Generating Deploy to remote sites $ hexo deploy More info: Deployment","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://landau1994.github.io/tags/hexo/"},{"name":"NodeJS","slug":"NodeJS","permalink":"https://landau1994.github.io/tags/NodeJS/"}]}]}