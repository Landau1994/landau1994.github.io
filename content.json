{"meta":{"title":"Coding for Life Sciences","subtitle":"从数据，模型中获取生物知识","description":"关注从数据和模型中获取生物知识的博客","author":"Longteng Wang","url":"https://landau1994.github.io","root":"/"},"pages":[{"title":"学习，研究，创新，分享","date":"2020-04-08T13:50:00.000Z","updated":"2025-01-12T02:40:40.805Z","comments":false,"path":"about/index.html","permalink":"https://landau1994.github.io/about/index.html","excerpt":"","text":"为何建站 科研从兴趣出发，用良好的习惯坚持和成长。本站旨在记录成长点滴。 为何写作 写作可以抵抗遗忘和衰朽，古人云： 盖文章，经国之大业，不朽之盛事。年寿有时而尽，荣乐止乎其身，二者必至之常期，未若文章之无穷。 ——曹丕《典论·论文》节选 而在科研中，写作可以整理文献综述、材料方法，已经取得的数据结果。更重要的是理清下一步研究思路和技术路线。 此外，勤练写作，可以提高研究者表达和推广自己观点和研究成果的能力。 最终希望大家都能做学问或者学自己感兴趣的事物，最后能如韩愈作文一样，实现这种理想的境界： 本深而末茂，形大而声宏，行峻而言厉，心醇而气和，昭晰者无疑，优游者有余。 涵盖主题 本站最关注的是基因组学和生物信息学的各项研究以及相关的生物学，信息学，数学和统计学（将来可能还会有物理学和化学）的基础知识的学习。更多见话题标签 关于作者 生物信息学博士。知乎主页[https://www.zhihu.com/people/landau1994]。","author":"夏目沉吟"},{"title":"QA","date":"2020-04-08T13:32:22.000Z","updated":"2025-01-11T17:16:32.274Z","comments":false,"path":"help/index.html","permalink":"https://landau1994.github.io/help/index.html","excerpt":"","text":"Q: 这网站怎么弄的，还挺好看的啊？ A: 本站是静态博客，通过hexo生成，主题为jsimple,做了个性化的定制（换了白天和晚上的图片，修改了配置支持数学公式）。 Q: 为什么博客有时候打开速度很慢，一直在加载，或者有时压根打不开呢？ A: 本站尚无独立域名，暂时使用Github Page。所以github卡或者崩的时候就gg了。不过这都是小概率事件。开源万岁，github万岁,拥抱开源的微软万岁。 Q: 我也想搭个博客，不知道怎么弄？ A: 参考问题1，学会看官网教程，以及自己动手修改和调试配置文档。 Q: 本站是否接受投稿或转载？ 站长本人之外的投稿和转载暂不支持。 Q: 其他的… 本站为站长自己的学习记录，因个人知识水平所限，如有错误，还望批评指正。","author":"夏目沉吟"},{"title":"tags","date":"2020-04-05T14:04:00.000Z","updated":"2025-01-11T17:16:32.280Z","comments":false,"path":"tags/index.html","permalink":"https://landau1994.github.io/tags/index.html","excerpt":"","text":"","author":"夏目沉吟"},{"title":"links","date":"2020-04-08T14:20:45.000Z","updated":"2026-02-25T08:15:02.627Z","comments":false,"path":"links/index.html","permalink":"https://landau1994.github.io/links/index.html","excerpt":"","text":"计算生物学/生物信息学家成长之路 以下摘录有趣、有意义、有影响力的链接 持续更新中。 此处不做网址导航，排序不分先后… 🔬 基本资源 代码与开发 GitHub - 全球最大的代码托管平台 Stack Overflow - 程序员问答社区 Biostars - 生物信息学专业问答社区 学术搜索 Google Scholar - 学术文献搜索引擎 PubMed - 生物医学文献数据库 bioRxiv - 生物学预印本服务器 arXiv - 物理、数学、计算机科学预印本 顶级期刊 Nature Science Cell Nature Methods - 方法学期刊 Genome Biology Bioinformatics 📚 生物信息学资源 中文社区 实用生物信息技术 - 北大CBI实用教程 CBI forum - 北大生信论坛 生信技能树 - 生信学习社区 生信坑 - 生信技术分享 生信菜鸟团 - 生信入门教程 国际资源 Bioconductor - R 语言生物信息学包 Galaxy - 基于Web的生信分析平台 UCSC Genome Browser - 基因组浏览器 Ensembl - 基因组注释数据库 NCBI - 美国生物技术信息中心 数据库 UniProt - 蛋白质序列与功能数据库 KEGG - 基因与基因组百科全书 STRING - 蛋白质相互作用网络 Gene Ontology - 基因本体论 ExPASy - 蛋白质组学资源 🏛️ 研究机构与大型项目 国际研究机构 Wellcome Sanger Institute - 英国桑格研究所，基因组学研究先驱 Broad Institute - 哈佛-MIT联合研究所，基因组医学 Allen Institute - 艾伦脑科学研究所 Arc Institute - 前沿生物医学研究机构 European Bioinformatics Institute (EBI) - 欧洲生物信息学研究所 大型科研计划 Human Cell Atlas - 人类细胞图谱计划 Chan Zuckerberg Initiative (CZI) - 陈-扎克伯格倡议 CZ Biohub - CZ 生物中心 CZ CELLxGENE - 单细胞数据门户 ENCODE Project - DNA元件百科全书计划 1000 Genomes Project - 千人基因组计划 GTEx Portal - 基因型-组织表达项目 Human Protein Atlas - 人类蛋白质图谱 单细胞资源 Single Cell Portal - Broad研究所单细胞门户 10x Genomics Resources - 10x 单细胞技术资源 scRNA-seq Database - 单细胞数据库集合 🛠️ 工具与教程 在线工具 BLAST - 序列比对工具 Clustal Omega - 多序列比对 SnapGene Viewer - 质粒查看工具 DeepL - AI 翻译工具 编程学习 Rosalind - 生物信息学编程练习 Kaggle - 数据科学竞赛平台 DataCamp - 数据科学在线课程 Coursera - 在线课程平台 文档教程 The Carpentries - 科研计算技能培训 NGS Analysis - NGS 数据分析教程 Awesome Bioinformatics - 生信资源集合 scRNA-tools - 单细胞分析工具数据库 🧬 AI 生物学工具 蛋白质结构预测 AlphaFold 3 - DeepMind 蛋白质结构预测（最新版本） AlphaFold Database - 2亿+蛋白质结构数据库 AlphaFold GitHub - AlphaFold 开源代码 RoseTTAFold - Baker Lab 蛋白质结构预测 RoseTTAFold GitHub - 开源实现 ESMFold - Meta 快速蛋白质结构预测 ESM Metagenomic Atlas - 6亿+宏基因组蛋白结构 蛋白质设计 ProteinMPNN - 蛋白质序列设计 RFdiffusion - 基于扩散模型的蛋白质设计 Chroma - Generate Biomedicines 蛋白质生成模型 基因组与序列分析 AlphaGenome - DeepMind 基因组分析（开发中） Enformer - 基因表达预测 DNA Foundation Models - DNA 大模型合集 分子对接与药物发现 DiffDock - 扩散模型分子对接 AlphaFold-Multimer - 蛋白质复合物预测 Uni-Mol - 分子性质预测统一模型 RNA 结构预测 AlphaFold-RNA - RNA 结构预测（集成于 AlphaFold 3） RNAfold - RNA 二级结构预测 RhoFold - 基于 AI 的 RNA 3D 结构预测 🤖 AI 大语言模型 国际主流模型 OpenAI ChatGPT - GPT-5.3，最强大的通用大模型 OpenAI API - OpenAI 开发者平台 OpenAI Playground - API 测试环境 Anthropic Claude - Claude 4，擅长长文本和推理 Claude API - Anthropic 开发者平台 Google Gemini - Google 最新多模态大模型 Gemini API - Google AI 开发平台 Meta Llama - Meta 开源大模型家族 Mistral AI - 欧洲开源大模型领军者 Perplexity - AI 搜索引擎 国内主流模型 文心一言 - 百度大模型 通义千问 - 阿里云大模型 豆包 - 字节跳动大模型 智谱清言 - 清华智谱 ChatGLM Kimi - 月之暗面，擅长长文本 DeepSeek - 深度求索，强推理能力 腾讯混元 - 腾讯大模型 讯飞星火 - 科大讯飞大模型 开源模型社区 Hugging Face - 最大的开源模型社区 Hugging Face Models - 模型库 Hugging Face Spaces - 在线演示 ModelScope - 魔搭社区，国内模型平台 GitHub Models - GitHub 模型市场 Ollama - 本地运行大模型工具 生物医学专用模型 BioGPT - 微软生物医学文本生成模型 Med-PaLM - Google 医疗专用大模型 GeneGPT - NCBI 基因信息问答模型 BioMed-LLM - 生物医学开源大模型 Scientific Large Language Models - 科研专用模型集合 AI 辅助工具 Cursor - AI 代码编辑器 GitHub Copilot - AI 编程助手 Codeium - 免费 AI 代码补全 Consensus - AI 文献搜索与总结 Elicit - AI 研究助手 SciSpace - AI 论文阅读与理解 📝 博客与公众号 技术博客 Living in an Ivory Basement - Titus Brown Simply Statistics - 统计学博客 Bits of DNA - Lior Pachter Heng Li’s Blog - 李恒的博客 微信公众号 biobabble - 生物信息学科普 生信技能树 - 生信学习资源 生信菜鸟团 - 入门教程 Y大宽 - 科研与编程 生物信息学习圈 - 学习交流 🎓 课程与视频 公开课 MIT OpenCourseWare - MIT 开放课程 生物信息学导论 - 中国大学MOOC Introduction to Genomic Data Science - Coursera 视频教程 YouTube - StatQuest - 统计学与机器学习 Bilibili - 生信人 - 中文生信教程 📊 可视化工具 ggplot2 - R 语言绘图包 Matplotlib - Python 绘图库 Cytoscape - 网络可视化 IGV - 基因组浏览器 BioRender - 科研插画工具 🌟 其他资源 科研工具 Zotero - 文献管理软件 Mendeley - 文献管理与社交 Overleaf - 在线 LaTeX 编辑器 Sci-Hub - 文献下载（使用需谨慎） 数据分析 编程语言 R Project - R 语言官网 Python.org - Python 官网 IDE 与编辑器 RStudio - R 语言专业 IDE（Posit 公司） Positron - Posit 新一代数据科学 IDE，支持 Python 和 R Visual Studio Code - 微软开源代码编辑器 Python Extension - Python 开发插件 R Extension - R 语言支持 PyCharm - JetBrains Python IDE Jupyter Lab - 新一代 Jupyter 界面 Jupyter Notebook - 经典交互式笔记本 Google Colab - 在线 Jupyter 环境，免费 GPU Spyder - 科学计算 Python IDE Sublime Text - 轻量级文本编辑器 包管理工具 uv - 超快的 Python 包和项目管理器（Rust 编写） Conda - 跨平台包管理器 pip - Python 包管理工具 Poetry - 现代 Python 依赖管理和打包工具 pipx - 隔离安装 Python 应用程序 rig - R 版本管理工具，轻松安装和切换多个 R 版本 renv - R 项目环境管理 云计算平台 Google Colab - 免费 GPU/TPU 计算 AWS - 亚马逊云服务 阿里云 - 国内云计算平台 💡 学习建议 从基础开始：掌握编程基础（Python/R）和 Linux 操作 多看多练：关注社区动态，实践开源项目 建立体系：系统学习生物学背景知识 保持更新：关注最新文献和工具发展 交流分享：加入社区，参与讨论 最后更新：2026-02-25","author":"夏目沉吟"},{"title":"timeline","date":"2020-04-08T14:33:55.000Z","updated":"2025-01-11T17:16:32.289Z","comments":false,"path":"timeline/index.html","permalink":"https://landau1994.github.io/timeline/index.html","excerpt":"","text":"暂时没有，可以看标签和归档。","author":"夏目沉吟"}],"posts":[{"title":"LUMI-lab","slug":"LUMI-lab","date":"2026-02-25T05:49:05.000Z","updated":"2026-02-25T06:36:48.510Z","comments":true,"path":"2026/02/25/LUMI-lab/","permalink":"https://landau1994.github.io/2026/02/25/LUMI-lab/","excerpt":"","text":"Cell 2026 LUMI-lab: A foundation model-driven autonomous platform enabling discovery of ionizable lipid designs for mRNA delivery Quick Summary The authors present [[Cell 2026 LUMI-lab]], a fully autonomous self-driving laboratory that integrates a molecular foundation model with high-throughput robotics to discover novel [[ionizable lipids]] for [[mRNA delivery]]. By employing an iterative [[active learning]] workflow that balances exploration and exploitation, the system synthesized and screened over 1,700 lipid candidates, identifying [[brominated lipid tails]] as a potent structural motif. The top candidate, [[LUMI-6]], demonstrated superior pulmonary transfection efficiency, achieving 20.3% gene editing efficacy in mouse lung epithelial cells. Key Points Introduction of LUMI-lab, a closed-loop platform combining AI, robotics, and biological screening. Development of LUMI-model, a transformer-based 3D molecular foundation model adapted for data-sparse environments via continual pretraining. Autonomous synthesis and screening of &gt;1,700 [[Lipid Nanoparticles]] (LNPs) over 10 active learning iterations. Discovery of brominated tails as a non-intuitive structural feature that significantly enhances [[endosomal escape]] and mRNA transfection. In vivo validation showed [[LUMI-6]] outperforms clinically approved benchmarks ([[SM-102]] and [[MC3]]) in pulmonary gene editing. Methods Data Pretraining Dataset: 13,369,320 generic small molecules with 147M 3D conformations (derived from [Uni-Mol] dataset). Continual Pretraining Dataset: 15,491,072 lipid-like molecules (170M conformations) generated via combinatorial enumeration of the Ugi-4CR reaction space. Experimental Data: 1,781 distinct ionizable lipids synthesized and tested for mRNA transfection potency (mTP) in human bronchial epithelial ([[HBE]]) cells. Model Architecture LUMI-model: A 15-layer [[Transformer]] architecture based on [Uni-Mol]. Input: Atom types and 3D atomic coordinates to capture conformation-aware representations. Embeddings: Atom-type aware Gaussian Kernel used to encode pairwise distances, ensuring invariance to global rotation/translation. Training Strategy Stage 1: Unsupervised Pretraining: Masked atom prediction, 3D position recovery, and contrastive learning on generic molecules. Stage 2: Continual Pretraining: Domain adaptation on the lipid-like dataset to prioritize features relevant to LNP engineering. Stage 3: Active Learning Fine-tuning: Supervised fine-tuning on experimental data collected during iterations. Dual-Plate Strategy: Each iteration synthesized two plates—one for exploitation (high predicted potency) and one for exploration (high ensemble uncertainty). Results Metric Value Baseline ([[SM-102]]/[[MC3]]) In vivo Gene Editing (Lung Epithelial) 20.3% &lt; 5% (estimated from plots) Top 25% Pearson Correlation (Noise σ=8) 0.51 ~0.37 ([LiON]) Transfection Efficiency (relative to LUMI-6D) 1.8-fold higher N/A Figures Figure Description Fig 1 Overview of [[Cell 2026 LUMI-lab]] hardware/software architecture, demonstrating the closed-loop cycle of design, synthesis, formulation, and testing. Fig 2 The three-stage training pipeline of [[LUMI-model]] and benchmark comparisons showing superior performance against GNNs and XGBoost. Fig 3 Visualization of the dual-plate [[active learning]] strategy (exploitation vs. exploration) and the rapid enrichment of high-potency lipids over 10 iterations. Fig 4 UMAP analysis revealing the clustering of [[brominated lipids]] and their high prediction/experimental performance. Fig 5 Identification of top candidates (LUMI-1 to LUMI-6) and in vivo validation in mice via intratracheal administration. Fig 6 Evaluation of [[LUMI-6]] for [[CRISPR-Cas9]] gene editing in [[Ai9 mice]], showing high efficiency in lung epithelial cells. Critical Analysis Strengths Closed-Loop Integration: Seamlessly connects computational prediction with robotic execution, removing human bottlenecks in the DMTA (Design-Make-Test-Analyze) cycle. Data Efficiency: The foundation model approach allows effective learning from sparse wet-lab data (few-shot learning), a common hurdle in material discovery. Novel Insight: The system identified [[bromination]] as a key feature, a modification not typically prioritized in expert-driven lipid design, validating the AI’s ability to find non-intuitive SARs. Robust Validation: Moved beyond in vitro screening to demonstrate significant functional efficacy in live animal models. Weaknesses Fixed Formulation: The screening used a standardized helper lipid formulation. The paper acknowledges that co-optimizing the lipid structure and the formulation ratio simultaneously could yield even better results. Chemical Space Limits: Synthesis was restricted to 4-component Ugi reactions. While combinatorial, it doesn’t cover all possible lipid chemistries. Generative Limits: The model selects from an enumerated library rather than performing de novo generative design, potentially limiting the search space to the pre-defined building blocks. Questions How transferable is the [[LUMI-model]] to other tissue targets (e.g., liver, spleen, brain) without extensive retraining? Does the bromination motif pose any long-term toxicity or metabolic accumulation risks not captured in the 28-day subchronic toxicity study? Connections Related Papers Papers describing [[SM-102]] (Moderna) and [[MC3]] (Alnylam) as industry standards. Related Concepts [[Self-Driving Laboratories]] (SDLs) [[Active Learning]] [[Foundation Models]] in Chemistry [[Lipid Nanoparticles]] (LNPs) [[CRISPR-Cas9]] Delivery Potential Applications Pulmonary gene therapy (e.g., Cystic Fibrosis). Rapid development of mRNA vaccines for emerging pathogens. Automated discovery of materials for other biomedical applications (e.g., polymer design). Notes The “2026” date in the citation suggests this is a “future-dated” issue or pre-press release metadata provided in the prompt. The use of “Exploitation” and “Exploration” plates is a clever practical implementation of Bayesian Optimization principles in a high-throughput physical setting.","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}],"author":"研精极锐"},{"title":"AlphaGenome 简介","slug":"AlphaGenome","date":"2026-02-25T05:43:12.000Z","updated":"2026-02-25T06:16:40.852Z","comments":true,"path":"2026/02/25/AlphaGenome/","permalink":"https://landau1994.github.io/2026/02/25/AlphaGenome/","excerpt":"","text":"Nature 2026 Advancing regulatory variant effect prediction with AlphaGenome Quick Summary AlphaGenome 是由 Google DeepMind 开发并发表于 Nature 的一种统一的深度学习模型，旨在解决基因组序列建模中“长距离上下文”与“高分辨率预测”之间的权衡难题。该模型接受 1 Mb 的 DNA 序列作为输入，能够以 单碱基分辨率 同时预测 5,930 个（人类）和 1,128 个（小鼠）功能基因组轨道，涵盖基因表达、剪接（位点、使用率及连接）、染色质可及性、组蛋白修饰、转录因子结合以及 3D 染色体接触图谱。在 26 项变异效应预测（VEP）基准测试中，AlphaGenome 在 25 项 上达到或超过了现有的最佳模型（SOTA），并展示了在解释罕见病和癌症（如 T-ALL 中的 TAL1 增强子突变）非编码区变异机制方面的强大能力。 Key Points 统一的全能架构：在一个模型中同时实现了长序列建模（1 Mb 上下文）和单碱基输出精度，打破了以往模型（如 Enformer 牺牲分辨率，SpliceAI 牺牲长度）的局限。 SOTA 性能：在 22/24 个基因组轨道预测任务和 25/26 个变异效应预测任务中表现优于现有最佳模型（包括 Borzoi, Orca, Pangolin 等）。 剪接预测的突破：不仅预测剪接位点，还引入了直接预测 剪接连接（Splice Junctions） 的机制，能更准确地识别外显子跳跃等复杂剪接变异。 高效蒸馏：通过“预训练+蒸馏”策略，将大型集成模型的知识压缩到单个学生模型中，在单个 GPU 上推理时间小于 1 秒，大幅降低了应用门槛。 Methods Data 训练数据：来自 ENCODE, GTEx, FANTOM5, 4D Nucleome 等项目的公开数据。 涵盖模态：RNA-seq, CAGE, PRO-cap, DNase-seq, ATAC-seq, ChIP-seq (TF &amp; Histone), Hi-C/Micro-C。 物种：人类 (hg38) 和 小鼠 (mm10)。 Model Architecture 主干：U-Net 风格的编码器-解码器架构 。 Encoder：卷积层将 1 Mb 序列下采样。 Transformer Tower：处理长距离依赖关系，并生成用于预测接触图谱的 2D 嵌入。 Decoder：通过跳跃连接（Skip connections）将特征上采样回 1 bp 分辨率。 输出头：针对不同模态在不同分辨率（1 bp, 128 bp, 2048 bp）输出预测结果。特别设计了能够捕捉供体-受体相互作用的剪接连接预测头 。 Training Strategy 两阶段训练： 预训练 (Pre-training)：在 8 个 TPUv3 核心上进行序列并行训练，学习预测实验轨道数据 。 蒸馏 (Distillation)：训练一个学生模型来模仿“全折叠（all-fold）”教师模型集成的预测。此阶段引入了更强的增强策略（如随机突变），显著提升了模型的鲁棒性和变异效应预测能力 。 Results Metric Value (AlphaGenome) Baseline (SOTA) Description VEP Benchmarks 25/26 - 在 26 项变异效应预测基准中，25 项达到或超越 SOTA Gene Expr LFC (Pearson r) +14.7% (vs Borzoi) 细胞类型特异性基因表达预测的相对提升 Contact Map (Pearson r) +6.3% (vs Orca) 3D 基因组接触图谱预测的相对提升 eQTL Sign Prediction (auROC) 0.80 0.75 (Borzoi) 预测 eQTL 效应方向的准确性 ClinVar (Deep Intronic) 0.66 0.64 (Pangolin) 深层内含子致病变异的分类精度 (auPRC) Figures Figure Description Fig 1 模型架构、训练流程（预训练与蒸馏）概览，以及与 SOTA 模型在各项基准上的性能对比摘要 。 Fig 2 展示了模型在 LDLR 等基因座上的高精度轨道预测（包括剪接连接），以及各模态预测值与观测值的高相关性 。 Fig 3 剪接变异预测深入分析：展示了模型如何准确预测导致外显子跳跃的罕见变异，并在 ClinVar 基准测试中领先 。 Fig 4 基因表达变异预测（eQTL）：展示了在 GTEx eQTL 效应值和方向预测上的显著提升，以及在 GWAS 信号解读中的应用 。 Fig 5 染色质状态变异预测（caQTL/bQTL）：展示了对染色质可及性和转录因子结合变异的精准预测 。 Fig 6 跨模态案例分析：解析 T-ALL 中 TAL1 癌基因的非编码突变机制，展示模型如何通过多模态输出揭示致病机理 。 Critical Analysis Strengths 多模态整合：成功将此前分裂的多个领域（如剪接、表达、3D结构）整合到一个统一框架中，且在各子任务上均不输于专用模型。 分辨率优势：相比 Borzoi/Enformer，提供了单碱基分辨率的输出，这对于识别精细的剪接位点和 TF 结合位点至关重要。 机制可解释性：不仅能预测“变异致病”，还能通过多模态输出（如“该变异破坏了 CTCF 结合并改变了 3D 结构从而影响表达”）提供机制解释 。 Weaknesses 远端调控局限：尽管输入长达 1 Mb，但在预测距离超过 100 kb 的远端调控元件影响时，性能仍有下降，仍是一个挑战 。 组织特异性：虽然表现优异，但在跨细胞背景下精确复现某些组织特异性模式方面仍有提升空间 。 非编码基因覆盖：目前的训练和评估主要集中在蛋白编码基因，对 microRNAs 等非编码基因的覆盖不足 。 Questions 如何进一步扩展模型以处理更长范围（&gt;1 Mb）的相互作用，以捕捉超长距离的增强子-启动子互作？ 未来的版本是否会整合单细胞数据，以提高在复杂组织中细胞类型特异性的分辨率？ Connections Related Papers Borzoi (Linder et al., 2025): 上一代多模态 SOTA，AlphaGenome 的主要对比基线。 Enformer (Avsec et al., 2021): 本文第一作者之前的开创性工作，引入了 Transformer 处理长序列。 Orca (Zhou, 2022): 3D 基因组预测的专用模型，被 AlphaGenome 在接触图谱任务上超越。 Pangolin / SpliceAI: 剪接预测领域的标杆，AlphaGenome 在剪接任务上的对比对象。 Related Concepts Sequence-to-Function: 从序列直接预测功能的建模范式。 In Silico Mutagenesis (ISM): 计算机模拟诱变，用于解析模型预测背后的序列基序（Motif）。 Knowledge Distillation: 知识蒸馏，本文用于提升模型推理效率和鲁棒性的关键技术。 Potential Applications 全基因组关联分析 (GWAS) 解读：为非编码区 GWAS 信号提供因果变异和分子机制的假设（如确定 eQTL 的方向）。 临床变异解读：辅助诊断罕见病，特别是针对那些现有工具难以解释的深层内含子变异或非编码调控变异。 序列设计：用于设计具有特定组织特异性的增强子或优化反义寡核苷酸（ASO）疗法 。 Notes 这是 AlphaGenome 的正式发表版本（Nature 2026），与之前的 bioRxiv 版本相比，基准测试结果更加完善（如 VEP SOTA 数从 24/26 更新为 25/26）。 论文明确指出，该模型并未在“个人基因组预测（personal genome prediction）”任务上进行基准测试，这是该领域模型的一个已知弱点 。","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"AIVC","slug":"AIVC","permalink":"https://landau1994.github.io/tags/AIVC/"}],"author":"研精极锐"},{"title":"我花了三年时间，整理了这份生物信息学资源清单（2026最新版）","slug":"bioinformatics-resources-2026","date":"2026-02-24T16:00:00.000Z","updated":"2026-02-25T08:13:42.785Z","comments":true,"path":"2026/02/25/bioinformatics-resources-2026/","permalink":"https://landau1994.github.io/2026/02/25/bioinformatics-resources-2026/","excerpt":"写在前面 作为一名生物信息学 PhD，这三年来最常被师弟师妹们问到的问题就是： “学长，有什么好的生信学习资源推荐吗？” “AlphaFold 怎么用啊？” “哪个大模型适合写代码？” “R 和 Python 用什么 IDE 比较好？” 每次都要翻聊天记录找链接，实在太麻烦了。于是，我决定把这些年收藏的优质资源系统性地整理出来，做成一个完整的资源导航页面。 今天就把这份清单分享给大家。全文 7000+ 字，建议先收藏再看！","text":"写在前面 作为一名生物信息学 PhD，这三年来最常被师弟师妹们问到的问题就是： “学长，有什么好的生信学习资源推荐吗？” “AlphaFold 怎么用啊？” “哪个大模型适合写代码？” “R 和 Python 用什么 IDE 比较好？” 每次都要翻聊天记录找链接，实在太麻烦了。于是，我决定把这些年收藏的优质资源系统性地整理出来，做成一个完整的资源导航页面。 今天就把这份清单分享给大家。全文 7000+ 字，建议先收藏再看！ 为什么要做这个清单？ 说实话，生物信息学的学习曲线真的很陡峭： 生物学背景的同学，编程是拦路虎 计算机背景的同学，生物知识是天书 两边都懂一点的，不知道从哪里开始系统学习 市面上的资源虽然很多，但良莠不齐。我见过太多人因为找不到合适的资源，在入门阶段就放弃了。 所以这个清单的目标很明确： ✅ 只收录真正有价值的资源 ✅ 覆盖从入门到进阶的完整路径 ✅ 紧跟最新技术发展（尤其是 AI 工具） 📋 清单概览 这份清单包含 13 个主题板块，190+ 个精选资源，涵盖： 板块 资源数 适合人群 🔬 基本资源 15+ 所有人 📚 生物信息学资源 20+ 入门&amp;进阶 🏛️ 研究机构与大型项目 18+ 科研工作者 🛠️ 工具与教程 12+ 实践者 🧬 AI 生物学工具 25+ 前沿研究者 🤖 AI 大语言模型 40+ 效率提升 📊 可视化工具 5+ 数据分析 💻 数据分析工具 25+ 日常开发 🎓 课程与视频 5+ 系统学习 完整清单在这里 👉 资源导航页面 下面我挑几个最值得关注的板块详细说说。 🧬 重点板块一：AI 生物学工具 这是 2024-2026 年变化最大的领域！不夸张地说，AI 正在重新定义生物学研究。 1. 蛋白质结构预测 - 已经是基操了 还记得 2020 年 AlphaFold 2 横空出世的震撼吗？现在： AlphaFold 3 - 最新版本，精度更高，速度更快 数据库已经有 2 亿+ 蛋白质结构 基本上你想要的蛋白，都能找到预测结构 RoseTTAFold - Baker Lab 出品，开源实现 在某些蛋白质家族上比 AlphaFold 还准 ESMFold - Meta 出品，最快 宏基因组蛋白结构图谱达到 6 亿+ 适合大规模筛选 实用建议：现在做蛋白相关研究，第一步就是去 AlphaFold Database 查结构。实验验证之前先预测一下，能省好多时间和经费！ 2. 蛋白质设计 - 从预测到创造 更激进的是，AI 现在不只能预测结构，还能从头设计蛋白质： ProteinMPNN - 给定结构，生成序列 RFdiffusion - 扩散模型设计蛋白 Chroma - Generate Biomedicines 的商业化产品 这个方向太火了，已经有好几个 Biotech 公司拿到巨额融资。未来的药物设计，可能不需要从自然界筛选，而是直接 AI 生成。 3. 分子对接 - 药物发现的加速器 DiffDock - 扩散模型做分子对接 比传统方法快 100 倍 精度还更高 我的观察：传统的虚拟筛选管线正在被 AI 快速替代。如果你做药物发现，不学这些工具就真的落伍了。 🤖 重点板块二：AI 大语言模型 大模型不只是聊天工具，用对了能让科研效率翻倍！ 1. 通用大模型 - 日常必备 国际版： - ChatGPT (GPT-5.3) - 最强综合能力，但需要魔法上网 - Claude 4 - 长文本之王（可以处理整本书） - 我现在写论文都先让 Claude 帮忙润色 - Gemini - Google 出品，多模态能力强 国内版： - Kimi - 长文本处理很不错，免费！ - DeepSeek - 推理能力强，适合做数学题和代码 - 豆包 - 字节出品，速度快 实用技巧： - 写代码用 Claude 或 DeepSeek - 读文献用 Kimi（一次能塞好几篇论文） - 画图解用 GPT-5.3 或 Gemini 2. 生物医学专用模型 - 专业问题找专家 BioGPT - 微软训练的生物医学文本生成模型 Med-PaLM - Google 的医疗专用模型 GeneGPT - NCBI 出品，专门回答基因问题 举个例子：我最近在研究一个不熟悉的基因，直接问 GeneGPT，它给出的解释比我自己查文献快多了。 3. AI 辅助工具 - 效率加倍器 Cursor - AI 代码编辑器 强烈推荐！ 写代码效率至少提升 50% 直接在编辑器里问 AI，不用来回切换 GitHub Copilot - AI 编程助手 代码补全非常智能 学生可以免费用 Consensus - AI 文献搜索 输入问题，直接给你文献总结 比自己翻 PubMed 快太多 Elicit - AI 研究助手 帮你做系统性文献综述 自动提取论文关键信息 真心话：如果你还在纯手工写代码、读文献，真的该试试这些工具了。工具用得好，下班下得早！ 💻 重点板块三：数据分析工具链 工欲善其事，必先利其器。这个板块我花了很多心思整理。 1. IDE 选择 - 找到最适合你的 R 用户： - RStudio - 老牌IDE，功能完善 - Positron - Posit 新产品 - 同时支持 Python 和 R - 界面现代化，推荐尝鲜 Python 用户： - VS Code - 万能编辑器 - 轻量、插件丰富 - 我现在 80% 的代码都在 VS Code 写 PyCharm - 专业 Python IDE 功能强大，但比较重 Jupyter Lab - 交互式分析 数据探索必备 出图特别方便 2. 包管理工具 - 依赖管理不再头疼 Python 环境： - uv - 新星工具！ - 用 Rust 写的，比 pip 快 10-100 倍 - 强烈推荐，真的快到飞起 Poetry - 现代化依赖管理 比 pip + requirements.txt 好用太多 Conda - 跨语言包管理 生信领域的标配 R 环境： - rig - R 版本管理 - 多版本 R 切换很方便 renv - 项目环境管理 保证项目的可复现性 避坑经验：很多人遇到的 “我电脑上能跑，你电脑上不能跑” 问题，90% 是因为环境管理不当。学会用这些工具，能省无数时间！ 📚 重点板块四：学习路径推荐 资源虽好，但如何系统学习才是关键。根据我的经验： 新手路径（0-6 个月） 编程基础 Python：Rosalind - 生信编程练习，边玩边学 R：直接上手 Bioconductor，边用边学 生信基础 生信技能树 - 中文教程丰富 The Carpentries - 系统化培训 实战项目 跟着 NGS Analysis Tutorial 做一遍 去 Kaggle 找生信竞赛练手 进阶路径（6-18 个月） 深入特定方向 单细胞：从 Seurat 入手 蛋白质：学 AlphaFold 和分子对接 关注前沿动态 定期看 bioRxiv 预印本 关注几个大牛的 Twitter/X 参与开源项目 去 GitHub 找感兴趣的项目贡献代码 建立自己的作品集 高级路径（18 个月+） 发表研究 找到细分领域的 gap 开发自己的工具/算法 建立影响力 写技术博客分享经验 在社区里活跃 核心建议：不要囤积资源！ 选 2-3 个最适合你的，深入学习，比收藏 100 个资源更有用。 🏛️ 值得关注的研究机构 如果你想了解最前沿的研究，关注这些机构准没错： 国际顶尖机构 Wellcome Sanger Institute - 基因组学研究先驱 人类基因组计划的主力军 Broad Institute - 哈佛-MIT 联合研究所 单细胞测序技术的引领者 Arc Institute - 新兴研究机构 Patrick Hsu 创立，专注前沿生物技术 大型科研计划 Human Cell Atlas - 人类细胞图谱计划 想了解单细胞领域，这是必看的 Chan Zuckerberg Initiative - CZI CELLxGENE 单细胞数据门户超好用 实用建议：这些机构经常有公开的讲座和培训，可以关注他们的 YouTube 频道。 💡 我的使用心得 1. 建立自己的工具箱 不要什么都想学，根据你的研究方向，精选 10-15 个常用工具深度掌握。 我自己的常用工具箱： - IDE: VS Code + Jupyter Lab - 包管理: uv + Conda - 代码助手: Cursor + GitHub Copilot - 文献管理: Zotero - 大模型: Claude + Kimi - 绘图: ggplot2 + BioRender 2. 善用 AI 提效 能让 AI 做的，就不要手工做： - 读文献 → 用 Consensus 或 Elicit - 写代码 → 用 Cursor 或 Copilot - 画图 → 用 BioRender 或 GPT-4 - 润色文章 → 用 Claude 但记住：AI 是助手，不是替代品。 批判性思维永远不能丢。 3. 持续学习的节奏 不要试图一次性学完所有东西！ 建议： 每周固定 1-2 个小时学新工具 每月读 2-3 篇前沿论文 每季度学一个新技能 关键是持续，而不是爆发。 📍 常见问题 Q1: 这么多资源，从哪里开始？ A: 根据你的目标选择： - 想快速上手 → 先看 工具与教程 板块 - 想系统学习 → 先看 课程与视频 板块 - 想了解前沿 → 先看 AI 生物学工具 板块 Q2: 免费资源够用吗？要不要付费？ A: 90% 的情况下免费资源就够了。 付费工具我只推荐： - GitHub Copilot（学生免费） - ChatGPT Plus（如果你高频使用） 其他的等你真正有需求了再考虑。 Q3: 英文不好怎么办？ A: 1. 优先用国内资源：生信技能树、生信菜鸟团的中文教程很全面 2. 借助翻译工具：DeepL 的翻译质量很高 3. 边用边学：实践中积累专业词汇，比死记硬背快 Q4: 资源会持续更新吗？ A: 会的！我会保持每月更新，添加新的优质资源。 完整清单在这里 👉 资源导航页面 写在最后 这份清单耗费了我大量心血，但如果能帮到一个人少走弯路，就值了。 生物信息学的学习之路很长，但不孤单。 我们都是在这条路上摸索前进的。 几句肺腑之言： 不要被资源的数量吓到 - 选择适合你的，深入学习 不要闭门造车 - 多参与社区讨论，分享你的经验 不要停止学习 - 这个领域变化太快，保持好奇心 不要忘记初心 - 我们做这些，是为了推动科学进步 🙏 致谢 这份清单的诞生离不开： - 生信社区的前辈们无私分享 - 师兄师姐们的经验传授 - 开源社区的贡献者们 如果你觉得有帮助，欢迎分享给更多人！ 有任何建议或补充，欢迎在评论区留言，或者直接访问 资源导航页面 查看完整内容。 相关阅读： - 计算生物学成长路线图 （附路线图） 本文约 7000 字，阅读时间约 15 分钟 最后更新：2026-02-25 转载请注明出处","categories":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/categories/note/"}],"tags":[{"name":"生物信息学","slug":"生物信息学","permalink":"https://landau1994.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"资源导航","slug":"资源导航","permalink":"https://landau1994.github.io/tags/%E8%B5%84%E6%BA%90%E5%AF%BC%E8%88%AA/"},{"name":"AI工具","slug":"AI工具","permalink":"https://landau1994.github.io/tags/AI%E5%B7%A5%E5%85%B7/"},{"name":"学习路径","slug":"学习路径","permalink":"https://landau1994.github.io/tags/%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/"}],"author":"研精极锐"},{"title":"test mermaid","slug":"mermaid_example","date":"2025-01-15T11:29:22.000Z","updated":"2025-01-15T12:46:35.219Z","comments":true,"path":"2025/01/15/mermaid_example/","permalink":"https://landau1994.github.io/2025/01/15/mermaid_example/","excerpt":"","text":"sequenceDiagram Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob: How about you? Bob--&gt;&gt;John: Jolly good! graph TD A[开始] --&gt; B{判断} B -- Yes --&gt; C[执行] B -- No --&gt; D[跳过] C --&gt; E[结束] D --&gt; E","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://landau1994.github.io/tags/AI/"}],"author":"研精极锐"},{"title":"udl-chap3-4","slug":"udl-chap3-4","date":"2025-01-15T11:29:22.000Z","updated":"2025-01-15T12:54:30.082Z","comments":true,"path":"2025/01/15/udl-chap3-4/","permalink":"https://landau1994.github.io/2025/01/15/udl-chap3-4/","excerpt":"","text":"chapter 3: Shallow neural networks 如上一章末尾所言，第3章讨论了浅层神经网络，它比线性回归稍复杂，但能描述更广泛的输入/输出关系。这章主要以浅层神经网络为例，初步介绍神经网络的基本概念。浅层神经网络的架构，激活函数（主要介绍ReLU），以及universal approximation theorem 浅层神经网络有一个隐藏层。它们（i）计算输入的多个线性函数，（ii）将每个结果通过一个激活函数，然后（iii）取这些激活的线性组合以形成输出。浅层神经网络通过将输入空间划分为连续的分段线性区域来基于输入 ( x ) 进行预测 ( y )。只要有足够的隐藏单元（神经元），浅层神经网络可以任意精确地近似任何连续函数。 第4章讨论了深度神经网络，它通过增加更多的隐藏层来扩展本章中的模型。第5-7章描述了如何训练这些模型。 chapter 4: deep neural networks 这更进一步，初步介绍了深层神经网络。 h1 = a[β0 + Ω1x] h2 = a[β1 + Ω2h1] h3 = a[β2 + Ω2h2] ⋮ hK = a[βK − 1 + ΩKhK − 1] y = βK + ΩKhK graph LR x1((x₁)) --&gt; h11((h₁₁)) x1 --&gt; h12((h₁₂)) x1 --&gt; h13((h₁₃)) x2((x₂)) --&gt; h11 x2 --&gt; h12 x2 --&gt; h13 h11 --&gt; h21((h₂₁)) h12 --&gt; h21 h13 --&gt; h21 h11 --&gt; h22((h₂₂)) h12 --&gt; h22 h13 --&gt; h22 h21 --&gt; y((y)) h22 --&gt; y style x1 fill:#f9f,stroke:#333,stroke-width:2px style x2 fill:#f9f,stroke:#333,stroke-width:2px style h11 fill:#bbf,stroke:#333,stroke-width:2px style h12 fill:#bbf,stroke:#333,stroke-width:2px style h13 fill:#bbf,stroke:#333,stroke-width:2px style h21 fill:#fbb,stroke:#333,stroke-width:2px style h22 fill:#fbb,stroke:#333,stroke-width:2px style y fill:#bfb,stroke:#333,stroke-width:2px 最重要的是末尾的： 深层神经网络与浅层神经网络的比较： Ability to approximate different functions Number of linear regions per parameter Depth efficiency（深层优势，作者在末尾的note部分举了一些理论的例子） Large, structured inputs (如图像，实际上只能深层) Training and generalization 在本章中，我们首先考虑了当我们组合两个浅层网络时会发生什么。我们论证了第一个网络“折叠”输入空间，而第二个网络则对其应用分段线性函数。当输入空间被折叠到自身时，第二个网络的效果会被复制。 我们接着证明了这种浅层网络的组合是深度网络中两层的特例。我们将每一层中的 ReLU 函数解释为在多个位置裁剪输入函数，并在输出函数中创造“新的点”。我们引入了超参数的概念，就目前所见的网络而言，超参数包括每层中隐藏单元的数量。 最后，我们比较了浅层和深度网络。我们发现：(i) 两种网络都能以足够的容量近似任何函数；(ii) 深度网络每个参数产生更多的线性区域，使得某些函数能够用深度网络更有效地近似；(iv) 大型、结构化的输入（如图像）最好在多个阶段处理；以及 (v) 在实践中，最好的结果往往是使用具有多层的深度网络获得的。 现在我们已经理解了深度和浅层网络模型，我们将注意力转向训练它们。在下一章中，我们将讨论损失函数。对于任何给定的参数值 φ，损失函数返回一个单一数值，表示模型输出与训练数据集的真实预测之间的不匹配程度。在第 6 章和第 7 章中，我们将讨论训练过程本身，即我们如何寻找能最小化这个损失的参数值。","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"AI","slug":"AI","permalink":"https://landau1994.github.io/tags/AI/"}],"author":"研精极锐"},{"title":"北岛-必定有人重写爱情","slug":"北岛-必定有人重写爱情","date":"2025-01-12T02:25:53.000Z","updated":"2025-01-12T02:36:57.909Z","comments":true,"path":"2025/01/12/北岛-必定有人重写爱情/","permalink":"https://landau1994.github.io/2025/01/12/%E5%8C%97%E5%B2%9B-%E5%BF%85%E5%AE%9A%E6%9C%89%E4%BA%BA%E9%87%8D%E5%86%99%E7%88%B1%E6%83%85/","excerpt":"","text":"《我们》 北岛 失魂落魄 提着灯笼追赶春天 伤疤发亮，杯子转动 光线被创造 看那迷人的时刻： 盗贼潜入邮局 信发出叫喊 钉子啊钉子 这歌词不可更改 木柴紧紧搂在一起 寻找听众 寻找冬天的心 河流尽头 船夫等待着茫茫暮色 必有人重写爱情","categories":[{"name":"others","slug":"others","permalink":"https://landau1994.github.io/categories/others/"}],"tags":[{"name":"art","slug":"art","permalink":"https://landau1994.github.io/tags/art/"}],"author":"北岛"},{"title":"知乎上的有趣的概率论与线性代数问题汇总","slug":"知乎上的有趣的概率论与线性代数问题汇总","date":"2025-01-12T02:23:53.000Z","updated":"2025-01-12T02:24:34.961Z","comments":true,"path":"2025/01/12/知乎上的有趣的概率论与线性代数问题汇总/","permalink":"https://landau1994.github.io/2025/01/12/%E7%9F%A5%E4%B9%8E%E4%B8%8A%E7%9A%84%E6%9C%89%E8%B6%A3%E7%9A%84%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/","excerpt":"","text":"概率论 圆上随机取点，在同一个半圆内的概率有多大？ - Dylaaan的文章 - 知乎 https://zhuanlan.zhihu.com/p/17491774604","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}],"author":"夏目沉吟"},{"title":"udl-chap1-2","slug":"udl-chap1-2","date":"2025-01-12T01:58:17.000Z","updated":"2025-01-12T02:20:04.397Z","comments":true,"path":"2025/01/12/udl-chap1-2/","permalink":"https://landau1994.github.io/2025/01/12/udl-chap1-2/","excerpt":"","text":"信息 本书网站见，https://udlbook.github.io/udlbook/ 如何阅读这本书 第一章是概论，作者讲了应该如何学习这本书， 本书中大多数剩余章节包含主体文本、注释部分和一组习题。 主体文本旨在自成一体，可以在不参考章节其他部分的情况下阅读。尽可能地，背景数学被纳入主体文本中。然而，对于较大的主题，如果它会分散论点的主线，背景材料会被附录处理，并在边缘提供参考。书中大多数符号遵循附录A的符号标准。然而，一些约定不太广泛使用，鼓励读者在继续之前查阅附录A。 主体文本包括许多关于深度学习模型和结果的新插图和可视化。我努力提供现有思想的新解释，而不仅仅是整理他人的工作。深度学习是一个新领域，有时现象并不完全清楚。我会明确指出哪些地方情况不明，以及我的解释应谨慎对待。 参考文献仅在章节主体中包含结果被展示的地方。相反，参考文献可以在章节末尾的注释部分找到。我通常不在主体文本中尊重历史先例；如果某个当前技术的前身不再有用，我将不会提及。然而，领域的历史发展在注释部分中进行了描述，并且希望能公平地给予相应的信用。 注释部分按段落组织，提供进一步阅读的指引。它们应帮助读者在子领域内定位自己，并理解其与机器学习其他部分的关系。与主体文本相比，注释部分的自成体系程度较低。根据你的背景知识和兴趣水平，你可能会发现这些部分的用处有所不同。 每章都有若干相关习题。在主体文本中，当应该尝试习题时，会在边缘进行引用。正如乔治·波利亚所言：“数学，您看，不是一项观众运动。”他是对的，我强烈建议您在阅读过程中尝试习题。在某些情况下，它们提供的见解将帮助您理解主体文本。对于在相关网站（http://udlbook.com）上提供答案的习题，会用星号进行标注。此外，帮助您理解本书中思想的Python笔记本也可以通过该网站获得，这些笔记本也在文本的边缘进行了引用。实际上，如果您觉得自己有些生疏，现在可能值得先学习一下关于背景数学的笔记本。 不幸的是，人工智能研究的快速发展使得本书不可避免地将是一项持续的工作。如果您发现某些部分难以理解、明显的遗漏或似乎多余的部分，请通过相关网站与我们联系。我们可以共同努力使下一版更好。 有监督学习 监督学习模型是一个函数 y = f(x, ϕ)，它将输入 x 与输出 y 关联起来，具体关系由参数 ϕ 决定。为了训练模型，我们在训练数据集 {xi, yi} 上定义损失函数 L(ϕ)，量化模型预测 f(xi, ϕ) 与观察到的输出 yi 之间的差异。接着，我们寻找最小化损失的参数，并在不同的测试数据集上评估模型，以检验其对新输入的泛化能力。 接下来的章节（3-9）扩展了这些概念。第3章讨论了浅层神经网络，它比线性回归稍复杂，但能描述更广泛的输入/输出关系。第4章介绍深层神经网络，能够用更少的参数描述复杂函数，并在实践中表现更好。第5章研究不同任务的损失函数，并揭示最小二乘损失的理论基础。第6和第7章讨论训练过程，第8章探讨如何衡量模型性能，第9章考虑正则化技术，以提高模型性能。","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"AI","slug":"AI","permalink":"https://landau1994.github.io/tags/AI/"}],"author":"夏目沉吟"},{"title":"待完成系列博文清单","slug":"待完成系列博文清单","date":"2025-01-12T01:36:05.000Z","updated":"2025-01-12T02:28:39.600Z","comments":true,"path":"2025/01/12/待完成系列博文清单/","permalink":"https://landau1994.github.io/2025/01/12/%E5%BE%85%E5%AE%8C%E6%88%90%E7%B3%BB%E5%88%97%E5%8D%9A%E6%96%87%E6%B8%85%E5%8D%95/","excerpt":"","text":"20250112 待完成的系列博文主题中，除随机过程（这个可能和深度学习的读书笔记一起更新）外，其余两本书的阅读计划结合研究实际进行系统性完善与更新。鉴于近期研究任务繁重，拟先行积累相关研究素材与理论洞见，待条件成熟时再行更新。笔者认为，学术阅读应与实际研究相结合，方能避免思维陷入被动接受的状态，确保学术思想的独立性与创造性。同时，唯有坚定学术信念，持续践行研究规划，方能确保研究工作的系统性与完整性。 [ ] Dobrow的随机过程 [ ] igraph 学习笔记 [ ] 医学免疫学 计划的读书笔记系列 - [ ] 《Understanding Deep Learning》 - [ ] 《ChatGPT进阶：提示工程入门》主要用于写代码，和一些简单任务 - [ ] 《我的科研助理：ChatGPT全方位使用指南》主要用于写代码，和一些简单任务","categories":[{"name":"orthers","slug":"orthers","permalink":"https://landau1994.github.io/categories/orthers/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}],"author":"夏目沉吟"},{"title":"cursor与cline","slug":"cursor与cline","date":"2025-01-12T01:11:09.000Z","updated":"2025-01-12T01:25:18.770Z","comments":true,"path":"2025/01/12/cursor与cline/","permalink":"https://landau1994.github.io/2025/01/12/cursor%E4%B8%8Ecline/","excerpt":"","text":"结论 就可用性而言，目前用cursor较为方便，一个比较好的实用教程是：AI编程神器Cursor】不止写代码，5种玩法让你全面提效，小白宝藏! cline一个搞笑的不易用之处，是其需要耗费漫长的时间，等待响应，github上有人说充钱可以解决，但是我试了，好像不太行。 CSDN上的一个测评 2024年12月，我体验了一下AI编码辅助工具，本文我们将对比分析GitHub Copilot、Cursor和Cline这三款AI工具，评估它们在自动代码生成和AI辅助编码方面的优缺点。 GitHub Copilot 是一款IDE插件，需要结合JetBrains或VS Code使用。 优点 - 高效的代码补全：GitHub Copilot能够实时分析代码上下文并提供建议，帮助开发者快速完成代码块。 - 跨语言支持：支持多种编程语言，满足不同开发者的需求。 - 学习与成长：Copilot通过不断学习开发者的代码风格和习惯来提高建议质量。 缺点 - 依赖性：过度依赖Copilot可能导致程序员失去自主思考和手动编写代码的能力。 - 隐私问题：Copilot需要访问代码库以提供建议，这可能引发隐私担忧。 - 成本问题：一个月的免费体验期，之后每个月10美金，或者每年100美金。 Cursor 是一款基于VS Code开发的IDE，可单独下载安装使用。 优点 - 提高开发效率：通过智能补全、自动错误修复和优化建议，开发者可以更快地完成代码编写和调试工作。 - 降低错误率：Cursor的代码审查和自动修复功能有助于避免常见的编程错误。 - 增强代码可读性：AI的优化建议不仅提升了代码的性能，还能帮助开发者编写更加简洁易读的代码。 - 实时反馈与协作：通过与AI的实时对话，开发者可以随时获得帮助。 - 价格：有免费版，Pro版本美月20美金。 缺点 - 基础功能缺失：Cursor的基础功能可能不够完善，不能称之为一个可靠的IDE。 - 服务不稳定：Cursor的服务可能不够稳定，影响使用体验。 Cline 是一款IDE插件，需要结合JetBrains或VS Code使用。 优点 - 全面的项目支持：Cline不仅提供代码补全，还能执行复杂的软件开发任务，覆盖开发全流程。 - 灵活的模型选择：支持多种API提供商和模型，可以根据需求和预算选择最适合的模型。 - 成本效益高：特别是使用DeepSeek等模型时，成本显著降低。 - 人机协作：每一步操作都需要用户确认，保证了安全性。 - 成本：预付费模式，需要绑定银行卡或Paypal，但之后选择Google Gemini模型的话，可以免费使用（本文写作时仍然可以）。 缺点 - 开源劣势：作为开源工具，Cline可能在某些高级功能上受到限制。 - 成本上升：由于基于token的消耗模式，随着使用频率的增加，开发成本也可能迅速上升。 总结 GitHub Copilot、Cursor和Cline各有其独特的优缺点。GitHub Copilot以其高效的代码补全和跨语言支持著称，但隐私和依赖性问题不容忽视。Cursor通过智能补全和实时协作提高了开发效率，但其基础功能和稳定性有待提升。Cline则以其全面的项目支持和灵活的模型选择脱颖而出，但成本和开源劣势也需考虑。开发者应根据自身需求和偏好选择最适合的工具。 版权声明：本文为转载的博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。 原文链接：https://blog.csdn.net/xidianjiapei001/article/details/144374563","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"AI","slug":"AI","permalink":"https://landau1994.github.io/tags/AI/"}],"author":"夏目沉吟"},{"title":"两首由deepseek生成的北岛风格的诗","slug":"一首北岛风格的诗","date":"2025-01-12T01:01:25.000Z","updated":"2025-01-12T02:38:53.740Z","comments":true,"path":"2025/01/12/一首北岛风格的诗/","permalink":"https://landau1994.github.io/2025/01/12/%E4%B8%80%E9%A6%96%E5%8C%97%E5%B2%9B%E9%A3%8E%E6%A0%BC%E7%9A%84%E8%AF%97/","excerpt":"","text":"《消解》 意义像沙漏中的沙 一粒粒坠落在虚无的深渊 说教是纸做的剑 刺向风的胸膛 碎成苍白的蝴蝶 确定在镜中模糊成雾 我们都是雾中的影子 寻找失去的形状 在消解的世界里 我们都是自己的谜题 《习题》 爱情和尊严 同时转身 留下一个 永远解不开的方程 清晨的镜子 照见了 一个数字的死亡 最后的算式 是水泥台阶上的 血迹 现在我终于明白 人生没有标准答案 只有 永远解不完的 习题","categories":[{"name":"others","slug":"others","permalink":"https://landau1994.github.io/categories/others/"}],"tags":[{"name":"art","slug":"art","permalink":"https://landau1994.github.io/tags/art/"}],"author":"deepseek"},{"title":"artin_review","slug":"artin-review","date":"2025-01-11T17:37:44.000Z","updated":"2025-01-12T01:10:12.053Z","comments":true,"path":"2025/01/12/artin-review/","permalink":"https://landau1994.github.io/2025/01/12/artin-review/","excerpt":"","text":"2024.03-2025.01 # 缘起 见：能说一本或几本在你在学数学路上对你影响最大的一本书吗？ - 万物皆数数海拾贝的回答 - 知乎 https://www.zhihu.com/question/555672024/answer/3418569722 如何从群Zn×，环ℤn，到𝔽p，再到Galois理论。你可以将这篇书评视为关于Artin一书的一个学习纲领，特别是在这篇书评的末尾，我们还附上一些近年来出现在国内外的数学考试中的习题以及解答，这些习题没有超过Artin一书包含的内容。 Artin的编排对初学者不是特别友好，比如第二版一开始就是线性代数，或许会让一些已经被线性代数产生审美疲劳的读者劝退，但是等仔细耐着性子读完之后，你会发现，这些线性代数的知识，其实与后面的抽象代数的知识并不是割裂的。笔者在将Artin的书通读了三遍之后，呈现给一个笔者认为较为容易理解的目次。笔者觉得Artin这本书，仅管缺点诸多，与Artin风格类似的，如Dummit，我觉得也很好。但是Artin这本书最大的优点，是将线性代数和抽象代数融合为一体，具体就是通过表示论的知识穿插将两者结合起来，几乎没有一本面向本科的教材，能够做的这么好。","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}],"author":"夏目沉吟"},{"title":"learn_python_001","slug":"learn-python-001","date":"2021-12-04T13:19:59.000Z","updated":"2025-01-11T17:16:31.837Z","comments":true,"path":"2021/12/04/learn-python-001/","permalink":"https://landau1994.github.io/2021/12/04/learn-python-001/","excerpt":"","text":"Learn_python_001 Top K problem 🟧❓ The problem Top K question: 输入整数数组 arr ，找出其中最小的 k 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。 示例 1： 输入：arr = [3,2,1], k = 2 输出：[1,2] 或者 [2,1] 示例 2： 输入：arr = [0,1,2,1], k = 1 输出：[0] 限制： 0 &lt;= k &lt;= arr.length &lt;= 10000 0 &lt;= arr[i] &lt;= 10000 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明 📄 code 有三种解法，解法二，三，是符合题目要求的两种（因为题目也考察了排序算法）。详解见https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/solution/jian-zhi-offer-40-zui-xiao-de-k-ge-shu-j-9yze/ class Solution1: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: lstStd = arr lstStd.sort() res = lstStd[:k] return res### solution2:### wirte your own quick sort### This was taken from https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/solution/jian-zhi-offer-40-zui-xiao-de-k-ge-shu-j-9yze/class Solution2: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: def quick_sort(arr, l, r): if l &gt;= r: return i, j = l, r while i &lt; j: while i &lt; j and arr[j] &gt;= arr[l]: j -= 1 while i &lt; j and arr[i] &lt;= arr[l]: i += 1 arr[i], arr[j] = arr[j], arr[i] arr[l], arr[i] = arr[i], arr[l] quick_sort(arr, l, i - 1) quick_sort(arr, i + 1, r) quick_sort(arr, 0, len(arr) - 1) return arr[:k]class Solution3: def getLeastNumbers(self, arr: List[int], k: int) -&gt; List[int]: if k &gt;= len(arr): return arr def quick_sort(l, r): i, j = l, r while i &lt; j: while i &lt; j and arr[j] &gt;= arr[l]: j -= 1 while i &lt; j and arr[i] &lt;= arr[l]: i += 1 arr[i], arr[j] = arr[j], arr[i] arr[l], arr[i] = arr[i], arr[l] if k &lt; i: return quick_sort(l, i - 1) if k &gt; i: return quick_sort(i + 1, r) return arr[:k] return quick_sort(0, len(arr) - 1) 📏 测试 我们用如下代码测试： ### import require packageimport numpy as npimport random import matplotlib.pyplot as pltimport timeimport seaborn as snsfrom typing import List, Dict, Tuple, Sequencedef ProgramTime(N,func): lst = [random.randrange(10**7) for n in range(N)] start = time.perf_counter() func(lst,10) runtime = (time.perf_counter() - start) return runtimeProgramTimeVec = np.vectorize(ProgramTime)### define theory functiondef f1(n, k): return k*ndef f2(n, k): return k*n*np.log(n)### plot test curven = np.arange(1, 2000)colors = sns.color_palette(\"Set1\")plt.plot(n, f1(n, 1e-7), c=colors[0])plt.plot(n, f2(n, 1e-7), c=colors[1])plt.plot(n, ProgramTimeVec(n,sol1.getLeastNumbers),c=colors[2])plt.plot(n, ProgramTimeVec(n,sol2.getLeastNumbers),c=colors[3])plt.plot(n, ProgramTimeVec(n,sol3.getLeastNumbers),c=colors[4])plt.xlabel('Size of input (n)', fontsize=16)plt.ylabel('Time', fontsize=16)#plt.legend(['$\\mathcal{O}(n^2)$', '$\\mathcal{O}(n \\log n)$'], loc='best', fontsize=20)plt.legend(['$\\mathcal{O}(n)$', '$\\mathcal{O}(n \\log n)$','sol1', 'sol2','sol3'], loc='best', fontsize=20)fig = plt.gcf()fig.set_size_inches(8, 6)plt.savefig(\"../fig/test.png\",dpi=300) 结果如下, 可以看出，使用解法三，也就是基于快速排序的数组划分，可以实现线性时间： figure","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"Python","slug":"Python","permalink":"https://landau1994.github.io/tags/Python/"}],"author":"夏目沉吟"},{"title":"Epigenome_track_plot","slug":"Epigenome-track-plot","date":"2021-10-27T11:06:50.000Z","updated":"2025-01-11T17:16:31.806Z","comments":true,"path":"2021/10/27/Epigenome-track-plot/","permalink":"https://landau1994.github.io/2021/10/27/Epigenome-track-plot/","excerpt":"","text":"Epigenome track visulalization by R Recently, I create a new repo to visulizaiton Epigenome track by ggplot2() ecosytem. Details can be found at https://github.com/Landau1994/PlotEpiTrackByR","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}],"author":"夏目沉吟"},{"title":"reading_note_20201206","slug":"reading-note-20201206","date":"2020-12-06T12:49:41.000Z","updated":"2025-01-11T17:16:31.856Z","comments":true,"path":"2020/12/06/reading-note-20201206/","permalink":"https://landau1994.github.io/2020/12/06/reading-note-20201206/","excerpt":"","text":"题目：[3D] bioRxiv 2020 3D Genome Contributes to Protein-Protein Interactome - 生物问题：3D 基因组的与蛋白质互作是否存在关系？ 实验设计： PPI数据：收集不同数据库蛋白质互作数据，作为正样本；从不同亚细胞定位的非PPI互作蛋白中抽样，作为负样本； HiC数据：不同细胞系的HiC数据，采用相同方法重新处理，使得互作矩阵分辨率相同； 从3D基因组信息中，重建基因的空间信息，采用不同的机器学习方法预测PPI数据 分析思路： 分组比较PPI gene counterparts 组和 Non-PPI组的分布图，HiCHeatmap，Gene-gene pair projections of PPIs overlaid on Hi-C heatmaps.，发现了PPI gene counterparts 在空间更为邻近；（Figure2,3,4）； 分析至少一个蛋白有信号肽的PPI（SigPep PPI）与无信号肽PPI(Non-SigPep PPI)的关系，得到结论是：“This can be explained that for the interacting proteins that are brought together by signal peptides, their gene counterparts can be more freely located on the 3D genome, with larger spatial distances“ 用3维基因组的信息在不同的模型中预测PPI，发现引入3维基因组的信息之后，” the prediction accuracy in terms of AUC can be significantly improved if 3D genome information is employed“（Table1)，由于是预印本，特征工程的那一部分作者并没有详细写； 评论： 目前有很多研究组致力于解析3D基因组结构和疾病的关系，报道了一些3D基因组结构改变，影响转录，从而影响疾病的案例；本文的分析虽然简单，但是给出了3D基因组结构对于更为下游的蛋白质互作有影响的可能性。但是这种可能性，还需要更为solid的技术，数据和分析方法来证明； alphafold是基于序列信息来预测蛋白质结构，目前已经取得重大突破。目前也陆续有基于机器学习的方法，整合不同基因组学的数据进行功能基因组学研究的报道。可能在未来的研究中，结合多组学数据，像alphafold这样的AI框架，才能实现更为深刻的蛋白动态功能的预测；","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}],"author":"夏目沉吟"},{"title":"mmet 2020 Age-related loss of gene-to-gene transcriptional coordination among single-cells","slug":"readnote","date":"2020-12-06T03:07:29.000Z","updated":"2025-01-11T17:16:31.858Z","comments":true,"path":"2020/12/06/readnote/","permalink":"https://landau1994.github.io/2020/12/06/readnote/","excerpt":"","text":"在HSC中没有观察到cell-cell variation随着衰老的改变；For example, despite observations of genetic and epigenteic damage in ageing haematopoietic stem cells(HSCs); cell to cell transcriptional variability is not observed. 基因共表达方法的缺陷： First, co-expression networks estimates the direct or indirect correlations between pairs of genes, while an individual gene may be controlled by multiple regulators. Second, each co-expression measure is designed to capture a specific feature that is not necessarily optimal for depicting all types of gene-to-gene transcriptional interrelations ( PCC, linear relatiosnhips) Third, large calculated coexpresion matrices contain a considerable amount of noise, which raises an additional difficulty in explporing their differentiation across cohorts Gcl 本质上是对bcdcorr的bootstrap. 一个重要的观察和建设： As an illustration of the coordination measured by the GCL, consider the expression profiles of cells with N genes, that are represented as points in an N-dimensional space. If the gene expression levels are not independent, the set of points do not fill the N- dimensional space but are rather located near lower-dimensional manifold. The GCL measures has two main advantages. The dependency level is defined with respect to a general dependency form, not specific relations ( such as linear) It can include high-order dependencies between multiple variables","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}],"author":"夏目沉吟"},{"title":"Learn-igraph-More about igraph","slug":"Learnigraph-2-MoreOnIgraph","date":"2020-07-29T15:23:30.000Z","updated":"2025-01-11T17:16:31.826Z","comments":true,"path":"2020/07/29/Learnigraph-2-MoreOnIgraph/","permalink":"https://landau1994.github.io/2020/07/29/Learnigraph-2-MoreOnIgraph/","excerpt":"","text":"0. 说明 我们接着讲更多关于对igraph对象的操作，参考Statistical Network Analysis with igraph第一章。 1. 创建igraph 对象 使用管道 library(igraph)library(igraphdata)library(magrittr)library(tidyverse)library(ggraph)library(ggnetwork)# Notable graphs# make_graph can create some notable graphs. The name of the graph (case insensitive), a character scalar must be suppliced as the edges argument, and other arguments are ignored. (A warning is given is they are specified.)# eg.# Cubical# The Platonic graph of the cube. A convex regular polyhedron with 8 vertices and 12 edges.g &lt;- make_graph(\"Cubical\") %&gt;% set_vertex_attr(\"name\",value = LETTERS[1:4])g %&gt;% add_layout_(with_fr()) %&gt;% plot() 补充：更为实际的案例中，需要使用数据集来创建图。igraph作者提供了一些根据数据集创建好的igraph对象： library(igraphdata)### data:Loads specified data sets, or list the available data sets.data(package=\"igraphdata\")# Data sets in package ‘igraphdata’:# # Koenigsberg Bridges of Koenigsberg from Euler's times# UKfaculty Friendship network of a UK university faculty# USairports US airport network, 2010 December# enron Enron Email Network# foodwebs A collection of food webs# immuno Immunoglobulin interaction network# karate Zachary's karate club network# kite Krackhardt's kite# macaque Visuotactile brain areas and connections# rfid Hospital encounter network data# yeast Yeast protein interaction network 2. 使用iraph对象查看边和点的信息 ### alreadydata(\"macaque\")macaque ## IGRAPH f7130f3 DN-- 45 463 -- ## + attr: Citation (g/c), Author (g/c), shape (v/c), name (v/c) ## + edges from f7130f3 (vertex names): ## [1] V1 -&gt;V2 V1 -&gt;V3 V1 -&gt;V3A V1 -&gt;V4 V1 -&gt;V4t V1 -&gt;MT ## [7] V1 -&gt;PO V1 -&gt;PIP V2 -&gt;V1 V2 -&gt;V3 V2 -&gt;V3A V2 -&gt;V4 ## [13] V2 -&gt;V4t V2 -&gt;VOT V2 -&gt;VP V2 -&gt;MT V2 -&gt;MSTd/p V2 -&gt;MSTl ## [19] V2 -&gt;PO V2 -&gt;PIP V2 -&gt;VIP V2 -&gt;FST V2 -&gt;FEF V3 -&gt;V1 ## [25] V3 -&gt;V2 V3 -&gt;V3A V3 -&gt;V4 V3 -&gt;V4t V3 -&gt;MT V3 -&gt;MSTd/p ## [31] V3 -&gt;PO V3 -&gt;LIP V3 -&gt;PIP V3 -&gt;VIP V3 -&gt;FST V3 -&gt;TF ## [37] V3 -&gt;FEF V3A-&gt;V1 V3A-&gt;V2 V3A-&gt;V3 V3A-&gt;V4 V3A-&gt;VP ## [43] V3A-&gt;MT V3A-&gt;MSTd/p V3A-&gt;MSTl V3A-&gt;PO V3A-&gt;LIP V3A-&gt;DP ## + ... omitted several edges 原作者是这么解释的： This is the standard way of showing (printing) an igraph graph object onthe screen. The top line of the output declares that the object is an igraphgraph, and also lists its most important properties. A four-character longcode is printed first:‘D/U’ The first character is either ‘D’ or ‘U’ and encodes whether the graphis directed or undireted.‘N’ The second letter is ‘N’ for named graphs (see Section 1.2.5). A dashhere means that the graph is not named.‘W’ The third letter is ‘W’ if the graph is weighted (in other words, if thegraph is a valued graph, Section 2.4). Unweighted graphs have a dash inthis position.‘B’ Finally, the fourth is ‘B’ if the graph is bipartite (two-mode, Section ??).For unipartite (one-mode) graphs a dash is printed here.This notation might seem quite dense at first, but it is easy to get used to andconveys much information in a small space. Then two numbers are printed,these are the number of vertices and the number of edges in the graph, 45and 463 in our case. At the end of the line the name of the graph is printed,if there is any. The next line(s) list attributes, meta-data that belong to thevertices, edges or the graph itself. Finally, the edges of the graph are listed.Except for very small graphs, this list is truncated, so that it fits to the screen. 一些基本量的展示，之前讲过，此外，还有更多关于边的操作： ###|V|gorder(macaque)###[1] 45###|E|gsize(macaque)###[1] 463V(macaque)# + 45/45 vertices, named, from f7130f3:# [1] V1 V2 V3 V3A V4 V4t VOT VP MT MSTd/p MSTl # [12] PO LIP PIP VIP DP 7a FST PITd PITv CITd CITv # [23] AITd AITv STPp STPa TF TH FEF 46 3a 3b 1 # [34] 2 5 Ri SII 7b 4 6 SMA Ig Id 35 # [45] 36 E(macaque)# + 463/463 edges from f7130f3 (vertex names):# [1] V1 -&gt;V2 V1 -&gt;V3 V1 -&gt;V3A V1 -&gt;V4 V1 -&gt;V4t V1 -&gt;MT # [7] V1 -&gt;PO V1 -&gt;PIP V2 -&gt;V1 V2 -&gt;V3 V2 -&gt;V3A V2 -&gt;V4 # [13] V2 -&gt;V4t V2 -&gt;VOT V2 -&gt;VP V2 -&gt;MT V2 -&gt;MSTd/p V2 -&gt;MSTl # [19] V2 -&gt;PO V2 -&gt;PIP V2 -&gt;VIP V2 -&gt;FST V2 -&gt;FEF V3 -&gt;V1 # [25] V3 -&gt;V2 V3 -&gt;V3A V3 -&gt;V4 V3 -&gt;V4t V3 -&gt;MT V3 -&gt;MSTd/p# [31] V3 -&gt;PO V3 -&gt;LIP V3 -&gt;PIP V3 -&gt;VIP V3 -&gt;FST V3 -&gt;TF # [37] V3 -&gt;FEF V3A-&gt;V1 V3A-&gt;V2 V3A-&gt;V3 V3A-&gt;V4 V3A-&gt;VP # [43] V3A-&gt;MT V3A-&gt;MSTd/p V3A-&gt;MSTl V3A-&gt;PO V3A-&gt;LIP V3A-&gt;DP # [49] V3A-&gt;FST V3A-&gt;FEF V4 -&gt;V1 V4 -&gt;V2 V4 -&gt;V3 V4 -&gt;V3A # [55] V4 -&gt;V4t V4 -&gt;VOT V4 -&gt;VP V4 -&gt;MT V4 -&gt;LIP V4 -&gt;PIP # + ... omitted several edgesmacaque %&gt;% ends(\"V1|V2\")# # [,1] [,2]# [1,] \"V1\" \"V2\"macaque %&gt;% tail_of(\"V1|V2\")# + 1/45 vertex, named, from f7130f3:# [1] V1macaque %&gt;% head_of(\"V1|V2\")# + 1/45 vertex, named, from f7130f3:# [1] V2macaque %&gt;% neighbors(\"V1\",mode = \"out\")# + 8/45 vertices, named, from f7130f3:# [1] V2 V3 V3A V4 V4t MT PO PIPmacaque %&gt;% neighbors(\"V1\",mode = \"in\")# + 8/45 vertices, named, from f7130f3:# [1] V2 V3 V3A V4 V4t MT PO PIPE(macaque)[.from(\"V1\")] 3. 子图 创建子图 V(macaque)[\"V1\",\"V2\",.nei(\"V1\"),.nei(\"V2\")] %&gt;% induced_subgraph(graph = macaque) %&gt;% summary() ## IGRAPH cb88d15 DN-- 16 156 -- ## + attr: Citation (g/c), Author (g/c), shape (v/c), name (v/c) 连通 is_connected(macaque,mode = \"weak\") ## [1] TRUE is_connected(macaque,mode = \"strong\") ## [1] TRUE 边和点的筛选： V(macaque)[1:4]# + 4/45 vertices, named, from f7130f3:# [1] V1 V2 V3 V3AV(macaque)[c(\"V1\",\"V2\",\"V3\",\"V3A\")]# + 4/45 vertices, named, from f7130f3:# [1] V1 V2 V3 V3 建立边或者点的索引向量： E(macaque)[1:10] %&gt;% as_ids()# [1] \"V1|V2\" \"V1|V3\" \"V1|V3A\" \"V1|V4\" \"V1|V4t\" \"V1|MT\" \"V1|PO\" \"V1|PIP\"# [9] \"V2|V1\" \"V2|V3\" V(macaque)[1:10] %&gt;% as_ids() # [1] \"V1\" \"V2\" \"V3\" \"V3A\" \"V4\" \"V4t\" \"VOT\" \"VP\" # [9] \"MT\" \"MSTd/p\" 类似于算数操作，关于点的操作汇总： data(\"kite\")V(kite)# + 10/10 vertices, named, from 6b7ddad:# [1] A B C D E F G H I JV(kite)[1:3,7:10]# + 7/10 vertices, named, from 6b7ddad:# [1] A B C G H I JV(kite)[degree(kite) &lt; 2]# + 1/10 vertex, named, from 6b7ddad:# [1] JV(kite)[.nei(\"D\")]# + 6/10 vertices, named, from 6b7ddad:# [1] A B C E F GV(kite)[.innei(\"D\")]# + 6/10 vertices, named, from 6b7ddad:# [1] A B C E F GV(kite)[.outnei(\"D\")]# + 6/10 vertices, named, from 6b7ddad:# [1] A B C E F GV(kite)[.inc(\"A|D\")]# + 2/10 vertices, named, from 6b7ddad:# [1] A Dc(V(kite)[\"A\"],V(kite)[\"D\"])# + 2/10 vertices, named, from 6b7ddad:# [1] A Drev(V(kite))# + 10/10 vertices, named, from 6b7ddad:# [1] J I H G F E D C B Aunique(V(kite)[\"A\",\"A\",\"C\",\"C\"])# + 2/10 vertices, named, from 6b7ddad:# [1] A C### Set operationunion(V(kite)[1:5],v(kite)[6:10])# + 2/10 vertices, named, from 6b7ddad:# [1] A Cintersection(V(kite)[1:7],V(kite)[5:10])# + 3/10 vertices, named, from 6b7ddad:# [1] E F Gdifference(V(kite),V(kite)[1:5])# + 5/10 vertices, named, from 6b7ddad:# [1] F G H I JE(kite)# + 18/18 edges from 6b7ddad (vertex names):# [1] A--B A--C A--D A--F B--D B--E B--G C--D C--F D--E D--F D--G E--G F--G F--H G--H# [17] H--I I--JE(kite,path = c(\"A\",\"D\",\"C\"))# + 2/18 edges from 6b7ddad (vertex names):# [1] A--D C--DE(kite)[ V(kite)[1:2] %--% V(kite)[3:4] ]# + 3/18 edges from 6b7ddad (vertex names):# [1] A--C A--D B--DE(kite)[1:3,7:10]# + 7/18 edges from 6b7ddad (vertex names):# [1] A--B A--C A--D B--G C--D C--F D--EE(kite)[seq_len(gsize(kite))[seq_len(gsize(kite)) %%2 == 0]]# + 9/18 edges from 6b7ddad (vertex names):# [1] A--C A--F B--E C--D D--E D--G F--G G--H I--JE(kite)[seq_len(gsize(kite)) %%2 == 0]# + 9/18 edges from 6b7ddad (vertex names):# [1] A--C A--F B--E C--D D--E D--G F--G G--H I--JE(kite)[seq_len(gsize(kite)) %%2]# + 9/18 edges from 6b7ddad (vertex names):# [1] A--B A--B A--B A--B A--B A--B A--B A--B A--BE(kite)[.inc(\"D\")]# + 6/18 edges from 6b7ddad (vertex names):# [1] A--D B--D C--D D--E D--F D--GE(macaque)[.from(\"V1\")]# + 8/463 edges from f7130f3 (vertex names):# [1] V1-&gt;V2 V1-&gt;V3 V1-&gt;V3A V1-&gt;V4 V1-&gt;V4t V1-&gt;MT V1-&gt;PO V1-&gt;PIPE(macaque)[.to(\"V1\")]# + 8/463 edges from f7130f3 (vertex names):# [1] V2 -&gt;V1 V3 -&gt;V1 V3A-&gt;V1 V4 -&gt;V1 V4t-&gt;V1 MT -&gt;V1 PO -&gt;V1 PIP-&gt;V1### The remains are same as Vertices operations","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"Graph","slug":"Graph","permalink":"https://landau1994.github.io/tags/Graph/"},{"name":"Network","slug":"Network","permalink":"https://landau1994.github.io/tags/Network/"}],"author":"Landau1994"},{"title":"LearnSeurat_Intergrate","slug":"LearnSeurat-Intergrate","date":"2020-05-27T03:44:09.000Z","updated":"2025-01-11T17:16:31.816Z","comments":true,"path":"2020/05/27/LearnSeurat-Intergrate/","permalink":"https://landau1994.github.io/2020/05/27/LearnSeurat-Intergrate/","excerpt":"","text":"0. 说明 更为详细的使用，可以参考Seurat官方教程，或者Seurat进行单细胞RNA-seq数据整合。 1. 快速进行 实际分析中，如果细胞数目很多的话，进行整合分析的时候就会很慢，一种方式是将任务提交通过命令行提交到服务器或者集群上运行，并输出。 传递命令行的参数的脚本可以这么写： #### reference base Integration.libPaths(\"/home/user/lib/R/library\")library(Seurat)args = commandArgs(trailingOnly=TRUE)# test if there is at least one argument: if not, return an errorif (length(args)==0) { stop(\"At least one argument must be supplied (input file).n\", call.=FALSE)} ###args[1] seu.list.rds###args[2] seu.intergrated.rds###args[3] UMAPplot.pdf## program...seu.list &lt;- readRDS(file = args[1])for (i in names(seu.list)) { seu.list[[i]] &lt;- SCTransform(seu.list[[i]], verbose = FALSE)}seu.list.features &lt;- SelectIntegrationFeatures(object.list = seu.list, nfeatures = 3000)seu.list &lt;- PrepSCTIntegration(object.list = seu.list, anchor.features = seu.list.features)reference_dataset &lt;- 1names(seu.list)[1]seu.list.anchors &lt;- FindIntegrationAnchors(object.list = seu.list, normalization.method = \"SCT\", anchor.features = seu.list.features, reference = reference_dataset)seu.list.integrated &lt;- IntegrateData(anchorset = seu.list.anchors, normalization.method = \"SCT\")seu.list.integrated &lt;- RunPCA(object = seu.list.integrated, verbose = FALSE)seu.list.integrated &lt;- RunUMAP(object = seu.list.integrated, umap.method = \"umap-learn\", dims = 1:30)saveRDS(seu.list.integrated,file = args[2])#### show Integrated resultplots &lt;- DimPlot(seu.list.integrated, group.by = c(\"orig.ident\", \"cell.type\"))plots &amp; theme(legend.position = \"top\") &amp; guides(color = guide_legend(nrow = 4, byrow = TRUE, override.aes = list(size = 2.5)))ggsave(filename = args[3],width = 12,height = 6) 将其命名为Integrated_ref_based.R 然后在终端输入nohup Rscript Integrated_ref_based.R seu.list.rds seu.intergrated.rds UMAPplot.pdf &gt; log.txt &amp;提交即可； 2. 评论 当然，这个脚本读者还可以根据自己需求加以完善。","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"}],"author":"夏目沉吟"},{"title":"如何定义细胞类型","slug":"如何定义细胞类型","date":"2020-05-16T06:20:28.000Z","updated":"2025-01-11T17:16:31.874Z","comments":true,"path":"2020/05/16/如何定义细胞类型/","permalink":"https://landau1994.github.io/2020/05/16/%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E7%BB%86%E8%83%9E%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"生物学家的传统艺能是进行分类，即使在进入了21世纪，研究的尺度和研究的手段和林奈已经有了很大的不同，但是分类这个古老的问题依然是众多生物研究领域的基础。作为分类这个大问题中的子问题，细胞类型的鉴定是当前细胞生物学研究的一个基础问题和前沿问题。 比如发育生物学和干细胞生物学的研究，确定细胞的谱系是研究细胞命运决定因素等基础研究以及相关临床转化的基础。这个基础有多重要的呢，假如某个大牛声称自己发现了某种神奇的细胞，这个细胞可以带来医学革命，然而这种类型的细胞很可能就不存在，所为的带来革命的宣传都是忽悠和骗局,基于这种类型的细胞的研究都是建在沙子上的高楼大厦。以上不是我们的想象，而是确实发生的现实案例哈佛大学由于心肌干细胞不存在而大量撤稿，国内所有阳性指标论文是否都涉嫌造假？ 最近，Cell Stem Cell杂志上发表了一篇综述，阐述了细胞身份(Cellular Identity)研究的目的，以及基于高通量测序（特别是单细胞测序），成像以及遗传学等新方法来确定细胞身份的方法。 在作者看来，细胞类型鉴定研究的目的分为三条：（图片和引用的话均来自于文献） Detecting features assoicated with a cell type from a pre-defined list of candidates; Identifying new features and cell types through unbiased approaches; Defining Cellular Relationships 从原理上，鉴定细胞身份的不同feature可以概括如下： Figure 1. Defining Cell Types 某个细胞类型的feature可以如何研究呢，见下： Figure 2. Strategies to Detect Molecular Features Associated with a Cell Type 不同类型之间的细胞之间的关系的研究见下： Figure 3. Strategies to Define Cellular Relationships 当然同一类型的细胞在不同组织或者生理条件下会呈现不同的功能。 Figure 4. Cellular Functions Vary with Context 讨论部分最喜欢的一段话是： &gt; Together, our rapidly expanding capability to detect features and functions are revealing that “cell type” that were percevied as monolithic and stable in fact represent composites of multiple cells with distinguishable molecular signatures and have teh capability to adopt new features and functions in new contexts 更多内容请阅读原文。","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"},{"name":"sc-seq","slug":"sc-seq","permalink":"https://landau1994.github.io/tags/sc-seq/"},{"name":"cell biology","slug":"cell-biology","permalink":"https://landau1994.github.io/tags/cell-biology/"}],"author":"夏目沉吟"},{"title":"Learn-SciBet","slug":"Learn-scibet","date":"2020-05-15T14:16:52.000Z","updated":"2025-01-11T17:16:31.815Z","comments":true,"path":"2020/05/15/Learn-scibet/","permalink":"https://landau1994.github.io/2020/05/15/Learn-scibet/","excerpt":"","text":"1. 背景介绍 细胞类型注释是scRNA-seq里非常基础的一步，常见的策略是将基于无监督分群结果的基因差异表达分析结果作为marker,结合先验知识，判断该分群为何种类型。 近年来，随着scRNA-seq的数据集的逐渐积累，也有很多研究组提出了一些基于已有分群结果进行有监督的细胞类型注释的方法，比如scmap，或者Seurat里的TransferData。此外，也有评估相关方法的benchmark研究： SciBet是张泽民老师组最近新发表的一个快捷（实测真的比Seurat的TransferData快，而且效果确实差不多），方便的进行有监督的细胞类型注释的方法。论文见SciBet as a portable and fast single cell type identifier，相关报道见Nature Communications | 张泽民课题组发表单细胞转录组数据快速注释新方法 2. 方法原理简介 如果读者只对软件使用感兴趣的本节可以略过。 根据上面提到的那篇报道，如果用一句话概括SciBet的原理，应该是这样的： 张泽民实验室的博士生李辰威、刘宝琳联合任仙文副研究员开发的SciBet则有效地解决了这一问题：他们从“同一类型的单细胞表达谱服从同一多项分布”这一基本假设出发，对训练集数据中不同细胞类型分别进行建模，进而通过极大似然估计来对测试集细胞进行有监督注释。 接下来我们根据作者论文的方法部分和补充材料，学习一下这个巧妙地思路。分为如下几个部分： 预备知识 单细胞表达谱的统计模型 根据表达谱计算信息熵 E-test 构建有监督的细胞类型分类模型 我们假定读者已经修过概率论等相关课程。 2.1 预备知识 预备知识1： 我们需要向读者回顾关于负二项分布的知识，如果一个离散随机变量Y的pmf(probability mass function)为: 那么我们称其服从负二项分布。记为Y ∼ NB(r, p)。 预备知识2： 对于两个随机变量X和Y，在给定X = x下，Y的条件pmf为： 预备知识3： 关于负二项分布，有如下结论： 对于随机变量Y, Λ，若Y|Λ ∼ Poisson(Λ), Λ ∼ Gamma(α, β), 则 其中 证明： 因为： 所以 根据预备知识3，我们有： 预备知识4： 负二项分布是泊松分布和伽马分布的混合分布。 预备知识5(该结论为概率论和数理统计的常识)： 对于随机变量的pdf为fX(x)，做变换Y = g(X),其中g为单调函数，X和Y各自样本空间的𝒳和𝒴分别满足： 𝒳 = {x|fX(x) &gt; 0}, 𝒴 = {y|y = g(x), x ∈ 𝒳} 若fX(x)在𝒳中连续且逆变换g − 1(x)在𝒴中连续可微，则新的随机变量Y的pdf为： 该结论为Statistical Inference(Casella Berger著)中的定理2.1.5，证明见该书。 预备知识6（只有这个结论作者在补充材料里给了证明）： The scaling property of the Gamma distribution 若 X ∼ Gamma(α, β), 则 证明: 由题设： 根据题设，由预备知识5,有： 故 预备知识6： 若独立同分布样本X1, …, Xn服从Xi ∼ Poisson(λ), 且观测值分别为x1, …, xn，则参数λ的矩估计量和极大似然估计量相等，均为 证明很简单，在很多教材也能找到，故从略。 预备知识7： 若独立同分布样本X1, …, Xn服从Xi ∼ Gamma(α, β), 且观测值分别为x1, …, xn，则参数α, β的极大似然估计满足： 证明： 由题设： 故取对数后极大似然函数为： 由 解得 预备知识8： 若随机变量X的pdf为fX(x),样本空间为𝒳, 定义information generating function: T(u) = ∫𝒳fXu(x)dx 则： H(X) = − T′(1) 证明：(严格证明的话，得要考虑函数fX(x)和𝒳本身的性质，我们这里假定它们可以满足积分号下求导，如果要严格的话，请参考测度论相关教材) 而随机变量X的信息熵的定义为： H(X) = − ∫𝒳fX(x)ln fX(x)dx 故H(X) = − T′(1) 预备知识9： 若X ∼ Gamma(α, β)，则其信息熵S为 由预备知识8经过计算即可证明，从略。 预备知识10： 多项分布 注：更多关于伽马分布的知识可见：理解Gamma分布、Beta分布与Dirichlet分布 2.2 单细胞表达谱的统计模型 经过大量的统计分析和后续的实验验证（相关证据可参考这篇文献）有这样一个经验性的结论： 观察到单细胞基因表达的count(比如UMI count)的分布可以用负二项分布很好的拟合,且相同细胞类型的单细胞表达谱服从同一个分布。 结合2.1中的预备知识，我们可以将单细胞基因表达的count表示为泊松分布的伽马分布的混合分布。所以作者参考了SAVER可以进行如下建模： 假设我们现在有C个细胞，m个基因的原始表达谱数据，里面的数值为reads count或者是UMI count。如果我们记观察得到细胞c的某个基因i的UMI count为Zic, i = 1, …, m, c = 1, …, C，那么对于同一类型的细胞而言，有： Zic ∼ Poisson(λisc), λi ∼ Gamma(αi, βi) 其中λi表示基因i在细胞c中的真实表达量，sc = ∑cZic表示这个细胞中的UMI总数，与测序深度有关。而αi, βi则是两个参数表征某个细胞类型中的基因的真实表达分布的参数。 接下来的可以根据预备知识里的结论进行参数估计： 由预备知识6，我们很容易得到这也为我们常用的进行normalized的策略提供了一种依据。而由预备知识7，有。 2.3 根据表达数据计算信息熵 不是所有的基因都是对后续的统计学习有用的，需要进行特征选择，也就是说，挑选出那些能表示不同群细胞之间表达差异的基因。本文的新意是基于信息熵(也就是香农熵)的概念引入了新的进行特征选择的方法：E-test。在讲E-test之前，我们需要看看作者是如何实现从表达量中计算信息熵的。 根据2.2我们知道可以将观测得到单细胞表达gene countZic表示成Zic与真实表达量λic的混合分布，真正能反映不同细胞之间表达差异的是λic的分布。所以接下来要计算λic的分布的信息熵。 对于相同类型的细胞而言，根据2.1中的结论9，真实表达量λi的信息熵为： 用代入（1）可得： 记： 并且记C个细胞的平均normalized表达量为Xi, 显然有 根据上述记号，（1）最终化简为： 接下来，我们考虑道不同的细胞类型。若细胞c, c = 1, …, Cj属于细胞类型j，定义所有属于j的细胞的平均标准化的表达量为，根据上面的结论，可得： 其中 Xij是直接可以通过实验数据计算的，而hij则需要估计。作者假设hij是只是基因特异的参数，也就是hij = hi。理由如下： 若λi, c ∈ j为随机变量λij ∼ Γ(αij, βij)的观测值，如果我们记基因i从细胞类型j到细胞类型j′的表达量的fold change为Fi, j → j′, 并且假设λij′ = Fi, j → j′λij，那么由2.1中的预备知识6，可知 。 故αij = αi, 结合（6），hij = hi 最终，我们可以得到 2.4 E-test 首先，零假设为所有不同类型细胞都是从同一个细胞类型（记为 group 0）中均匀随机采样，那么基因的平均表达量为, 则group 0 的信息熵可以计算为： 接着计算基因i在所有细胞类型j中与group 0 的信息熵的差之和： (8)-(7)并求和，得： 其中 利用Jesen不等式可以证明GMi ≤ AMi，故ΔS ≥ 0 若要进行假设检验，还需要计算ΔS的显著性，作者的策略是基于置换检验的： 若所有预先定义分群的细胞类型的细胞均来自同一个样本，则对任意的标签为细胞类型j的细胞的size-factor normalized的表达量，根据中心极限定理，单细胞数目足够多的时候，Xij ∼ N(μi, σi)，很容易得到参数的无偏估计，所以置换被简化成了每次从分布n个不同的随机数Xi。接下来就是这么生成一个ΔS的分布，然后计算这个分布中大于从真实数据中测得的ΔS比例，作为显著性。 默认的Feature为500个基因。 2.5 构建有监督学习的模型 根据2.4，在训练集中，我们可以进行特征选择选出一些“informative gene”进行模型训练。 作者假设从相同的转录出的mRNA是不可区分的，而且每个mRNA的产生是相互独立的，记录对于细胞类型为j的细胞，基因i产生一个mRNA的概率为pij,若有m个informative gene 则对细胞类型j,我们得到了一个随机向量pj = (p1j, ⋯, pmj)其中∑ipij = 1且其服从多项式分布,则 对于属于细胞类型j的细胞y，其后验表达谱y = (y1, …, yn)可以计算为： 其中概率pij可估计为 同样的，在测试集中，未知细胞类型的细胞y属于细胞类型j的概率也为 其中pij是训练集中学习到的参数。 如果，我们引入,由极大似然的原则可知，细胞y最有可能的细胞类型ĵ为 2.6 方法总结 可以用原文献中的流图对SciBet进行总结： 3. 软件使用 3.1 在线版 在线版使用请按照官网的Online classification教程。 值得一提的是，作者提供了很从不同组织，不同实验条件的单细胞测序数据中训练好的Signature： 这些不同的signature可以供不同研究者结合自己的兴趣使用。 3.2 本地版 3.2.1 安装 if (!requireNamespace(\"devtools\", quietly = TRUE)) install.packages(\"devtools\")devtools::install_github(\"PaulingLiu/scibet\") 如果出现错误，请看相关issue 3.2.2 作者提供的测试数据 按照官网的教程E-test and SciBet；下载所需的数据；然后后按照其说明文档进行即可。 接下来，我们看如何用使用SciBet结合Seurat进行单细胞分析。 3.2.3 SciBet结合Seurat 为了说明问题，我们选择Seurat自带的pbmcsca数据集, 该数据集已经提供了预先定义好的细胞标签，代码如下： library(Seurat)library(pbmcsca.SeuratData)library(ggplot2)library(scibet)library(tidyverse)library(viridis)####0.---define utilized function--------####---Export expr data from 10x to tibble----#' @param seuv3 a seuv3 object #' myGetExpr &lt;- function(seuv3,...){ expr &lt;- GetAssayData(object = seuv3, slot = \"data\") expr &lt;- as_tibble(t(as.matrix(expr)),rownames = NA) return(expr)}###1.load data and preprocessingdata(\"pbmcsca\")###---avoid warning-----pbmcsca &lt;- UpdateSeuratObject(pbmcsca)###---show predifined cell type------table(pbmcsca$CellType) # B cell CD14+ monocyte # 5020 5550 # CD16+ monocyte CD4+ T cell # 804 7391 # Cytotoxic T cell Dendritic cell # 9071 433 # Megakaryocyte Natural killer cell # 977 1565 # Plasmacytoid dendritic cell Unassigned # 164 46 ###---split data-----pbmc.list &lt;- SplitObject(pbmcsca, split.by = \"Method\")###---normalize-------for (i in names(pbmc.list)) { pbmc.list[[i]] &lt;- NormalizeData(pbmc.list[[i]], verbose = FALSE)}names(pbmc.list) [1] \"Smart-seq2\" \"CEL-Seq2\" \"10x Chromium (v2) A\"[4] \"10x Chromium (v2) B\" \"10x Chromium (v3)\" \"Drop-seq\" [7] \"Seq-Well\" \"inDrops\" \"10x Chromium (v2)\" 测试 reference base模式的效果 ###----2. test scibet----###----define reference and query-----reference &lt;- pbmc.list[[1]]query &lt;- pbmc.list[[2]]###----test query reference mode----reference.expr &lt;- myGetExpr(reference)query.expr &lt;- myGetExpr(query)reference.label &lt;- as.character(reference$CellType)test.label &lt;- as.character(query$CellType)reference.expr &lt;- cbind(reference.expr,label=reference.label)prd.label &lt;- SciBet(train = reference.expr, test = query.expr)Confusion_heatmap(test.label, prd.label)ggsave(filename = \"res/fig/learn_scibet_confusionheatmap_refmode.pdf\", width = 6,height = 6) 准确率为 num1 &lt;- length(test.label)num2 &lt;- tibble( ori = test.label, prd = prd.label) %&gt;% dplyr::filter(ori == prd) %&gt;% nrow(.)num2/num1 0.851711 测试用作者提供的训练好的模型 ###----test load_model mode-----###using 30 major cell types signature----model &lt;- readr::read_csv(file = \"http://scibet.cancer-pku.cn/major_human_cell_types.csv\")model &lt;- pro.core(model)prd &lt;- LoadModel(model)prd.label &lt;- prd(query.expr)Confusion_heatmap(test.label,prd.label)ggsave(filename = \"res/fig/learn_scibet_confusionheatmap_signaturemode.pdf\", width = 6,height = 6)","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"}],"author":"夏目沉吟"},{"title":"LearnSeurat_PBMC3k","slug":"LearnSeurat-PBMC3k","date":"2020-05-10T11:55:56.000Z","updated":"2025-01-11T17:16:31.818Z","comments":true,"path":"2020/05/10/LearnSeurat-PBMC3k/","permalink":"https://landau1994.github.io/2020/05/10/LearnSeurat-PBMC3k/","excerpt":"","text":"本系列假定读者对于单细胞测序的数据分析和Seurat的官方教程有所了解。 本篇研究最基础的PBMC3k。其实这里只有2700个外周血的细胞。注意到，由于取样是外周血，没有干细胞的存在，所以可以认为样品处于稳态。这个教程就是讲稳态下的单细胞测序分析是如何进行的。Seurat的官方教程的缺点之一就是没有涉及动态过程的单细胞分析如何进行。 如无特殊说明，本系列的代码均可以在自己的笔记本电脑上运行； 1. 构建Seurat object 使用作者已经构建好的数据进行构建。关于Seurat更详细的文档可见satijalab的wiki library(Seurat)library(SeuratData)library(ggplot2)library(igraph)library(tidyverse)library(patchwork)### AvailableData() check avaliable data: we choose cbmc### InstallData('pbmc3k')library(pbmc3k.SeuratData)### how this dataset generate?# ## Not run: # if (requireNamespace(Seurat, quietly = TRUE)) {# url &lt;- 'http://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz'# curl::curl_download(url = url, destfile = basename(path = url))# untar(tarfile = basename(path = url))# pbmc.data &lt;- Seurat::Read10X(data.dir = 'filtered_gene_bc_matrices/hg19/')# pbmc3k &lt;- Seurat::CreateSeuratObject(counts = pbmc.data, project = 'pbmc3k', min.cells = 3, min.features = 200)# # Annotations come from Seurat's PBMC3k Guided Clustering Tutorial# # https://satijalab.org/seurat/v3.0/pbmc3k_tutorial.html# annotations &lt;- readRDS(file = system.file('extdata/annotations/annotations.Rds', package = 'pbmc3k.SeuratData'))# pbmc3k &lt;- Seurat::AddMetaData(object = pbmc3k, metadata = annotations)# # Clean up downloaded files# file.remove(basename(path = url))# unlink(x = 'filtered_gene_bc_matrices/', recursive = TRUE)# }# # ## End(Not run)### how Create Seurat object work?### by run `Seurat::CreateSeuratObject` you can get the source function# ## Not run:# Seurat::CreateSeuratObject# function (counts, project = \"SeuratProject\", assay = \"RNA\", # min.cells = 0, min.features = 0, names.field = 1, names.delim = \"_\", # meta.data = NULL) # {# if (!is.null(x = meta.data)) {# if (is.null(x = rownames(x = meta.data))) {# stop(\"Row names not set in metadata. Please ensure that rownames of metadata match column names of data matrix\")# }# if (length(x = setdiff(x = rownames(x = meta.data), y = colnames(x = counts)))) {# warning(\"Some cells in meta.data not present in provided counts matrix.\")# meta.data &lt;- meta.data[intersect(x = rownames(x = meta.data), # y = colnames(x = counts)), ]# }# if (is.data.frame(x = meta.data)) {# new.meta.data &lt;- data.frame(row.names = colnames(x = counts))# for (ii in 1:ncol(x = meta.data)) {# new.meta.data[rownames(x = meta.data), colnames(x = meta.data)[ii]] &lt;- meta.data[, # ii, drop = FALSE]# }# meta.data &lt;- new.meta.data# }# }# assay.data &lt;- CreateAssayObject(counts = counts, min.cells = min.cells, # min.features = min.features)# Key(object = assay.data) &lt;- paste0(tolower(x = assay), \"_\")# assay.list &lt;- list(assay.data)# names(x = assay.list) &lt;- assay# init.meta.data &lt;- data.frame(row.names = colnames(x = assay.list[[assay]]))# idents &lt;- factor(x = unlist(x = lapply(X = colnames(x = assay.data), # FUN = ExtractField, field = names.field, delim = names.delim)))# if (any(is.na(x = idents))) {# warning(\"Input parameters result in NA values for initial cell identities. Setting all initial idents to the project name\")# }# ident.levels &lt;- length(x = unique(x = idents))# if (ident.levels &gt; 100 || ident.levels == 0 || ident.levels == # length(x = idents)) {# idents &lt;- rep.int(x = factor(x = project), times = ncol(x = assay.data))# }# names(x = idents) &lt;- colnames(x = assay.data)# object &lt;- new(Class = \"Seurat\", assays = assay.list, # meta.data = init.meta.data, active.assay = assay, active.ident = idents, # project.name = project, version = packageVersion(pkg = \"Seurat\"))# object[[\"orig.ident\"]] &lt;- idents# n.calc &lt;- CalcN(object = assay.data)# if (!is.null(x = n.calc)) {# names(x = n.calc) &lt;- paste(names(x = n.calc), assay, # sep = \"_\")# object[[names(x = n.calc)]] &lt;- n.calc# }# if (!is.null(x = meta.data)) {# object &lt;- AddMetaData(object = object, metadata = meta.data)# }# return(object)# }# # Seurat:: CreateAssayObject# function (counts, data, min.cells = 0, min.features = 0) # {# if (missing(x = counts) &amp;&amp; missing(x = data)) {# stop(\"Must provide either 'counts' or 'data'\")# }# else if (!missing(x = counts) &amp;&amp; !missing(x = data)) {# stop(\"Either 'counts' or 'data' must be missing; both cannot be provided\")# }# else if (!missing(x = counts)) {# if (anyDuplicated(rownames(x = counts))) {# warning(\"Non-unique features (rownames) present in the input matrix, making unique\", # call. = FALSE, immediate. = TRUE)# rownames(x = counts) &lt;- make.unique(names = rownames(x = counts))# }# if (anyDuplicated(colnames(x = counts))) {# warning(\"Non-unique cell names (colnames) present in the input matrix, making unique\", # call. = FALSE, immediate. = TRUE)# colnames(x = counts) &lt;- make.unique(names = colnames(x = counts))# }# if (is.null(x = colnames(x = counts))) {# stop(\"No cell names (colnames) names present in the input matrix\")# }# if (any(rownames(x = counts) == \"\")) {# stop(\"Feature names of counts matrix cannot be empty\", # call. = FALSE)# }# if (nrow(x = counts) &gt; 0 &amp;&amp; is.null(x = rownames(x = counts))) {# stop(\"No feature names (rownames) names present in the input matrix\")# }# if (!inherits(x = counts, what = \"dgCMatrix\")) {# counts &lt;- as(object = as.matrix(x = counts), Class = \"dgCMatrix\")# }# if (min.features &gt; 0) {# nfeatures &lt;- Matrix::colSums(x = counts &gt; 0)# counts &lt;- counts[, which(x = nfeatures &gt;= min.features)]# }# if (min.cells &gt; 0) {# num.cells &lt;- Matrix::rowSums(x = counts &gt; 0)# counts &lt;- counts[which(x = num.cells &gt;= min.cells), # ]# }# data &lt;- counts# }# else if (!missing(x = data)) {# if (anyDuplicated(rownames(x = data))) {# warning(\"Non-unique features (rownames) present in the input matrix, making unique\", # call. = FALSE, immediate. = TRUE)# rownames(x = data) &lt;- make.unique(names = rownames(x = data))# }# if (anyDuplicated(colnames(x = data))) {# warning(\"Non-unique cell names (colnames) present in the input matrix, making unique\", # call. = FALSE, immediate. = TRUE)# colnames(x = data) &lt;- make.unique(names = colnames(x = data))# }# if (is.null(x = colnames(x = data))) {# stop(\"No cell names (colnames) names present in the input matrix\")# }# if (any(rownames(x = data) == \"\")) {# stop(\"Feature names of data matrix cannot be empty\", # call. = FALSE)# }# if (nrow(x = data) &gt; 0 &amp;&amp; is.null(x = rownames(x = data))) {# stop(\"No feature names (rownames) names present in the input matrix\")# }# if (min.cells != 0 | min.features != 0) {# warning(\"No filtering performed if passing to data rather than counts\", # call. = FALSE, immediate. = TRUE)# }# counts &lt;- new(Class = \"matrix\")# }# if (!is.vector(x = rownames(x = counts))) {# rownames(x = counts) &lt;- as.vector(x = rownames(x = counts))# }# if (!is.vector(x = colnames(x = counts))) {# colnames(x = counts) &lt;- as.vector(x = colnames(x = counts))# }# if (!is.vector(x = rownames(x = data))) {# rownames(x = data) &lt;- as.vector(x = rownames(x = data))# }# if (!is.vector(x = colnames(x = data))) {# colnames(x = data) &lt;- as.vector(x = colnames(x = data))# }# if (any(grepl(pattern = \"_\", x = rownames(x = counts))) || # any(grepl(pattern = \"_\", x = rownames(x = data)))) {# warning(\"Feature names cannot have underscores ('_'), replacing with dashes ('-')\", # call. = FALSE, immediate. = TRUE)# rownames(x = counts) &lt;- gsub(pattern = \"_\", replacement = \"-\", # x = rownames(x = counts))# rownames(x = data) &lt;- gsub(pattern = \"_\", replacement = \"-\", # x = rownames(x = data))# }# if (any(grepl(pattern = \"|\", x = rownames(x = counts), # fixed = TRUE)) || any(grepl(pattern = \"|\", x = rownames(x = data), # fixed = TRUE))) {# warning(\"Feature names cannot have pipe characters ('|'), replacing with dashes ('-')\", # call. = FALSE, immediate. = TRUE)# rownames(x = counts) &lt;- gsub(pattern = \"|\", replacement = \"-\", # x = rownames(x = counts), fixed = TRUE)# rownames(x = data) &lt;- gsub(pattern = \"|\", replacement = \"-\", # x = rownames(x = data), fixed = TRUE)# }# init.meta.features &lt;- data.frame(row.names = rownames(x = data))# assay &lt;- new(Class = \"Assay\", counts = counts, data = data, # scale.data = new(Class = \"matrix\"), meta.features = init.meta.features)# return(assay)# }###update object to avoid warning.data(\"pbmc3k\")pbmc &lt;- UpdateSeuratObject(pbmc3k)rm(pbmc3k)pbmc ## An object of class Seurat ## 13714 features across 2700 samples within 1 assay ## Active assay: RNA (13714 features) 2. 基本预处理 作者在原教程说： The steps below encompass the standard pre-processing workflow for scRNA-seq data in Seurat. These represent the selection and filtration of cells based on QC metrics, data normalization and scaling, and the detection of highly variable features. 2.1 细胞质控 三种基本的QC metrics The number of unique genes detected in each cell. Low-quality cells or empty droplets will often have very few genes Cell doublets or multiplets may exhibit an aberrantly high gene count Similarly, the total number of molecules detected within a cell (correlates strongly with unique genes) The percentage of reads that map to the mitochondrial genome Low-quality / dying cells often exhibit extensive mitochondrial contamination We calculate mitochondrial QC metrics with the PercentageFeatureSet function, which calculates the percentage of counts originating from a set of features We use the set of all genes starting with MT- as a set of mitochondrial genes 注意，人的线粒体基因是“MT-”开头，而小鼠的线粒体基因是“mt-”开头 # The [[ operator can add columns to object metadata. This is a great place to stash QC stats### how does PercentageFeatureSet work# PercentageFeatureSet# function (object, pattern = NULL, features = NULL, col.name = NULL, # assay = NULL) # {# assay &lt;- assay %||% DefaultAssay(object = object)# if (!is.null(x = features) &amp;&amp; !is.null(x = pattern)) {# warning(\"Both pattern and features provided. Pattern is being ignored.\")# }# features &lt;- features %||% grep(pattern = pattern, x = rownames(x = object[[assay]]), # value = TRUE)# percent.featureset &lt;- colSums(x = GetAssayData(object = object, # assay = assay, slot = \"counts\")[features, , drop = FALSE])/object[[paste0(\"nCount_\", # assay)]] * 100# if (!is.null(x = col.name)) {# object &lt;- AddMetaData(object = object, metadata = percent.featureset, # col.name = col.name)# return(object)# }# return(percent.featureset)# }pbmc[[\"percent.mt\"]] &lt;- PercentageFeatureSet(pbmc, pattern = \"^MT-\")# Show QC metrics for the first 5 cellshead(pbmc@meta.data, 5) ## orig.ident nCount_RNA nFeature_RNA seurat_annotations percent.mt ## AAACATACAACCAC pbmc3k 2419 779 Memory CD4 T 3.0177759 ## AAACATTGAGCTAC pbmc3k 4903 1352 B 3.7935958 ## AAACATTGATCAGC pbmc3k 3147 1129 Memory CD4 T 0.8897363 ## AAACCGTGCTTCCG pbmc3k 2639 960 CD14+ Mono 1.7430845 ## AAACCGTGTATGCG pbmc3k 980 521 NK 1.2244898 由于我们用的是作者给了metadata的数据，里面已经出现了细胞类型的注释，见seurat_annotation这一项； QC metric的可视化： # Visualize QC metrics as a violin plotVlnPlot(pbmc, features = c(\"nFeature_RNA\", \"nCount_RNA\", \"percent.mt\"), ncol = 3) # FeatureScatter is typically used to visualize feature-feature relationships, but can be used# for anything calculated by the object, i.e. columns in object metadata, PC scores etc.plot1 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"percent.mt\")plot2 &lt;- FeatureScatter(pbmc, feature1 = \"nCount_RNA\", feature2 = \"nFeature_RNA\")plot1 + plot2 最终选择的质控标准为： We filter cells that have unique feature counts over 2,500 or less than 200 We filter cells that have &gt;5% mitochondrial counts pbmc &lt;- subset(pbmc, subset = nFeature_RNA &gt; 200 &amp; nFeature_RNA &lt; 2500 &amp; percent.mt &lt; 5) 2.2 标准化 After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. Normalized values are stored in pbmc[[“RNA”]]@data. pbmc &lt;- NormalizeData(pbmc, normalization.method = \"LogNormalize\", scale.factor = 10000) 2.3 特征选择 哪些基因能反应不同细胞之间的异质性？是那些表达差异大的基因； 注意FindVariableFeatures是S3 generic，泛型函数。 如何查看一个泛型函数的源代码呢，我们先用methods函数匹配该范型函数的名字： methods(FindVariableFeatures) ## [1] FindVariableFeatures.Assay* FindVariableFeatures.default* ## [3] FindVariableFeatures.Seurat* ## see '?methods' for accessing help and source code 星号表明我们不能直接通过运行函数名字来查看其源代码，但是我们可以通过运行 getAnywhere函数来获取这个函数， getAnywhere(FindVariableFeatures.Seurat) ## A single object matching 'FindVariableFeatures.Seurat' was found ## It was found in the following places ## registered S3 method for FindVariableFeatures from namespace Seurat ## namespace:Seurat ## with value ## ## function (object, assay = NULL, selection.method = \"vst\", loess.span = 0.3, ## clip.max = \"auto\", mean.function = FastExpMean, dispersion.function = FastLogVMR, ## num.bin = 20, binning.method = \"equal_width\", nfeatures = 2000, ## mean.cutoff = c(0.1, 8), dispersion.cutoff = c(1, Inf), verbose = TRUE, ## ...) ## { ## assay &lt;- assay %||% DefaultAssay(object = object) ## assay.data &lt;- GetAssay(object = object, assay = assay) ## assay.data &lt;- FindVariableFeatures(object = assay.data, selection.method = selection.method, ## loess.span = loess.span, clip.max = clip.max, mean.function = mean.function, ## dispersion.function = dispersion.function, num.bin = num.bin, ## binning.method = binning.method, nfeatures = nfeatures, ## mean.cutoff = mean.cutoff, dispersion.cutoff = dispersion.cutoff, ## verbose = verbose, ...) ## object[[assay]] &lt;- assay.data ## object &lt;- LogSeuratCommand(object = object) ## return(object) ## } ## &lt;bytecode: 0x0000000022fa2410&gt; ## &lt;environment: namespace:Seurat&gt; 我们可以发现，默认的FindVariableFeatures.Seuratmethod调用了FindVariableFeatures.Assay： getAnywhere(FindVariableFeatures.Assay) ## A single object matching 'FindVariableFeatures.Assay' was found ## It was found in the following places ## registered S3 method for FindVariableFeatures from namespace Seurat ## namespace:Seurat ## with value ## ## function (object, selection.method = \"vst\", loess.span = 0.3, ## clip.max = \"auto\", mean.function = FastExpMean, dispersion.function = FastLogVMR, ## num.bin = 20, binning.method = \"equal_width\", nfeatures = 2000, ## mean.cutoff = c(0.1, 8), dispersion.cutoff = c(1, Inf), verbose = TRUE, ## ...) ## { ## if (length(x = mean.cutoff) != 2 || length(x = dispersion.cutoff) != ## 2) { ## stop(\"Both 'mean.cutoff' and 'dispersion.cutoff' must be two numbers\") ## } ## if (selection.method == \"vst\") { ## data &lt;- GetAssayData(object = object, slot = \"counts\") ## if (IsMatrixEmpty(x = data)) { ## warning(\"selection.method set to 'vst' but count slot is empty; will use data slot instead\") ## data &lt;- GetAssayData(object = object, slot = \"data\") ## } ## } ## else { ## data &lt;- GetAssayData(object = object, slot = \"data\") ## } ## hvf.info &lt;- FindVariableFeatures(object = data, selection.method = selection.method, ## loess.span = loess.span, clip.max = clip.max, mean.function = mean.function, ## dispersion.function = dispersion.function, num.bin = num.bin, ## binning.method = binning.method, verbose = verbose, ...) ## object[[names(x = hvf.info)]] &lt;- hvf.info ## hvf.info &lt;- hvf.info[which(x = hvf.info[, 1, drop = TRUE] != ## 0), ] ## if (selection.method == \"vst\") { ## hvf.info &lt;- hvf.info[order(hvf.info$vst.variance.standardized, ## decreasing = TRUE), , drop = FALSE] ## } ## else { ## hvf.info &lt;- hvf.info[order(hvf.info$mvp.dispersion, decreasing = TRUE), ## , drop = FALSE] ## } ## selection.method &lt;- switch(EXPR = selection.method, mvp = \"mean.var.plot\", ## disp = \"dispersion\", selection.method) ## top.features &lt;- switch(EXPR = selection.method, mean.var.plot = { ## means.use &lt;- (hvf.info[, 1] &gt; mean.cutoff[1]) &amp; (hvf.info[, ## 1] &lt; mean.cutoff[2]) ## dispersions.use &lt;- (hvf.info[, 3] &gt; dispersion.cutoff[1]) &amp; ## (hvf.info[, 3] &lt; dispersion.cutoff[2]) ## rownames(x = hvf.info)[which(x = means.use &amp; dispersions.use)] ## }, dispersion = head(x = rownames(x = hvf.info), n = nfeatures), ## vst = head(x = rownames(x = hvf.info), n = nfeatures), ## stop(\"Unkown selection method: \", selection.method)) ## VariableFeatures(object = object) &lt;- top.features ## vf.name &lt;- ifelse(test = selection.method == \"vst\", yes = \"vst\", ## no = \"mvp\") ## vf.name &lt;- paste0(vf.name, \".variable\") ## object[[vf.name]] &lt;- rownames(x = object[[]]) %in% top.features ## return(object) ## } ## &lt;bytecode: 0x000000002dc5d050&gt; ## &lt;environment: namespace:Seurat&gt; 千层饼的最后一层； getAnywhere(FindVariableFeatures.default) ## A single object matching 'FindVariableFeatures.default' was found ## It was found in the following places ## registered S3 method for FindVariableFeatures from namespace Seurat ## namespace:Seurat ## with value ## ## function (object, selection.method = \"vst\", loess.span = 0.3, ## clip.max = \"auto\", mean.function = FastExpMean, dispersion.function = FastLogVMR, ## num.bin = 20, binning.method = \"equal_width\", verbose = TRUE, ## ...) ## { ## CheckDots(...) ## if (!inherits(x = object, \"Matrix\")) { ## object &lt;- as(object = as.matrix(x = object), Class = \"Matrix\") ## } ## if (!inherits(x = object, what = \"dgCMatrix\")) { ## object &lt;- as(object = object, Class = \"dgCMatrix\") ## } ## if (selection.method == \"vst\") { ## if (clip.max == \"auto\") { ## clip.max &lt;- sqrt(x = ncol(x = object)) ## } ## hvf.info &lt;- data.frame(mean = rowMeans(x = object)) ## hvf.info$variance &lt;- SparseRowVar2(mat = object, mu = hvf.info$mean, ## display_progress = verbose) ## hvf.info$variance.expected &lt;- 0 ## hvf.info$variance.standardized &lt;- 0 ## not.const &lt;- hvf.info$variance &gt; 0 ## fit &lt;- loess(formula = log10(x = variance) ~ log10(x = mean), ## data = hvf.info[not.const, ], span = loess.span) ## hvf.info$variance.expected[not.const] &lt;- 10^fit$fitted ## hvf.info$variance.standardized &lt;- SparseRowVarStd(mat = object, ## mu = hvf.info$mean, sd = sqrt(hvf.info$variance.expected), ## vmax = clip.max, display_progress = verbose) ## colnames(x = hvf.info) &lt;- paste0(\"vst.\", colnames(x = hvf.info)) ## } ## else { ## if (!inherits(x = mean.function, what = \"function\")) { ## stop(\"'mean.function' must be a function\") ## } ## if (!inherits(x = dispersion.function, what = \"function\")) { ## stop(\"'dispersion.function' must be a function\") ## } ## feature.mean &lt;- mean.function(object, verbose) ## feature.dispersion &lt;- dispersion.function(object, verbose) ## names(x = feature.mean) &lt;- names(x = feature.dispersion) &lt;- rownames(x = object) ## feature.dispersion[is.na(x = feature.dispersion)] &lt;- 0 ## feature.mean[is.na(x = feature.mean)] &lt;- 0 ## data.x.breaks &lt;- switch(EXPR = binning.method, equal_width = num.bin, ## equal_frequency = c(-1, quantile(x = feature.mean[feature.mean &gt; ## 0], probs = seq.int(from = 0, to = 1, length.out = num.bin))), ## stop(\"Unknown binning method: \", binning.method)) ## data.x.bin &lt;- cut(x = feature.mean, breaks = data.x.breaks) ## names(x = data.x.bin) &lt;- names(x = feature.mean) ## mean.y &lt;- tapply(X = feature.dispersion, INDEX = data.x.bin, ## FUN = mean) ## sd.y &lt;- tapply(X = feature.dispersion, INDEX = data.x.bin, ## FUN = sd) ## feature.dispersion.scaled &lt;- (feature.dispersion - mean.y[as.numeric(x = data.x.bin)])/sd.y[as.numeric(x = data.x.bin)] ## names(x = feature.dispersion.scaled) &lt;- names(x = feature.mean) ## hvf.info &lt;- data.frame(feature.mean, feature.dispersion, ## feature.dispersion.scaled) ## rownames(x = hvf.info) &lt;- rownames(x = object) ## colnames(x = hvf.info) &lt;- paste0(\"mvp.\", c(\"mean\", \"dispersion\", ## \"dispersion.scaled\")) ## } ## return(hvf.info) ## } ## &lt;bytecode: 0x0000000023f13fd0&gt; ## &lt;environment: namespace:Seurat&gt; 忽略这些技术细节，进行特征选择； pbmc &lt;- FindVariableFeatures(pbmc, selection.method = \"vst\", nfeatures = 2000)# Identify the 10 most highly variable genestop10 &lt;- head(VariableFeatures(pbmc), 10)# plot variable features with and without labelsplot1 &lt;- VariableFeaturePlot(pbmc)plot2 &lt;- LabelPoints(plot = plot1, points = top10, repel = TRUE)plot1 + plot2 2.4 Scaling the data 这步的目的是为了后续的PCA： Next, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. The ScaleData function: + Shifts the expression of each gene, so that the mean expression across cells is 0 + Scales the expression of each gene, so that the variance across cells is 1 + This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate + The results of this are stored in pbmc[[“RNA”]]@scale.data 回归掉percent.mt对于PCA的影响。这步是一步限速步骤； all.genes &lt;- rownames(pbmc)pbmc &lt;- ScaleData(pbmc, features = all.genes,vars.to.regress = \"percent.mt\") 有一个问题后面的marker基因一定是HVG吗？ 2.5 线性降维(PCA) Next we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset. pbmc &lt;- RunPCA(pbmc, features = VariableFeatures(object = pbmc))# Examine and visualize PCA results a few different waysprint(pbmc[[\"pca\"]], dims = 1:5, nfeatures = 5) ## PC_ 1 ## Positive: CST3, TYROBP, LST1, AIF1, FTL ## Negative: MALAT1, LTB, IL32, IL7R, CD2 ## PC_ 2 ## Positive: CD79A, MS4A1, TCL1A, HLA-DQA1, HLA-DQB1 ## Negative: NKG7, PRF1, CST7, GZMA, GZMB ## PC_ 3 ## Positive: HLA-DQA1, CD79A, CD79B, HLA-DQB1, HLA-DPA1 ## Negative: PPBP, PF4, SDPR, SPARC, GNG11 ## PC_ 4 ## Positive: HLA-DQA1, CD79B, CD79A, MS4A1, HLA-DQB1 ## Negative: VIM, IL7R, S100A6, S100A8, IL32 ## PC_ 5 ## Positive: GZMB, FGFBP2, S100A8, NKG7, GNLY ## Negative: LTB, IL7R, CKB, MS4A7, RP11-290F20.3 VizDimLoadings(pbmc, dims = 1:2, reduction = \"pca\") DimPlot(pbmc, reduction = \"pca\") In particular DimHeatmap allows for easy exploration of the primary sources of heterogeneity in a dataset, and can be useful when trying to decide which PCs to include for further downstream analyses. Both cells and features are ordered according to their PCA scores. Setting cells to a number plots the ‘extreme’ cells on both ends of the spectrum, which dramatically speeds plotting for large datasets. Though clearly a supervised analysis, we find this to be a valuable tool for exploring correlated feature sets. ### Plot an equal number of genes with both + and - scores.mypal &lt;- rev(colorRampPalette(RColorBrewer::brewer.pal(11,\"RdBu\"))(256))DimHeatmap(pbmc, dims = 1, cells = 500, balanced = TRUE,fast = F)+scale_fill_gradientn(colors = mypal) DimHeatmap(pbmc, dims = 1:15, cells = 500, balanced = TRUE) 2.6 Determine the ‘dimensionality’ of the dataset To overcome the extensive technical noise in any single feature for scRNA-seq data, Seurat clusters cells based on their PCA scores, with each PC essentially representing a ‘metafeature’ that combines information across a correlated feature set. The top principal components therefore represent a robust compression of the dataset. However, how many componenets should we choose to include? 10? 20? 100? 两种统计方法，JackStraw和ElbowPlot，前者比较耗时，不再展示了，用后者 ElbowPlot(pbmc) 作者给出了更进一步的解释 Identifying the true dimensionality of a dataset – can be challenging/uncertain for the user. We therefore suggest these three approaches to consider. The first is more supervised, exploring PCs to determine relevant sources of heterogeneity, and could be used in conjunction with GSEA for example. The second implements a statistical test based on a random null model, but is time-consuming for large datasets, and may not return a clear PC cutoff. The third is a heuristic that is commonly used, and can be calculated instantly. In this example, all three approaches yielded similar results, but we might have been justified in choosing anything between PC 7-12 as a cutoff. We chose 10 here, but encourage users to consider the following: Dendritic cell and NK aficionados may recognize that genes strongly associated with PCs 12 and 13 define rare immune subsets (i.e. MZB1 is a marker for plasmacytoid DCs). However, these groups are so rare, they are difficult to distinguish from background noise for a dataset of this size without prior knowledge. We encourage users to repeat downstream analyses with a different number of PCs (10, 15, or even 50!). As you will observe, the results often do not differ dramatically. We advise users to err on the higher side when choosing this parameter. For example, performing downstream analyses with only 5 PCs does signifcanltly and adversely affect results. 3. 后续分析 3.1 聚类 FindNeighbors构建构建SNN-graph, 而FindClusters用来实现Louvain algorithm，进行图聚类； methods(FindNeighbors) ## [1] FindNeighbors.Assay* FindNeighbors.default* FindNeighbors.dist* ## [4] FindNeighbors.Seurat* ## see '?methods' for accessing help and source code getAnywhere(FindNeighbors.Seurat) ## A single object matching 'FindNeighbors.Seurat' was found ## It was found in the following places ## registered S3 method for FindNeighbors from namespace Seurat ## namespace:Seurat ## with value ## ## function (object, reduction = \"pca\", dims = 1:10, assay = NULL, ## features = NULL, k.param = 20, compute.SNN = TRUE, prune.SNN = 1/15, ## nn.method = \"rann\", annoy.metric = \"euclidean\", nn.eps = 0, ## verbose = TRUE, force.recalc = FALSE, do.plot = FALSE, graph.name = NULL, ## ...) ## { ## CheckDots(...) ## if (!is.null(x = dims)) { ## assay &lt;- DefaultAssay(object = object[[reduction]]) ## data.use &lt;- Embeddings(object = object[[reduction]]) ## if (max(dims) &gt; ncol(x = data.use)) { ## stop(\"More dimensions specified in dims than have been computed\") ## } ## data.use &lt;- data.use[, dims] ## neighbor.graphs &lt;- FindNeighbors(object = data.use, k.param = k.param, ## compute.SNN = compute.SNN, prune.SNN = prune.SNN, ## nn.method = nn.method, annoy.metric = annoy.metric, ## nn.eps = nn.eps, verbose = verbose, force.recalc = force.recalc, ## ...) ## } ## else { ## assay &lt;- assay %||% DefaultAssay(object = object) ## data.use &lt;- GetAssay(object = object, assay = assay) ## neighbor.graphs &lt;- FindNeighbors(object = data.use, features = features, ## k.param = k.param, compute.SNN = compute.SNN, prune.SNN = prune.SNN, ## nn.method = nn.method, annoy.metric = annoy.metric, ## nn.eps = nn.eps, verbose = verbose, force.recalc = force.recalc, ## ...) ## } ## graph.name &lt;- graph.name %||% paste0(assay, \"_\", names(x = neighbor.graphs)) ## for (ii in 1:length(x = graph.name)) { ## DefaultAssay(object = neighbor.graphs[[ii]]) &lt;- assay ## object[[graph.name[[ii]]]] &lt;- neighbor.graphs[[ii]] ## } ## if (do.plot) { ## if (!\"tsne\" %in% names(x = object@reductions)) { ## warning(\"Please compute a tSNE for SNN visualization. See RunTSNE().\") ## } ## else { ## if (nrow(x = Embeddings(object = object[[\"tsne\"]])) != ## ncol(x = object)) { ## warning(\"Please compute a tSNE for SNN visualization. See RunTSNE().\") ## } ## else { ## net &lt;- graph.adjacency(adjmatrix = as.matrix(x = neighbor.graphs[[2]]), ## mode = \"undirected\", weighted = TRUE, diag = FALSE) ## plot.igraph(x = net, layout = as.matrix(x = Embeddings(object = object[[\"tsne\"]])), ## edge.width = E(graph = net)$weight, vertex.label = NA, ## vertex.size = 0) ## } ## } ## } ## object &lt;- LogSeuratCommand(object = object) ## return(object) ## } ## &lt;bytecode: 0x000000001e49f8e0&gt; ## &lt;environment: namespace:Seurat&gt; pbmc &lt;- FindNeighbors(pbmc, dims = 1:10)pbmc &lt;- FindClusters(pbmc, resolution = 0.5) ## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck ## ## Number of nodes: 2638 ## Number of edges: 95930 ## ## Running Louvain algorithm... ## Maximum modularity in 10 random starts: 0.8737 ## Number of communities: 9 ## Elapsed time: 0 seconds 3.2 Run UMAP/tsne run tsne pbmc &lt;- RunTSNE(pbmc,dims = 1:10)DimPlot(pbmc,label = T, reduction = \"tsne\") draw snn graph on tsne-embeding test &lt;- pbmc[[\"RNA_snn\"]]net &lt;- graph.adjacency(adjmatrix = as.matrix(x = test), mode = \"undirected\", weighted = TRUE, diag = FALSE)plot.igraph(x = net, layout = as.matrix(x = Embeddings(object = pbmc[[\"tsne\"]])), edge.width = E(graph = net)$weight, vertex.label = NA, vertex.size = 0) run umap # If you haven't installed UMAP, you can do so via reticulate::py_install(packages =# 'umap-learn')pbmc &lt;- RunUMAP(pbmc,umap.method = \"umap-learn\", dims = 1:10)# note that you can set `label = TRUE` or use the LabelClusters function to help label# individual clustersDimPlot(pbmc,label = T, reduction = \"umap\") test &lt;- pbmc[[\"RNA_snn\"]]net &lt;- graph.adjacency(adjmatrix = as.matrix(x = test), mode = \"undirected\", weighted = TRUE, diag = FALSE)plot.igraph(x = net, layout = as.matrix(x = Embeddings(object = pbmc[[\"umap\"]])), edge.width = E(graph = net)$weight, vertex.label = NA, vertex.size = 0) 3.3 Finding differentially expressed features (cluster biomarkers) 之前分群结果做差异表达； Seurat can help you find markers that define clusters via differential expression. By default, it identifes positive and negative markers of a single cluster (specified in ident.1), compared to all other cells. FindAllMarkers automates this process for all clusters, but you can also test groups of clusters vs. each other, or against all cells. The min.pct argument requires a feature to be detected at a minimum percentage in either of the two groups of cells, and the thresh.test argument requires a feature to be differentially expressed (on average) by some amount between the two groups. You can set both of these to 0, but with a dramatic increase in time - since this will test a large number of features that are unlikely to be highly discriminatory. As another option to speed up these computations, max.cells.per.ident can be set. This will downsample each identity class to have no more cells than whatever this is set to. While there is generally going to be a loss in power, the speed increases can be significiant and the most highly differentially expressed features will likely still rise to the top. # find markers for every cluster compared to all remaining cells, report only the positive onespbmc.markers &lt;- FindAllMarkers(pbmc, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(n = 2, wt = avg_logFC) ## # A tibble: 18 x 7 ## # Groups: cluster [9] ## p_val avg_logFC pct.1 pct.2 p_val_adj cluster gene ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;chr&gt; ## 1 1.88e-117 0.748 0.913 0.588 2.57e-113 0 LDHB ## 2 5.01e- 85 0.931 0.437 0.108 6.88e- 81 0 CCR7 ## 3 0. 3.86 0.996 0.215 0. 1 S100A9 ## 4 0. 3.80 0.975 0.121 0. 1 S100A8 ## 5 2.61e- 81 0.886 0.981 0.65 3.58e- 77 2 LTB ## 6 1.22e- 59 0.886 0.669 0.25 1.68e- 55 2 CD2 ## 7 0. 2.99 0.939 0.042 0. 3 CD79A ## 8 1.06e-269 2.49 0.623 0.022 1.45e-265 3 TCL1A ## 9 5.98e-221 2.23 0.987 0.226 8.20e-217 4 CCL5 ## 10 1.42e-173 2.08 0.572 0.051 1.94e-169 4 GZMK ## 11 3.51e-184 2.30 0.975 0.134 4.82e-180 5 FCGR3A ## 12 2.03e-125 2.14 1 0.315 2.78e-121 5 LST1 ## 13 3.17e-267 3.35 0.961 0.068 4.35e-263 6 GZMB ## 14 1.04e-189 3.66 0.961 0.132 1.43e-185 6 GNLY ## 15 1.48e-220 2.68 0.812 0.011 2.03e-216 7 FCER1A ## 16 1.67e- 21 1.99 1 0.513 2.28e- 17 7 HLA-DPB1 ## 17 7.73e-200 5.02 1 0.01 1.06e-195 8 PF4 ## 18 3.68e-110 5.94 1 0.024 5.05e-106 8 PPBP 可视化： VlnPlot(pbmc, features = c(\"MS4A1\", \"CD79A\")) # you can plot raw counts as wellVlnPlot(pbmc, features = c(\"MS4A1\", \"CD79A\"), slot = \"counts\", log = TRUE) 使用FeatureScatter获得和流式图一样的效果； FeatureScatter(object = pbmc, feature1 = \"MS4A1\", feature2 = \"CD79A\")+ ggtitle(label = NULL) 用FeaturePlot在Embeding上展示表达量； FeaturePlot(pbmc, features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\", \"PPBP\", \"CD8A\")) 气泡图DotPlot DotPlot(object = pbmc, features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\", \"PPBP\", \"CD8A\"))+ coord_flip() RidgePlot RidgePlot(object = pbmc, features = c(\"MS4A1\", \"GNLY\", \"CD3E\", \"CD14\", \"FCER1A\", \"FCGR3A\", \"LYZ\", \"PPBP\", \"CD8A\")) 热图DoHeatmap top10 &lt;- pbmc.markers %&gt;% group_by(cluster) %&gt;% top_n(n = 10, wt = avg_logFC)DoHeatmap(pbmc, features = top10$gene) + scale_fill_gradientn(colors = mypal) 3.4 Assigning cell type identity to clusters new.cluster.ids &lt;- c(\"Naive CD4 T\",\"CD14+ Mono\", \"Memory CD4 T\", \"B\", \"CD8 T\", \"FCGR3A+ Mono\", \"NK\", \"DC\", \"Platelet\")names(new.cluster.ids) &lt;- levels(pbmc)pbmc &lt;- RenameIdents(pbmc, new.cluster.ids)DimPlot(pbmc, reduction = \"umap\", label = TRUE, pt.size = 0.5) + NoLegend() 4. Seurat object 详解 这一部分来自wiki 4.1 The Seurat object 一个Seurat对象有如下的slots: Slot Function assays A list of assays within this object meta.data Cell-level meta data active.assay Name of active, or default, assay active.ident Identity classes for the current object graphs A list of nearest neighbor graphs reductions A list of DimReduc objects project.name User-defined project name (optional) tools Empty list. Tool developers can store any internal data from their methods here misc Empty slot. User can store additional information here version Seurat version used when creating the object 这个对象把单细胞数据的所有的基本信息都包含进去了，可以用基本的一些函数去获取这些信息。例如，我们想要知道这个数据对应多少细胞，多少基因，可以用dim;ncol;nrow;细胞或者feature的名字，可以用rownames;colnames; 我们也可以通过names知道里面存储的如原始表达矩阵，或者降维后对象的名字。 names(x = pbmc) ## [1] \"RNA\" \"RNA_nn\" \"RNA_snn\" \"pca\" \"tsne\" \"umap\" rna &lt;- pbmc[['RNA']] 对于Seurat对象，有一系列的函数可以对其进行操作。这些函数可以称为其所属的methods。多说一句，Seurat采取的是S3对象的面向对象的数据结构。 可以使用如下命令访问与Seurat对象相关的操作。 utils::methods(class = 'Seurat') ## [1] $ $&lt;- [ ## [4] [[ [[&lt;- AddMetaData ## [7] as.CellDataSet as.loom as.SingleCellExperiment ## [10] Command DefaultAssay DefaultAssay&lt;- ## [13] dim dimnames droplevels ## [16] Embeddings FindClusters FindMarkers ## [19] FindNeighbors FindVariableFeatures GetAssay ## [22] GetAssayData HVFInfo Idents ## [25] Idents&lt;- Key levels ## [28] levels&lt;- Loadings merge ## [31] Misc Misc&lt;- names ## [34] NormalizeData OldWhichCells Project ## [37] Project&lt;- RenameCells RenameIdents ## [40] ReorderIdent RunALRA RunCCA ## [43] RunICA RunLSI RunPCA ## [46] RunTSNE RunUMAP ScaleData ## [49] ScoreJackStraw SetAssayData SetIdent ## [52] show StashIdent Stdev ## [55] subset SubsetData Tool ## [58] Tool&lt;- VariableFeatures VariableFeatures&lt;- ## [61] WhichCells ## see '?methods' for accessing help and source code 4.2 Assay The Assay class stores single cell data. For typical scRNA-seq experiments, a Seurat object will have a single Assay (“RNA”). This assay will also store multiple ‘transformations’ of the data, including raw counts (@counts slot), normalized data (@data slot), and scaled data for dimensional reduction (@scale.data slot). For more complex experiments, an object could contain multiple assays. These could include multi-modal data types (CITE-seq antibody-derived tags, ADTs), or imputed/batch-corrected measurements. Each of those assays has the option to store the same data transformations as well. 一个Assay 所含有的Slots Slot Function counts Stores unnormalized data such as raw counts or TPMs data Normalized data matrix scale.data Scaled data matrix key A character string to facilitate looking up features from a specific Assay var.features A vector of features identified as variable meta.features Feature-level meta data Assay对象也可以使用以下方法 Summary information about Assay objects can be had quickly and easily using standard R functions. Object shape/dimensions can be found using the dim, ncol, and nrow functions; cell and feature names can be found using the colnames and rownames functions, respectively, or the dimnames function. 更多的方法见 utils::methods(class = 'Assay') ## [1] [ [[ [[&lt;- ## [4] AddMetaData DefaultAssay DefaultAssay&lt;- ## [7] dim dimnames FindNeighbors ## [10] FindVariableFeatures GetAssayData HVFInfo ## [13] Key Key&lt;- merge ## [16] Misc Misc&lt;- NormalizeData ## [19] OldWhichCells RenameCells RunICA ## [22] RunLSI RunPCA ScaleData ## [25] SetAssayData show subset ## [28] SubsetData VariableFeatures VariableFeatures&lt;- ## [31] WhichCells ## see '?methods' for accessing help and source code Data Access # GetAssayData allows pulling from a specific slot rather than just dataGetAssayData(object = rna, slot = 'scale.data')[1:3, 1:3] ## AAACATACAACCAC AAACATTGAGCTAC AAACATTGATCAGC ## AL627309.1 -0.06433822 -0.06968772 -0.04966479 ## AP006222.2 -0.02663018 -0.02065038 -0.04303249 ## RP11-206L10.2 -0.03015459 -0.02024084 -0.05734758 head(x = HVFInfo(object = rna,selection.method = \"vst\")) ## mean variance variance.standardized ## AL627309.1 0.003411676 0.003401325 0.9330441 ## AP006222.2 0.001137225 0.001136363 0.9924937 ## RP11-206L10.2 0.001895375 0.001892500 0.9627290 ## RP11-206L10.9 0.001137225 0.001136363 0.9924937 ## LINC00115 0.006823351 0.006779363 0.9062135 ## NOC2L 0.107278241 0.159514698 0.7849309 The key # Key both accesses and sets the key slot for an Assay object&gt; Key(object = rna)\"rna_\"&gt; Key(object = rna) &lt;- 'myRNA_'&gt; Key(object = rna)\"myRNA_\"# Pull a feature from the RNA assay on the Seurat level&gt; head(x = FetchData(object = pbmc, vars.fetch = 'rna_MS4A1')) rna_MS4A1AAACATACAACCAC 0.000000AAACATTGAGCTAC 2.583047AAACATTGATCAGC 0.000000AAACCGTGCTTCCG 0.000000AAACCGTGTATGCG 0.000000AAACGCACTGGTAC 0.000000 The DimReduc object represents a dimensional reduction taken upon the Seurat object. 4.3 The DimReduc object The DimReduc object represents a dimensional reduction taken upon the Seurat object. Slot Function cell.embeddings A matrix with cell embeddings feature.loadings A matrix with feature loadings feature.loadings.projected A matrix with projected feature loadings assay.used Assay used to calculate this dimensional reduction stdev Standard deviation for the dimensional reduction key A character string to facilitate looking up features from a specific DimReduc jackstraw Results from the JackStraw function misc … 和之前的很类似 pca &lt;- pbmc[[\"pca\"]]# The following examples use the PCA dimensional reduction from the PBMC 3k dataset&gt; pcaA dimensional reduction object with key PC Number of dimensions: 20 Projected dimensional reduction calculated: FALSE Jackstraw run: FALSE# nrow and ncol provide the number of features and cells, respectively# dim provides both nrow and ncol at the same time&gt; dim(x = pca)[1] 1838 2638# length provides the number of dimensions calculated&gt; length(x = pca)[1] 20# In addtion to rownames and colnames, one can use dimnames# which provides a two-length list with both rownames and colnames&gt; head(x = rownames(x = rna))[1] \"TNFRSF4\" \"CPSF3L\" \"ATAD3C\" \"C1orf86\" \"RER1\" \"TNFRSF25\"&gt; head(x = colnames(x = rna))[1] \"AAACATACAACCAC\" \"AAACATTGAGCTAC\" \"AAACATTGATCAGC\" \"AAACCGTGCTTCCG\"[5] \"AAACCGTGTATGCG\" \"AAACGCACTGGTAC\" Access data # The key can be used to pull cell embeddings for specific dimensions from the Seurat level&gt; Key(object = pca)\"PC\"&gt; head(x = FetchData(object = pbmc, vars.fetch = 'PC1')) PC1AAACATACAACCAC 5.569384AAACATTGAGCTAC 7.216456AAACATTGATCAGC 2.706629AAACCGTGCTTCCG -10.134042AAACCGTGTATGCG -1.099311AAACGCACTGGTAC 1.455335# DefaultAssay gets the name of the Assay object used to calculate the DimReduc&gt; DefaultAssay(object = pca)[1] \"RNA\"# Stdev gets the vector of standard deviations for each dimension embedded.Stdev(object = pca) [1] 5.666584 4.326466 3.952192 3.638124 2.191529 1.996551 1.877891 1.798251 [9] 1.766873 1.753684 1.731568 1.720525 1.718079 1.715879 1.707009 1.702660[17] 1.697318 1.692549 1.686149 1.683967 在其上可以执行的method有 utils::methods(class = \"DimReduc\") ## [1] [ [[ Cells DefaultAssay DefaultAssay&lt;- ## [6] dim dimnames Embeddings IsGlobal JS ## [11] JS&lt;- Key Key&lt;- length Loadings ## [16] Loadings&lt;- names print RenameCells RunTSNE ## [21] ScoreJackStraw show Stdev subset ## see '?methods' for accessing help and source code 4.4 R面向对象编程的更多细节； 关于面向对象，以及S3对象的教程，更多可见： R深入|面向对象——泛型函数 OO field guide R语言面向对象编程","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"}],"author":"夏目沉吟"},{"title":"Dobrow-chap3","slug":"Dobrow-chap3","date":"2020-05-06T14:15:53.000Z","updated":"2025-01-15T12:37:58.401Z","comments":true,"path":"2020/05/06/Dobrow-chap3/","permalink":"https://landau1994.github.io/2020/05/06/Dobrow-chap3/","excerpt":"","text":"This is a note of the textbook Introduction to stochastic processes with R There exists everywhere a medium in things, determined by equilibrium. —Dmitri Mendeleev 承接上章最后的数值案例，本章主要讲转移步数趋于无穷时马尔可夫链的性质。 3.1 Limiting Distribution 3.1.1 定义 作者给了有一个定义和三个等价定义。这个含义最清楚： A limiting distribution for the Markov chain is a probability distribution 𝝀 with the property that, for any initial distribution α: limn → ∞αPn = λ 这个定义与原定义的等价性也很容易理解： 若对某一马尔可夫链的状态转移矩阵有： limn → ∞Pijn = λj 并且设初始分布α = (α1, …, αn),状态总数为m 则有： Ex3.1 Two state Markov Chain 计算案例； 3.1.2 Proportion of Time in Each State 利用计算条件期望的技术，来从状态在过程中所占的比例来理解Limit distribution Ex3.2 ###### Simulate discrete-time Markov chain ######################### Simulates n steps of a Markov chain # markov(init,mat,n,states)# Generates X0, ..., Xn for a Markov chain with initiial# distribution init and transition matrix mat# Labels can be a character vector of states; default is 1, .... kmarkov &lt;- function(init,mat,n,labels) { if (missing(labels)) labels &lt;- 1:length(init)simlist &lt;- numeric(n+1)states &lt;- 1:length(init)simlist[1] &lt;- sample(states,1,prob=init)for (i in 2:(n+1)) { simlist[i] &lt;- sample(states,1,prob=mat[simlist[i-1],]) }labels[simlist]}####################################################P &lt;- matrix(c(0.1,0.2,0.4,0.3,0.4,0,0.4,0.2,0.3,0.3,0,0.4,0.2,0.1,0.4,0.3), nrow=4, byrow=TRUE)lab &lt;- c(\"Aerobics\",\"Massage\",\"Weights\",\"Yoga\")rownames(P) &lt;- labcolnames(P) &lt;- labPinit &lt;- c(1/4,1/4,1/4,1/4) # initial distributionstates &lt;- c(\"a\",\"m\",\"w\",\"y\")# simulate chain for 100 stepssimlist &lt;- markov(init,P,100,states)simlisttable(simlist)/100steps &lt;- 1000000simlist &lt;- markov(init,P,steps,states)table(simlist)/steps 3.2 Stationary Distribution 3.2.1 定义 注意Stationary Distribution的定义没有出现极限。 If the initial distributino is a stationary distribution, Then X0, X1, ⋯, Xn is a sequence of identically distributed random variables. But it doesn’t mean that the random variables are independent. Lemma 3.1: Limiting Distributions are stationary Distribution The reverse is false, 反例： ， 以及 3.2.2 Regular Matrices 一个自然的想法是问，什么样的条件下，一个马尔可夫链有极限分布，而且极限分布就是平稳分布呢。 满足如下性质的马尔可夫链是符合这个要求的 Regular Transition Matrix A transition matrix P is said to be regular if some power of P is positive. That is , for some n ≥ 1 有定理： Theorem 3.2: A markov chain whose transition matrix P is regular has a limiting distribution, which is teh unique, positive, stationary distribution of the chanin. Ex 3.3-3.4 具体算例， 3.2.3 Finding the stationary distribution 本质上这是一个特征值问题。 ### Stationary distribution of discrete-time Markov chain### (uses eigenvectors)###stationary &lt;- function(mat) {x = eigen(t(mat))$vectors[,1]as.double(x/sum(x))} Ex 3.5-3.6; 计算技巧，令x1 = 1 Ex 3.7 The Ehrenfest dog-flea model Ex 3.8 Random walk on a graph; On weighted graph Stationiary Distribution for Random walk on a weighted graph Let G = (V, E) be a weighted graph with edge weight function w(i, j). For random walk on G, the stationary distribution pi is proportion to the sum of teh edge weights incident to each vertex. That is. where w(v) = ∑z ∼ vw(v, z) On simple graph Stationary Distribution for simple Random Walk on a graph For simple random walk on a weighted graph, set , then, w(v) = deg(v),which gives Ex 3.9-3.10 如何计算的案例； 3.2.4 The Eigenvalue Connection 转置，看出与特征值的关联。 Ex 3.10 理论案例： random walk in regular graph.。 3.3 Can you find the way to state a 3.3.1 状态可到达与状态互通 Say that state j is accessible from state i, if Pijn &gt; 0. That is,there is positive probability of reaching j from i in a finite number of steps. State i and j communicate if i is accessible from j and j is accessible from i eg 3.11 本例讲述了用 Transition graphs 展示 Communication classes 3.3.2 不可约 Irreducibility A Markov chain is called irreducible if it has exactly one cmmunication class. That is, all states communicate with each other Ex 3.12 一个不可约链的例子； 3.3.3 Recurrence and Transience Given a Markov chain X0, X1, …, let Tj = min {n &gt; 0 : Xn = j}be the first passage time to state j. If Xn ≠ j, ∀n &gt; 0, seeTj = ∞. Let fj = P(Tj &lt; ∞|X0 = j) be the probability started in j eventually returns to j. State j is said to be recurrent if the Markov chain started in j eventually revists j. That is fj = 1 State j is said to be transient if there is positive probability that the Markov chain started in j never returns to j. That is fj &lt; 1 如何根据状态转移矩阵判定，某一个状态是Recurrent或Transient States。用示性函数， 由此可以推出另外一个判定条件； Recurrence, Transience State j is recurrent if and only if State j is transient if and only if Recuurence and Transience are Class Properties Theorem 3.3 The states of a communication class are either all recurrent or all transient. Corollary 3.4 For a finite irreducible Markov chain, all states are recuurent. Ex 3.13 接下来的例子是简单的一维随机游走；这个例子可以推广到高维。 3.3.4 Canonical Decomposition Closed Communication Class Lemma 3.5 A communication class is closed if it consists of all recurrent states. A finite communication class is closed only if it consits of all recurrent states. 反证法即可证得；最后便可以得到，我们想定义的； The state space S of a finite Markov chain can be partitioned into transient and reccurent states as S = T ∪ R1 ∪ ⋯Rm, where T is the set of all transient states and Ri are closed communiction classes of recurrent states. This is called the canonical decomposition. 注：由等价类的定义可以保障这么重排状态转移矩阵，是与原矩阵等价的。 Given a canonical decomposition, the state space can be reordered so that the Markov transition matrix has the block matrix form 其中O = (pij = 0), Q = (pij)i, j ∈ T, Pl = (pij)i, j ∈ Rl, l = 1, 2, ⋯, m Ex3.14 具体 case; 更进一步有： edit: 2020-05-06 3.7 Time reversibility 3.7.1 Definition The property of time reversibility can be explained intuitively as follows. If you were to take a movie of Markov chain moving forward in time and then run the movie backwards, you could not tell the difference between the two. 换成数学上的语言就是，如果假设马尔可夫链处于稳态，这时存在： P(X0 = i, X1 = j) = P(X0 = j, X1 = i) 由全概率公式可知； Time Reversibility An irreducible Markov chain with transition matrix P and stationary distribution π, if πiPij = πjPji, ∀i, j Ex 3.23; Ex 3.24；Simple random walk on a graph is time 3.7.2 Reversible Markov Chains and Radom walk Every reversible Markov chain can be considered as a random walk on a weighted graph Ex 3.25 算例； 3.7.3 The key benifit of reversibility Proposition 3.9 Let P be the transition matrix of a Markov chain. If x is a probability distribution which satisfies xiPij = xjPji, ∀i, j then x is the stationary distribution, and the markov chain is reversible. Ex 3.26 Birth-and-death chain Case: random walk with a partialy relecting boundary. 3.8 Absorbing Chains 3.8.1 定义 Absorbing State, Absorbing Chain State i is an absorbing state if Pii = 1. A Markov chain is called an absorbing chain if it has at leat one absorbing state. 根据这个定义，一个吸收的马尔可夫链的canoical decompostion可以写为： Ex 3.31 3.8.2 Expected Number of Visits to Transient States Theorem 3.11 Consider an absorbing Markov chain with t transient states. Let F be a t × t matrix indexed by transient states. where Fij is the expected number of visits to j given that the chain starts in i, Then, F = (I − Q) − 1 3.8.3 Expected Time to Absorption Absorbing Markov Chains For an absorbing Markov chain with all states either transient or absorbing. Let F = (I − Q) − 1 1. (Absorption probability) The probability that from transient state i the chain is absorbed in state j is (FR)ij 2. (Absorption time) The expected number of steps from transient state i until the chain is absorbed in some absorbing state is (F1)i 3.8.4 Expected Hitting Time for Irreducible chain 3.8.5 Patterns in Sequences 3.9 Regenration and strong Markov property 3.10 Proofs of limiting Theorem 剩下的都是常规内容。不再赘述。 总的来说，这一章的章节组织很有条理，对初学者友好。而且选的例子很有启发性。 题外话： 有个值得思考的问题，这种偏向应用的数学内容的教材，如何平衡论述的逻辑，理论以及思考的深度，以及应用的广度，以及对于读者的吸引性和实用性，都是很需要功底的。但是这方面做的好的教材真的太少了。 理想的大学教师，是学术成就和教学成就都很出色，但是这毕竟是少数。 有一对儿相互矛盾的命题： 大学生应该提高自学能力，不要指望老师手把手的教？ 国家给了大学老师工资，大学生也付了学费，如果都靠自学的话，要大学干什么？ 依笔者看来，大学提供的是一套适合学习和研究的硬件设施，一张平静的书桌，一群志同道合的良师益友。这些环境和人，是任何其它机构或者网课代替不了的。","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"}],"author":"夏目沉吟"},{"title":"","slug":"networkdata-quickstart","date":"2020-05-04T15:33:30.000Z","updated":"2025-01-11T17:16:31.839Z","comments":true,"path":"2020/05/04/networkdata-quickstart/","permalink":"https://landau1994.github.io/2020/05/04/networkdata-quickstart/","excerpt":"","text":"所选例子出自Modern Statistics for Modern Biology(Susan Holmes, Wolfgang Huber) 无向图的邻接矩阵是一个0-1矩阵： library(igraph)library(ggplot2)library(ggnetwork)library(network)edges1 &lt;- matrix(c(1,3,2,3,3,4,4,5,4,6),byrow = TRUE,ncol = 2)### generate adjacency matrixedges1 &lt;- as.data.frame(edges1)mat &lt;- matrix(data = 0,nrow = 6,ncol = 6)for(ii in 1:6){ mat[edges1[ii,1],edges1[ii,2]] &lt;- 1 mat[edges1[ii,2],edges1[ii,1]] &lt;- 1}### Prepare data to plotdat_long &lt;- reshape2::melt(mat)dat_long$value &lt;- as.factor(dat_long$value)colnames(dat_long) &lt;- c(\"V1\",\"V2\",\"value\")### plotgg &lt;- ggplot(dat_long)+ geom_tile(aes(V1,V2,fill=value), color=\"#7f7f7f\")+ scale_fill_manual(values=c(\"white\", \"black\"))+ coord_equal()+ labs(x=NULL, y=NULL)+ scale_x_continuous(breaks = 1:6)+ scale_y_reverse(breaks=1:6)+ theme_bw()+ theme(panel.grid=element_blank())+ theme(panel.border=element_blank())gg 从邻接矩阵得到Graph: g1 &lt;- graph_from_adjacency_matrix(mat,mode = \"undirected\")plot(g1,vertex.size=25,edge.width=5,vertex.color=\"coral\") 给定edgelist，得到Graph edges1 &lt;- matrix(c(1,3,2,3,3,4,4,5,4,6),byrow = TRUE,ncol = 2)g1 &lt;- graph_from_edgelist(edges1,directed = F)plot(g1,vertex.size=25,edge.width=5,vertex.color=\"coral\") 更为高级的是，从数据中计算出邻接矩阵，并且自定义可视化的layout。 library(rworldmap)### obtain data; get the binary matrixload(\"D:/tmp/Moderstatdata/data/dist2009c.RData\")country09 = attr(dist2009c, \"Label\")mstree2009 = ape::mst(dist2009c)### calculate layout from world mapmat = match(country09, countriesLow$NAME)coords2009 = data.frame( lat = countriesLow$LAT[mat], lon = countriesLow$LON[mat], country = country09)layoutCoordinates = cbind( x = jitter(coords2009$lon, amount = 15), y = jitter(coords2009$lat, amount = 8))labc = names(table(country09)[which(table(country09) &gt; 1)])matc = match(labc, countriesLow$NAME)dfc = data.frame( latc = countriesLow$LAT[matc], lonc = countriesLow$LON[matc], labc)dfctrans = dfcdfctrans[, 1] = (dfc[,1] + 31) / 93dfctrans[, 2] = (dfc[,2] + 105) / 238ggeo09 = ggnetwork(mstree2009, arrow.gap = 0, layout = layoutCoordinates)###plotggplot(ggeo09, aes(x = x, y = y, xend = xend, yend = yend)) + geom_edges(color = \"black\", alpha = 0.5, curvature = 0.1) + geom_nodes(aes(color = vertex.names), size = 2) + theme_blank() + geom_label(data = dfctrans, aes(x = lonc, xend = lonc, y = latc, yend = latc, label = labc, fill = labc), colour = \"white\", alpha = 0.5, size = 3) + theme(legend.position = \"none\")","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"Graph","slug":"Graph","permalink":"https://landau1994.github.io/tags/Graph/"},{"name":"Network","slug":"Network","permalink":"https://landau1994.github.io/tags/Network/"}],"author":"夏目沉吟"},{"title":"Calculate pi in R quikstart","slug":"Calculate-pi-in-R-quikstart","date":"2020-04-24T14:25:00.000Z","updated":"2025-01-11T17:16:31.798Z","comments":true,"path":"2020/04/24/Calculate-pi-in-R-quikstart/","permalink":"https://landau1994.github.io/2020/04/24/Calculate-pi-in-R-quikstart/","excerpt":"","text":"R中也可以用Rmpfr包实现多精度的计算。例如，我们可以用如下代码实现AGM算法计算Pi到小数点后256位。 library(Rmpfr)piMpfr &lt;- function(prec=256, itermax = 100, verbose=TRUE) { m2 &lt;- mpfr(2, prec) # '2' as mpfr number ## -&gt; all derived numbers are mpfr (with precision 'prec') p &lt;- m2 + sqrt(m2) # 2 + sqrt(2) = 3.414.. y &lt;- sqrt(sqrt(m2)) # 2^ {1/4} x &lt;- (y+1/y) / m2 it &lt;- 0L repeat { p.old &lt;- p it &lt;- it+1L p &lt;- p * (1+x) / (1+y) if(verbose) cat(sprintf(\"it=%2d, pi^ = %s, |.-.|/|.|=%e\\n\", it, formatMpfr(p, min(50, prec/log2(10))), 1-p.old/p)) if (abs(p-p.old) &lt;= m2^(-prec)) break if(it &gt; itermax) { warning(\"not converged in\", it, \"iterations\") ; break } ## else s &lt;- sqrt(x) y &lt;- (y*s + 1/s) / (1+y) x &lt;- (s+1/s)/2 } p}piMpfr(prec = 256) ## it= 1, pi^ = 3.1426067539416226007907198236183018919713562462772, |.-.|/|.|=-8.642723e-02 ## it= 2, pi^ = 3.1415926609660442304977522351203396906792842568645, |.-.|/|.|=-3.227958e-04 ## it= 3, pi^ = 3.1415926535897932386457739917571417940347896238675, |.-.|/|.|=-2.347934e-09 ## it= 4, pi^ = 3.1415926535897932384626433832795028841972241204666, |.-.|/|.|=-5.829228e-20 ## it= 5, pi^ = 3.1415926535897932384626433832795028841971693993751, |.-.|/|.|=-1.741826e-41 ## it= 6, pi^ = 3.1415926535897932384626433832795028841971693993751, |.-.|/|.|=0.000000e+00 ## 1 'mpfr' number of precision 256 bits ## [1] 3.141592653589793238462643383279502884197169399375105820974944592307816406286163","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"}],"author":"夏目沉吟"},{"title":"A Hard Rain's A-Gonna Fall","slug":"A-Hard-Rain-s-A-Gonna-Fall","date":"2020-04-20T02:31:32.000Z","updated":"2025-01-11T17:16:31.795Z","comments":true,"path":"2020/04/20/A-Hard-Rain-s-A-Gonna-Fall/","permalink":"https://landau1994.github.io/2020/04/20/A-Hard-Rain-s-A-Gonna-Fall/","excerpt":"","text":"A Hard Rain’s A-Gonna Fall是美国国宝级歌手，诗人，诺贝尔文学奖得主Bob Dylan的名曲之一，虽然原唱说不上多么好听，但是歌词很有意境，分享如下： A Hard Rain’s A-Gonna Fall Bob Dylan Oh, where have you been, my blue-eyed son? Oh, where have you been, my darling young one? I’ve stumbled on the side of twelve misty mountains I’ve walked and I’ve crawled on six crooked highways I’ve stepped in the middle of seven sad forests I’ve been out in front of a dozen dead oceans I’ve been ten thousand miles in the mouth of a graveyard And it’s a hard, and it’s a hard, it’s a hard, and it’s a hard And it’s a hard rain’s a-gonna fall Oh, what did you see, my blue-eyed son? Oh, what did you see, my darling young one? I saw a newborn baby with wild wolves all around it I saw a highway of diamonds with nobody on it I saw a black branch with blood that kept drippin’ I saw a room full of men with their hammers a-bleedin’ I saw a white ladder all covered with water I saw ten thousand talkers whose tongues were all broken I saw guns and sharp swords in the hands of young children And it’s a hard, and it’s a hard, it’s a hard, it’s a hard And it’s a hard rain’s a-gonna fall And what did you hear, my blue-eyed son? And what did you hear, my darling young one? I heard the sound of a thunder, it roared out a warnin’ Heard the roar of a wave that could drown the whole world Heard one person starve, I heard many people laughin’ Heard the song of a poet who died in the gutter Heard the sound of a clown who cried in the alley And it’s a hard, and it’s a hard, it’s a hard, it’s a hard And it’s a hard rain’s a-gonna fall Oh, who did you meet, my blue-eyed son? Who did you meet, my darling young one? I met a young child beside a dead pony I met a white man who walked a black dog I met a young woman whose body was burning I met a young girl, she gave me a rainbow I met one man who was wounded in love I met another man who was wounded with hatred And it’s a hard, it’s a hard, it’s a hard, it’s a hard It’s a hard rain’s a-gonna fall Oh, what’ll you do now, my blue-eyed son? Oh, what’ll you do now, my darling young one? I’m a-goin’ back out ‘fore the rain starts a-fallin’ I’ll walk to the depths of the deepest black forest Where the people are many and their hands are all empty Where the pellets of poison are flooding their waters Where the home in the valley meets the damp dirty prison Where the executioner’s face is always well-hidden Where hunger is ugly, where souls are forgotten Where black is the color, where none is the number And I’ll tell it and think it and speak it and breathe it And reflect it from the mountain so all souls can see it Then I’ll stand on the ocean until I start sinkin’ But I’ll know my song well before I start singin’ And it’s a hard, it’s a hard, it’s a hard, it’s a hard It’s a hard rain’s a-gonna fall","categories":[{"name":"others","slug":"others","permalink":"https://landau1994.github.io/categories/others/"}],"tags":[{"name":"art","slug":"art","permalink":"https://landau1994.github.io/tags/art/"}],"author":"夏目沉吟"},{"title":"LearnSeurat_CITE_seq","slug":"LearnSeurat_CITEseq","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.823Z","comments":true,"path":"2020/04/20/LearnSeurat_CITEseq/","permalink":"https://landau1994.github.io/2020/04/20/LearnSeurat_CITEseq/","excerpt":"","text":"前言 CITE-seq是Rahul Satija和Peter Smibert两个组合作开发的在单细胞精度，同时测量细胞表面蛋白表达和转录组的技术。该技术原理如下： CITE-seq原理图，用抗体来源标签，实现细胞表面蛋白定量 该项技术可以用于免疫相关的单细胞测序研究中。例如, 有研究表明称： 他们在人和小鼠非小细胞肺癌中进行单细胞RNA测序，鉴定了一群DC，并将其命名为“富含免疫调节分子的成熟DC”（mregDC），这是由于它们共表达了免疫调节基因（Cd274，Pdcd1lg2和Cd200）和成熟基因（Cd40，Ccr7和Il12b）。 这段中文报道来自小柯机器人 Rahul Satija组开发的软件Seurat有一个教程，可以分析CITE-seq数据。本文基于该教程对该类型数据的分析进行说明。 数据载入 首先我们需要获取数据，该数据集取样为8617个脐带血单核细胞，包含了表达谱数据和11个抗体来源标签数据（antibody-derived tags ,ADT)。 library(Seurat)library(SeuratData)library(ggplot2)library(patchwork)### AvailableData() check avaliable data: we choose cbmc### InstallData('cbmc')library(cbmc.SeuratData)data(\"cbmc\")### expression matrixcbmc[[\"RNA\"]]@counts[1:10,1:10] ## 10 x 10 sparse Matrix of class \"dgCMatrix\" ## ## A1BG . . . . . . . . . . ## A1BG-AS1 . . . . . . . . . . ## A1CF . . . . . . . . . . ## A2M . . . . . . . . . . ## A2M-AS1 . . . . . . . 1 . . ## A2ML1 . . . . . . . . . . ## A4GALT . . . . . . . . . . ## A4GNT . . . . . . . . . . ## AAAS . . . . . . . . . 1 ## AACS . . . . . . . . . . ### ADT count matrix### Actually there are just 10 surface proteincbmc[[\"ADT\"]]@counts[1:10,1:10] ## 10 x 10 sparse Matrix of class \"dgCMatrix\" ## ## CD3 60 52 89 55 63 82 53 42 103 56 ## CD4 72 49 112 66 80 78 63 59 122 70 ## CD8 76 59 61 56 94 57 61 55 64 80 ## CD45RA 575 3943 682 378 644 479 487 472 540 535 ## CD56 64 68 87 58 104 44 64 48 136 91 ## CD16 161 107 117 82 168 92 77 99 235 131 ## CD11c 77 65 65 44 92 63 70 75 106 69 ## CD14 206 129 169 136 164 122 112 111 206 204 ## CD19 70 665 79 49 81 44 60 58 61 107 ## CD34 179 79 78 83 152 103 79 86 144 193 ### show default assayDefaultAssay(cbmc) ## [1] \"RNA\" 根据基因表达进行聚类 注意在默认参数的情况下，下述操作时对Default Assay进行的 # standard log-normalizationcbmc &lt;- NormalizeData(cbmc)# choose ~1k variable featurescbmc &lt;- FindVariableFeatures(cbmc)# standard scaling (no regression)cbmc &lt;- ScaleData(cbmc)# Run PCA, select 13 PCs for tSNE visualization and graph-based clusteringcbmc &lt;- RunPCA(cbmc, verbose = FALSE) 下面的图是根据标准差来选择PCs ElbowPlot(cbmc, ndims = 50) 聚类和t-SNE降维 cbmc &lt;- FindNeighbors(cbmc, dims = 1:25)cbmc &lt;- FindClusters(cbmc, resolution = 0.8) ## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck ## ## Number of nodes: 8617 ## Number of edges: 347548 ## ## Running Louvain algorithm... ## Maximum modularity in 10 random starts: 0.8592 ## Number of communities: 19 ## Elapsed time: 3 seconds cbmc &lt;- RunTSNE(cbmc, dims = 1:25, method = \"FIt-SNE\")# Find the markers that define each cluster, and use these to annotate the clusters, we use# max.cells.per.ident to speed up the processcbmc.rna.markers &lt;- FindAllMarkers(cbmc, max.cells.per.ident = 100, min.diff.pct = 0.3, only.pos = TRUE)# Note, for simplicity we are merging two CD14+ Monocyte clusters (that differ in expression of# HLA-DR genes) and NK clusters (that differ in cell cycle stage)new.cluster.ids &lt;- c(\"Memory CD4 T\", \"CD14+ Mono\", \"Naive CD4 T\", \"NK\", \"CD14+ Mono\", \"Mouse\", \"B\", \"CD8 T\", \"CD16+ Mono\", \"T/Mono doublets\", \"NK\", \"CD34+\", \"Multiplets\", \"Mouse\", \"Eryth\", \"Mk\", \"Mouse\", \"DC\", \"pDCs\")names(new.cluster.ids) &lt;- levels(cbmc)cbmc &lt;- RenameIdents(cbmc, new.cluster.ids) 我们看看聚类结果： DimPlot(cbmc, label = TRUE) + NoLegend() ## Warning: Using `as.character()` on a quosure is deprecated as of rlang 0.3.0. ## Please use `as_label()` or `as_name()` instead. ## This warning is displayed once per session. 蛋白表达数据处理 Seurat3的assay实现多个组学或者模态的数据的存储和获取。 代码里的注释来自Seurat官网。 # Now we can repeat the preprocessing (normalization and scaling) steps that we typically run# with RNA, but modifying the 'assay' argument. For CITE-seq data, we do not recommend typical# LogNormalization. Instead, we use a centered log-ratio (CLR) normalization, computed# independently for each feature. This is a slightly improved procedure from the original# publication, and we will release more advanced versions of CITE-seq normalizations soon.cbmc &lt;- NormalizeData(cbmc, assay = \"ADT\", normalization.method = \"CLR\")cbmc &lt;- ScaleData(cbmc, assay = \"ADT\") 在RNA表达谱的降维Embedding中同时展示展示蛋白表达水平和基因表达水平： 散点图：横纵轴为降维的坐标： # in this plot, protein (ADT) levels are on top, and RNA levels are on the bottomFeaturePlot(cbmc, features = c(\"adt_CD3\", \"adt_CD11c\", \"adt_CD8\", \"adt_CD16\", \"CD3E\", \"ITGAX\", \"CD8A\", \"FCGR3A\"), min.cutoff = \"q05\", max.cutoff = \"q95\", ncol = 2) Ridge Plot: RidgePlot(cbmc, features = c(\"adt_CD3\", \"adt_CD8\", \"CD3E\",\"CD8A\"),ncol = 2) 散点图：横纵轴为表达量；这个类似于FACS # Draw ADT scatter plots (like biaxial plots for FACS). Note that you can even 'gate' cells if# desired by using HoverLocator and FeatureLocatorFeatureScatter(cbmc, feature1 = \"adt_CD19\", feature2 = \"adt_CD3\") 我们也可以看看蛋白表达和基因表达的关系： # view relationship between protein and RNAFeatureScatter(cbmc, feature1 = \"adt_CD3\", feature2 = \"CD3E\") 我们可以看看T细胞： # Let's plot CD4 vs CD8 levels in T cellstcells &lt;- subset(cbmc, idents = c(\"Naive CD4 T\", \"Memory CD4 T\", \"CD8 T\"))FeatureScatter(tcells, feature1 = \"adt_CD4\", feature2 = \"adt_CD8\") 选没有标准化的原始数据我们看看，坐标轴的间距太大，会有misleading # # Let's look at the raw (non-normalized) ADT counts. You can see the values are quite high,# particularly in comparison to RNA values. This is due to the significantly higher protein copy# number in cells, which significantly reduces 'drop-out' in ADT dataFeatureScatter(tcells, feature1 = \"adt_CD4\", feature2 = \"adt_CD8\", slot = \"counts\") 这里还是可以观察到dropouts现象的，据原作者说： &gt; If you look a bit more closely, you’ll see that our CD8 T cell cluster is enriched for CD8 T cells, but still contains many CD4+ CD8- T cells. This is because Naive CD4 and CD8 T cells are quite similar transcriptomically, and the RNA dropout levels for CD4 and CD8 are quite high. This demonstrates the challenge of defining subtle immune cell differences from scRNA-seq data alone. 画热图，Seurat3 加了 downsample的功能。 # Downsample the clusters to a maximum of 300 cells each (makes the heatmap easier to see for small clusters)cbmc.small &lt;- subset(cbmc, downsample = 300)# Find protein markers for all clusters, and draw a heatmapadt.markers &lt;- rownames(cbmc.small[[\"ADT\"]]@counts) 我们可以看看Seurat热图的默认配色（三个冒号可以看更为底层的函数）, 个人觉得并不好看。 # using code from RColorBrewer to demo the paletten = 200par(mfrow=c(3,1))image( 1:n, 1, as.matrix(1:n), col = Seurat:::PurpleAndYellow(k=n), xlab = \"PurpleAndYellow n\", ylab = \"\", xaxt = \"n\", yaxt = \"n\", bty = \"n\")image( 1:n, 1, as.matrix(1:n), col = colorRampPalette(c(\"navy\", \"white\", \"firebrick3\"))(n), xlab = \"NavyWhite3Firebrick3 n\", ylab = \"\", xaxt = \"n\", yaxt = \"n\", bty = \"n\")image( 1:n, 1, as.matrix(1:n), col = colorRampPalette(RColorBrewer::brewer.pal(11,\"RdBu\"))(n), xlab = \"RdBu n\", ylab = \"\", xaxt = \"n\", yaxt = \"n\", bty = \"n\") 把默认配色换掉,见 mypal &lt;- rev(colorRampPalette(RColorBrewer::brewer.pal(11,\"RdBu\"))(256))#mypal2 &lt;- colorRampPalette(c(\"navy\", \"white\", \"firebrick3\"))(256)DoHeatmap(cbmc.small, features = unique(adt.markers), assay = \"ADT\", angle = 90,size = 3)+ scale_fill_gradientn(colors = mypal) ## Scale for 'fill' is already present. Adding another scale for 'fill', which ## will replace the existing scale. 去除细胞杂质， # You can see that our unknown cells co-express both myeloid and lymphoid markers (true at the# RNA level as well). They are likely cell clumps (multiplets) that should be discarded. We'll# remove the mouse cells now as wellcbmc &lt;- subset(cbmc, idents = c(\"Multiplets\", \"Mouse\"), invert = TRUE) 直接根据蛋白质表达水平进行聚类 # Because we're going to be working with the ADT data extensively, we're going to switch the# default assay to the 'CITE' assay. This will cause all functions to use ADT data by default,# rather than requiring us to specify it each timeDefaultAssay(cbmc) &lt;- \"ADT\"cbmc &lt;- RunPCA(cbmc, features = rownames(cbmc), reduction.name = \"pca_adt\", reduction.key = \"pca_adt_\", verbose = FALSE) 再来看PCA(其实这里算是degenrate到线性组合了) DimPlot(cbmc, reduction = \"pca_adt\") # Since we only have 10 markers, instead of doing PCA, we'll just use a standard euclidean# distance matrix here. Also, this provides a good opportunity to demonstrate how to do# visualization and clustering using a custom distance matrix in Seuratadt.data &lt;- GetAssayData(cbmc, slot = \"data\")adt.dist &lt;- dist(t(adt.data))# Before we recluster the data on ADT levels, we'll stash the RNA cluster IDs for latercbmc[[\"rnaClusterID\"]] &lt;- Idents(cbmc)# Now, we rerun tSNE using our distance matrix defined only on ADT (protein) levels.cbmc[[\"tsne_adt\"]] &lt;- RunTSNE(adt.dist, assay = \"ADT\", reduction.key = \"adtTSNE_\")cbmc[[\"adt_snn\"]] &lt;- FindNeighbors(adt.dist)$snncbmc &lt;- FindClusters(cbmc, resolution = 0.2, graph.name = \"adt_snn\") ## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck ## ## Number of nodes: 7895 ## Number of edges: 258146 ## ## Running Louvain algorithm... ## Maximum modularity in 10 random starts: 0.9491 ## Number of communities: 11 ## Elapsed time: 2 seconds # We can compare the RNA and protein clustering, and use this to annotate the protein clustering# (we could also of course use FindMarkers)clustering.table &lt;- table(Idents(cbmc), cbmc$rnaClusterID)clustering.table ## ## Memory CD4 T CD14+ Mono Naive CD4 T NK B CD8 T CD16+ Mono ## 0 1754 0 1217 29 0 27 0 ## 1 0 2189 0 4 0 0 30 ## 2 3 0 2 890 3 1 0 ## 3 0 4 0 2 319 0 2 ## 4 24 0 18 4 1 243 0 ## 5 1 27 4 157 2 2 10 ## 6 4 5 0 1 0 0 0 ## 7 4 59 4 0 0 0 9 ## 8 0 9 0 2 0 0 179 ## 9 0 0 1 0 0 0 0 ## 10 1 0 2 0 25 0 0 ## ## T/Mono doublets CD34+ Eryth Mk DC pDCs ## 0 5 2 4 24 1 2 ## 1 1 1 5 25 55 0 ## 2 0 1 3 7 2 1 ## 3 0 2 2 3 0 0 ## 4 0 0 1 2 0 0 ## 5 56 0 9 16 6 2 ## 6 1 113 81 16 5 0 ## 7 117 0 0 2 0 1 ## 8 0 0 0 1 0 0 ## 9 0 0 0 0 1 43 ## 10 2 0 0 0 0 0 下面这个embeding 还是根据ADT来的（不过只要marker连续，只有10个也没有关系？） new.cluster.ids &lt;- c(\"CD4 T\", \"CD14+ Mono\", \"NK\", \"B\", \"CD8 T\", \"NK\", \"CD34+\", \"T/Mono doublets\", \"CD16+ Mono\", \"pDCs\", \"B\")names(new.cluster.ids) &lt;- levels(cbmc)cbmc &lt;- RenameIdents(cbmc, new.cluster.ids)tsne_rnaClusters &lt;- DimPlot(cbmc, reduction = \"tsne_adt\", group.by = \"rnaClusterID\") + NoLegend()tsne_rnaClusters &lt;- tsne_rnaClusters + ggtitle(\"Clustering based on scRNA-seq\") + theme(plot.title = element_text(hjust = 0.5))tsne_rnaClusters &lt;- LabelClusters(plot = tsne_rnaClusters, id = \"rnaClusterID\", size = 4)tsne_adtClusters &lt;- DimPlot(cbmc, reduction = \"tsne_adt\", pt.size = 0.5) + NoLegend()tsne_adtClusters &lt;- tsne_adtClusters + ggtitle(\"Clustering based on ADT signal\") + theme(plot.title = element_text(hjust = 0.5))tsne_adtClusters &lt;- LabelClusters(plot = tsne_adtClusters, id = \"ident\", size = 4)# Note: for this comparison, both the RNA and protein clustering are visualized on a tSNE# generated using the ADT distance matrix.wrap_plots(list(tsne_rnaClusters, tsne_adtClusters), ncol = 2) 对于该结果，作者是这么解释的： The ADT-based clustering yields similar results, but with a few differences + Clustering is improved for CD4/CD8 T cell populations, based on the robust ADT data for + CD4, CD8, CD14, and CD45RA + However, some clusters for which the ADT data does not contain good distinguishing protein markers (i.e. Mk/Ery/DC) lose separation You can verify this using FindMarkers at the RNA level, as well 更多 pbmc 10k的细胞也提供了CITE-seq的多模态数据，具体细节，请看Seurat官方教程。","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"},{"name":"sc-seq","slug":"sc-seq","permalink":"https://landau1994.github.io/tags/sc-seq/"}],"author":"Landau1994"},{"title":"Learn-igraph-Basic","slug":"Learnigraph-1-ManuNetworkDataBasic","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.824Z","comments":true,"path":"2020/04/20/Learnigraph-1-ManuNetworkDataBasic/","permalink":"https://landau1994.github.io/2020/04/20/Learnigraph-1-ManuNetworkDataBasic/","excerpt":"","text":"Learn-igraph系列是对Statistical Analysis of Network Data with R一书的学习笔记，介绍如何使用R进行网络数据分析，网络数据的处理主要是基于igraph包，可视化用的是ggnet 0. 基本概念 一些需要知道的基本概念； Network; Graph; Order of a graph; Size of a graph; directed graph; undirected graph; subgraph; 1. 创建igraph class 1.1 无向图 igraph包处理网络图的数据结构为igraph class, 最基础的创建方式如下： library(igraph)library(ggraph)library(ggnetwork)g &lt;- graph.formula(1-2,1-3,2-3,2-4,3-5,4-5,4-6,4-7,5-6,6-7)l &lt;- layout.auto(g)plot(g, layout=l, vertex.color=\"skyblue\") 该网络的基本信息可以通过如下方式获得： V(g)###+ 7/7 vertices, named, from 27d8280:###[1] 1 2 3 4 5 6 7E(g)###+ 10/10 edges from 27d8280 (vertex names):###[1] 1--2 1--3 2--3 2--4 3--5 4--5 4--6 4--7 5--6 6--7###str(g)get.adjedgelist(g)# $`1`# + 2/10 edges from f3f6e64 (vertex names):# [1] 1--2 1--3# # $`2`# + 3/10 edges from f3f6e64 (vertex names):# [1] 1--2 2--3 2--4# # $`3`# + 3/10 edges from f3f6e64 (vertex names):# [1] 1--3 2--3 3--5# # $`4`# + 4/10 edges from f3f6e64 (vertex names):# [1] 2--4 4--5 4--6 4--7# # $`5`# + 3/10 edges from f3f6e64 (vertex names):# [1] 3--5 4--5 5--6# # $`6`# + 3/10 edges from f3f6e64 (vertex names):# [1] 4--6 5--6 6--7# # $`7`# + 2/10 edges from f3f6e64 (vertex names):# [1] 4--7 6--7get.edgelist(g)# [,1] [,2]# [1,] \"1\" \"2\" # [2,] \"1\" \"3\" # [3,] \"2\" \"3\" # [4,] \"2\" \"4\" # [5,] \"3\" \"5\" # [6,] \"4\" \"5\" # [7,] \"4\" \"6\" # [8,] \"4\" \"7\" # [9,] \"5\" \"6\" # [10,] \"6\" \"7\" print(g, e=TRUE, v=TRUE)# IGRAPH f673c51 UN-- 7 10 -- # + attr: name (v/c)# + edges from f673c51 (vertex names):# [1] 1--2 1--3 2--3 2--4 3--5 4--5 4--6 4--7 5--6 6--7get.adjacency(g)# 7 x 7 sparse Matrix of class \"dgCMatrix\"# 1 2 3 4 5 6 7# 1 . 1 1 . . . .# 2 1 . 1 1 . . .# 3 1 1 . . 1 . .# 4 . 1 . . 1 1 1# 5 . . 1 1 . 1 .# 6 . . . 1 1 . 1# 7 . . . 1 . 1 . 1.2 有向图 同样的方法，也可以用来创建有向图； dg &lt;- graph.formula(1-+2,1-+3,2++3)op &lt;- par(mfrow=c(1,2))plot(g, vertex.size=10,layout=l, vertex.color=\"skyblue\")plot(dg,vertex.size=10,vertex.color=\"skyblue\") par(op) 1.3 从邻接矩阵导入图； 我们选择一个神奇的数据Arecibo_message[https://en.wikipedia.org/wiki/Arecibo_message], 来说明,有时候,信息所对应的矩阵，可能就是一张图片，而不是一个图。 ###python command comes from###https://codegolf.stackexchange.com/questions/182924/output-the-arecibo-messagemat &lt;- reticulate::py_eval(\"''.join(bin(i)[3:]for i in b'`UP@JB`IDQKJjjd`@@@@@L@@Ah@@CP@@J`@@_@@@@@LNLLP@FPtXpu}}}|@@@@`@@`@@@A@@A~@@~@@@CCCcDA@DMCGM____@@@@HF@H@L@@PX@_`pO`A`@HA@HHF@`LLB@FHX@@s@@Xa`CC@`HD@``L@b@XAD@PDDA@PD@C@F@X@ck@A@P@BCx@DKi[@gI\\x7f\\\\NC\\\\@TGY@hOrAPXDFp@@@@@\\\\D@@zbjipAU@@B`@Gp@@\\x7fx@G@\\\\@X@LAh@lFXCLHhJHQHdPBJH@DHP@H@`@Dh@OOix')[1:]\")mat &lt;- as.integer(unlist(strsplit(mat,split = \"\")))mat &lt;- matrix(data = mat,nrow = 23,ncol = 73)expand.matrix &lt;- function(A){ m &lt;- nrow(A) n &lt;- ncol(A) B &lt;- matrix(0,nrow = m, ncol = m) C &lt;- matrix(0,nrow = n, ncol = n) cbind(rbind(B,t(A)),rbind(A,C))}g1 &lt;- graph_from_adjacency_matrix(expand.matrix(mat),mode = \"undirected\")plot(g1,vertex.size=10,edge.width=2,layout=layout.circle,vertex.color=\"coral\") 如果直接可视化这个图，我们什么也看不出来，然而，如果我们用将原数据视为栅格数据，那么，我们能看出这个数据的内涵是很丰富的 dat_long &lt;- reshape2::melt(mat)dat_long$value &lt;- as.factor(dat_long$value)colnames(dat_long) &lt;- c(\"V1\",\"V2\",\"value\")### plotgg &lt;- ggplot(dat_long)+ geom_tile(aes(V1,V2,fill=value), color=\"#7f7f7f\")+ scale_fill_manual(values=c(\"black\", \"white\"))+ coord_equal()+ labs(x=NULL, y=NULL)+ scale_x_continuous(breaks = 1:6)+ scale_y_reverse(breaks=1:6)+ theme_bw()+ theme(panel.grid=element_blank())+ theme(panel.border=element_blank(), axis.ticks=element_blank(), axis.text = element_blank(), legend.position = \"none\")gg 1.4 从data.frame中创建图 需要两个输入，一个是边的信息，一个是节点的信息 ## A simple example with a couple of actors## The typical case is that these tables are read in from files....actors &lt;- data.frame(name=c(\"Alice\", \"Bob\", \"Cecil\", \"David\", \"Esmeralda\"), age=c(48,33,45,34,21), gender=c(\"F\",\"M\",\"F\",\"M\",\"F\"))relations &lt;- data.frame(from=c(\"Bob\", \"Cecil\", \"Cecil\", \"David\", \"David\", \"Esmeralda\"), to=c(\"Alice\", \"Bob\", \"Alice\", \"Alice\", \"Bob\", \"Alice\"), same.dept=c(FALSE,FALSE,TRUE,FALSE,FALSE,TRUE), friendship=c(4,5,5,2,1,1), advice=c(4,5,5,4,2,3))g &lt;- graph_from_data_frame(relations, directed=TRUE, vertices=actors)## The opposite operationas_data_frame(g, what=\"vertices\") ## name age gender ## Alice Alice 48 F ## Bob Bob 33 M ## Cecil Cecil 45 F ## David David 34 M ## Esmeralda Esmeralda 21 F as_data_frame(g, what=\"edges\") ## from to same.dept friendship advice ## 1 Bob Alice FALSE 4 4 ## 2 Cecil Bob FALSE 5 5 ## 3 Cecil Alice TRUE 5 5 ## 4 David Alice FALSE 2 4 ## 5 David Bob FALSE 1 2 ## 6 Esmeralda Alice TRUE 1 3 可视化， plot(g,vertex.size=10,vertex.color=\"skyblue\") 1.5 用预定义的函数生成 igraph里有很多带make的函数，是可以生成图的 # ls.str and lsf.str return an object of class \"ls_str\", basically the character vector of matching names (functions only for lsf.str), similarly to ls, with a print() method that calls str() on each object.###head(lsf.str(\"package:igraph\"))grep(pattern = \"^make\",x=ls(\"package:igraph\"),value = T) ## [1] \"make_\" \"make_bipartite_graph\" ## [3] \"make_chordal_ring\" \"make_clusters\" ## [5] \"make_de_bruijn_graph\" \"make_directed_graph\" ## [7] \"make_ego_graph\" \"make_empty_graph\" ## [9] \"make_full_bipartite_graph\" \"make_full_citation_graph\" ## [11] \"make_full_graph\" \"make_graph\" ## [13] \"make_kautz_graph\" \"make_lattice\" ## [15] \"make_line_graph\" \"make_ring\" ## [17] \"make_star\" \"make_tree\" ## [19] \"make_undirected_graph\" 我们展示其中的一些图： g1 &lt;- make_tree(10, 2)g2 &lt;- make_bipartite_graph( rep(0:1,length=10), c(1:10))g3 &lt;- make_star(10, mode = \"out\")g4 &lt;- make_star(10, mode = \"in\")op &lt;- par(mfrow=c(2,2))plot(g1,vertex.size=20,vertex.color=\"skyblue\")plot(g2,vertex.size=20,vertex.color=\"skyblue\")plot(g3,vertex.size=20,vertex.color=\"skyblue\")plot(g4,vertex.size=20,vertex.color=\"skyblue\") par(op) 2. 基本操作 诱导子图 g &lt;- graph.formula(1-2,1-3,2-3,2-4,3-5,4-5,4-6,4-7,5-6,6-7)h &lt;- induced.subgraph(g,1:5)print(h) ## IGRAPH d91ee38 UN-- 5 6 -- ## + attr: name (v/c) ## + edges from d91ee38 (vertex names): ## [1] 1--2 1--3 2--3 2--4 3--5 4--5 Exclusion： h &lt;- g - vertices(c(6,7))print(h) ## IGRAPH d923ec9 UN-- 5 6 -- ## + attr: name (v/c) ## + edges from d923ec9 (vertex names): ## [1] 1--2 1--3 2--3 2--4 3--5 4--5 Inclusion: h &lt;- h + vertices(c(6,7))g &lt;- h + edges(c(4,6),c(4,7),c(5,6),c(6,7))print(g) ## IGRAPH d928f5d UN-- 7 10 -- ## + attr: name (v/c) ## + edges from d928f5d (vertex names): ## [1] 1--2 1--3 2--3 2--4 3--5 4--5 4--6 4--7 5--6 6--7 union: h1 &lt;- hh2 &lt;- graph.formula(4-6,4-7,5-6,6-7)g &lt;- graph.union(h1,h2)print(g) ## IGRAPH d92f82f UN-- 7 10 -- ## + attr: name (v/c) ## + edges from d92f82f (vertex names): ## [1] 6--7 5--6 4--7 4--6 4--5 3--5 2--4 2--3 1--3 1--2 3. 查看/添加/修改 属性 首先创建一个示例的图， ## A simple example with a couple of actors## The typical case is that these tables are read in from files....actors &lt;- data.frame(name=c(\"Alice\", \"Bob\", \"Cecil\", \"David\", \"Esmeralda\"), age=c(48,33,45,34,21), gender=c(\"F\",\"M\",\"F\",\"M\",\"F\"))relations &lt;- data.frame(from=c(\"Bob\", \"Cecil\", \"Cecil\", \"David\", \"David\", \"Esmeralda\"), to=c(\"Alice\", \"Bob\", \"Alice\", \"Alice\", \"Bob\", \"Alice\"), same.dept=c(FALSE,FALSE,TRUE,FALSE,FALSE,TRUE), friendship=c(4,5,5,2,1,1), advice=c(4,5,5,4,2,3))g &lt;- graph_from_data_frame(relations, directed=TRUE, vertices=actors) 我们可以通过$运算符来查看，添加，修改属性 ###check edge attributenames(edge_attr(g))###[1] \"same.dept\" \"friendship\" \"advice\" ###vertextnames(vertex_attr(g))###[1] \"name\" \"age\" \"gender\"###Vertex# list.vertex.attributes(g)# list.edge.attributes(g)V(g)$name###[1] \"Alice\" \"Bob\" \"Cecil\" \"David\" \"Esmeralda\"edge_attr(g)$same.dept###[1] FALSE FALSE TRUE FALSE FALSE TRUEedge_attr(g)$friendship###[1] 4 5 5 2 1 1 可视化如下： ## A simple example with a couple of actors## The typical case is that these tables are read in from files....actors &lt;- data.frame(name=c(\"Alice\", \"Bob\", \"Cecil\", \"David\", \"Esmeralda\"), age=c(48,33,45,34,21), gender=c(\"F\",\"M\",\"F\",\"M\",\"F\"))relations &lt;- data.frame(from=c(\"Bob\", \"Cecil\", \"Cecil\", \"David\", \"David\", \"Esmeralda\"), to=c(\"Alice\", \"Bob\", \"Alice\", \"Alice\", \"Bob\", \"Alice\"), same.dept=c(FALSE,FALSE,TRUE,FALSE,FALSE,TRUE), friendship=c(4,5,5,2,1,1), advice=c(4,5,5,4,2,3))g &lt;- graph_from_data_frame(relations, directed=TRUE, vertices=actors)V(g)$gender &lt;- plyr::revalue(x=V(g)$gender, replace=c(\"F\"=\"Female\",\"M\"=\"Male\"))V(g)$gender ## [1] \"Female\" \"Male\" \"Female\" \"Male\" \"Female\" g$name &lt;- \"Toy Graph\"set.seed(42)tmp.df &lt;- layout.graphopt(g)V(g)$color &lt;- plyr::revalue(x=V(g)$gender, replace=c(\"Female\"=\"skyblue\", \"Male\"=\"coral\"))plot(g,layout=tmp.df,vertex.size=20, vertex.color=V(g)$color,main=\"Toy Graph\")legend('right',legend=unique(V(g)$gender),pch=c(19,19),col = c(\"skyblue\",\"coral\")) set.seed(42)tmp.df &lt;- layout.graphopt(g)gg.net = ggnetwork(g, arrow.gap = 0.05, layout = tmp.df)ggplot(gg.net, aes(x = x, y = y, xend = xend, yend = yend)) + geom_edges(color = \"black\", alpha = 0.5, curvature = 0, arrow = arrow(length = unit(6, \"pt\"), type = \"closed\")) + geom_nodes(aes(color = gender), size = 10) + geom_nodetext(aes(label = name))+ scale_color_manual(values = c(\"skyblue\",\"coral\"))+ ggtitle(\"Toy Graph\")+ theme_blank() 4. 更多关于图的概念和术语 4.1 概念 下述概念不搬运书里的定义；忘记就查书。后面的章节会再用到这些概念，进行图的可视化与统计分析。 multi-graph simple-graph: 可以用is.simple()判定，可以用simplify()将multi-graph转换为simple-graph. neighbors degree: The degree of a vertex v defined as the number of edges incident on v; in-degree out-degree walk trails circuit &amp; cylce; reachable graph connected component of a graph strong connected weak connected distance/geodesic distance diameter 4.2 一些特殊的图 与第一节有重叠 complet graph clique regular graph tree forest root ancestor descendant parents, children k-star dirrected acyclic graph(DAG) bipartite graph g.bip &lt;- graph.formula(actor1:actor2:actor3, movie1:movie2, actor1:actor2 - movie1, actor2:actor3 - movie2)V(graph = g.bip)$type &lt;- grepl(pattern = \"^movie\",V(graph = g.bip)$name)V(g.bip)$category &lt;- ifelse(V(graph = g.bip)$type,\"Movie\",\"Actor\")V(g.bip)$category ## [1] \"Actor\" \"Actor\" \"Actor\" \"Movie\" \"Movie\" g &lt;- g.bipset.seed(42)### using matrxi product to do layout rotate 3/2pitmp.df &lt;- layout.bipartite(g) %*% matrix(data = c(0,-1,1,0),nrow = 2)gg.net = ggnetwork(g, arrow.gap = 0.05, layout = tmp.df)head(gg.net) ## x y name type category xend yend ## 1 0 0.0 actor1 FALSE Actor 0.9514929 0.2378732 ## 2 0 0.5 actor2 FALSE Actor 0.9514929 0.2621268 ## 3 0 0.5 actor2 FALSE Actor 0.9514929 0.7378732 ## 4 0 1.0 actor3 FALSE Actor 0.9514929 0.7621268 ## 5 0 0.0 actor1 FALSE Actor 0.0000000 0.0000000 ## 6 0 0.5 actor2 FALSE Actor 0.0000000 0.5000000 ggplot(gg.net, aes(x = x, y = y, xend = xend, yend = yend)) + geom_edges(color = \"black\", alpha = 0.5, curvature = 0 # ,arrow = arrow(length = unit(6, \"pt\"), # type = \"closed\") ) + geom_nodes(aes(color = category), size = 16) + geom_nodetext(aes(label = name))+ scale_color_manual(values = c(\"skyblue\",\"coral\"))+ ggtitle(\"bipartite graph example\")+ theme_blank() igraph自带的例子： # Random bipartite graphinc &lt;- matrix(sample(0:1, 50, replace = TRUE, prob=c(2,1)), 10, 5)g &lt;- graph_from_incidence_matrix(inc)plot(g, layout = layout_as_bipartite,vertex.size=20, vertex.color=c(\"skyblue\",\"coral\")[V(g)$type+1]) 附录：R配色 基本颜色： #### code provided by####http://bc.bojanorama.pl/2013/04/r-color-reference-sheet/m &lt;- matrix(1:660, 60, 11)kol &lt;- colors()[m]#op &lt;- par(mar=c(.1, .1, 2, .1))image(1:11, 1:60, t(m), col=kol, axes=FALSE, ann=FALSE)txtcol &lt;- ifelse( apply(col2rgb(kol), 2, mean) &lt; 70, \"white\", \"black\")text( as.numeric(col(m)), as.numeric(row(m)), kol, cex=.8, col=txtcol)mtext(\"grDevices::colors\", 3, cex=2) 调色版 RColorBrewer::display.brewer.all()mtext(\"RColorBrewer\", 3, cex=2) 渐变色 library(RColorBrewer)library(colorRamps)library(viridis)### manurdylbu &lt;- colorRampPalette(rev(brewer.pal(n = 11, name =\"RdYlBu\")))rdbu &lt;- colorRampPalette(rev(brewer.pal(n = 11, name =\"RdBu\")))navy &lt;- colorRampPalette(c(\"navy\", \"white\", \"firebrick3\"))jet.colors &lt;- colorRampPalette(c(\"#00007F\", \"blue\", \"#007FFF\", \"cyan\", \"#7FFF7F\", \"yellow\", \"#FF7F00\", \"red\", \"#7F0000\"))cold &lt;- colorRampPalette(c('#f7fcf0','#41b6c4','#253494','#081d58','#081d58'))warm &lt;- colorRampPalette(c('#ffffb2','#fecc5c','#e31a1c','#800026','#800026'))warmcold &lt;- colorRampPalette(c(rev(cold(21)), warm(20)))### add manu with package functionN &lt;- 100 # ramp lengthfunnames &lt;- rev(c(\"manu::rdylbu\",\"manu::rdbu\",\"manu::navy\",\"manu::jet.colors\",\"manu::warmcold\", \"viridis::viridis\", \"grDevices::rainbow\", \"grDevices::heat.colors\", \"grDevices::terrain.colors\", \"grDevices::topo.colors\", \"grDevices::cm.colors\", \"colorRamps::blue2red\", \"colorRamps::blue2green\", \"colorRamps::green2red\", \"colorRamps::blue2yellow\", \"colorRamps::cyan2yellow\", \"colorRamps::magenta2green\", \"colorRamps::matlab.like\", \"colorRamps::matlab.like2\", \"colorRamps::primary.colors\", \"colorRamps::ygobb\"))spl &lt;- strsplit(funnames, \"::\")pkgs &lt;- sapply(spl, \"[\", 1)funs &lt;- sapply(spl, \"[\", 2)kolmat &lt;- sapply(funs, do.call, list(N))mat &lt;- matrix( seq(1, length(kolmat)), nrow(kolmat), ncol(kolmat))image(seq(1, nrow(mat)), seq(1, ncol(mat)), mat, col=kolmat, axes=FALSE, ann=FALSE)text( nrow(mat)/2, seq(1, ncol(mat)), funnames)mtext(\"Color Ramps function\", 3, cex=2)","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"Graph","slug":"Graph","permalink":"https://landau1994.github.io/tags/Graph/"},{"name":"Network","slug":"Network","permalink":"https://landau1994.github.io/tags/Network/"}],"author":"Landau1994"},{"title":"Combine pheatmap","slug":"combine_pheatmap","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.832Z","comments":true,"path":"2020/04/20/combine_pheatmap/","permalink":"https://landau1994.github.io/2020/04/20/combine_pheatmap/","excerpt":"","text":"Talk is cheap, this is code: library(grid)library(gridExtra)library(pheatmap)library(ggplot2)library(colormap)items=names(colormaps)plot_list=list()for (a in items[1:8]){ x= pheatmap(volcano, cluster_rows = F, cluster_cols = F, main = a, height = 3, width = 3, border_color = NA, color = colormap_pal(colormap = colormaps[[a]])(100),silent = T) plot_list[[a]] = x[[4]] ##to save each plot into a list. note the [[4]]}cowplot::plot_grid(plotlist = plot_list[1:8],ncol = 2,nrow = 4) test equation: E = mc2; P(AB) = P(A)P(B)","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"}],"author":null},{"title":"pheatmap_advanced","slug":"pheatmap_advanced","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.842Z","comments":true,"path":"2020/04/20/pheatmap_advanced/","permalink":"https://landau1994.github.io/2020/04/20/pheatmap_advanced/","excerpt":"","text":"Case 1 The datasets were provided by data-to-viz library(tidyverse)library(pheatmap)library(ggplot2)library(viridis)library(kableExtra)### dataset 1data &lt;- read.table(\"https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/13_AdjacencyDirectedWeighted.csv\", header=TRUE)# show datadata %&gt;% head(3) %&gt;% select(1:3) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = \"striped\", full_width = F) Africa East.Asia Europe Africa 3.142471 0.000000 2.107883 East Asia 0.000000 1.630997 0.601265 Europe 0.000000 0.000000 2.401476 ### the following function were embeded in pheatmap source codescale_rows = function(x){ m = apply(x, 1, mean, na.rm = T) s = apply(x, 1, sd, na.rm = T) return((x - m) / s)}scale_mat = function(mat, scale){ if(!(scale %in% c(\"none\", \"row\", \"column\"))){ stop(\"scale argument shoud take values: 'none', 'row' or 'column'\") } mat = switch(scale, none = mat, row = scale_rows(mat), column = t(scale_rows(t(mat)))) return(mat)}generate_breaks = function(x, n, center = F){ if(center){ m = max(abs(c(min(x, na.rm = T), max(x, na.rm = T)))) res = seq(-m, m, length.out = n + 1) } else{ res = seq(min(x, na.rm = T), max(x, na.rm = T), length.out = n + 1) } return(res)}data.plot &lt;- scale_mat(mat = data,scale = \"column\")breaks &lt;- generate_breaks(data.plot,n = 256,center = F)pheatmap::pheatmap(mat = data.plot, cluster_cols = F, cluster_rows = F, scale = \"column\",border_color = \"white\", color = viridis(n = 256, alpha = 1, begin = 0, end = 1, option = \"viridis\"), breaks = breaks) case 2 the codes were adapted from slowkow Sort dendrogram is very important set.seed(42)random_string &lt;- function(n) { substr(paste(sample(letters), collapse = \"\"), 1, n)}mat &lt;- matrix(rgamma(1000, shape = 1) * 5, ncol = 50)colnames(mat) &lt;- paste( rep(1:3, each = ncol(mat) / 3), replicate(ncol(mat), random_string(5)), sep = \"\")rownames(mat) &lt;- replicate(nrow(mat), random_string(3))mat %&gt;% as.data.frame %&gt;% head(3) %&gt;% select(1:3) %&gt;% kable() %&gt;% kable_styling(bootstrap_options = \"striped\", full_width = F) 1jrqxa 1pskvw 1ojvwz abv 9.6964789 9.172811 2.827695 nft 0.9020955 15.575853 4.328376 xha 2.6721643 3.127039 1.765077 split data into 3 groups, and increase the values in group1 col_groups &lt;- substr(colnames(mat), 1, 1)mat[,col_groups == \"1\"] &lt;- mat[,col_groups == \"1\"] * 5 making the heatmap # install.packages(\"pheatmap\", \"RColorBrewer\", \"viridis\")library(pheatmap)library(RColorBrewer)library(viridis)# Data frame with column annotations.mat_col &lt;- data.frame(group = col_groups)rownames(mat_col) &lt;- colnames(mat)# List with colors for each annotation.mat_colors &lt;- list(group = brewer.pal(3, \"Set1\"))names(mat_colors$group) &lt;- unique(col_groups)pheatmap( mat = mat, color = inferno(10), border_color = NA, show_colnames = FALSE, show_rownames = FALSE, annotation_col = mat_col, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 14, main = \"Default Heatmap\") The default color breaks in pheatmap are uniformly distributed across the range of the data. We can see that values in group 1 are larger than values in groups 2 and 3. However, we can’t distinguish different values within groups 2 and 3. ## ----uniform-color-breaks------------------------------------------------mat_breaks &lt;- seq(min(mat), max(mat), length.out = 10)dat &lt;- data.frame(values = as.numeric(mat))## ----uniform-color-breaks-detail, fig.height=2, echo=FALSE---------------dat_colors &lt;- data.frame( xmin = mat_breaks[1:(length(mat_breaks)-1)], xmax = mat_breaks[2:length(mat_breaks)], ymin = 0, ymax = max(density(mat, bw = \"SJ\")$y), fill = rev(inferno(length(mat_breaks) - 1)), stringsAsFactors = FALSE)ggplot() + geom_rect( data = dat_colors, mapping = aes( xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill ) ) + geom_density( data = dat, mapping = aes(values), bw = \"SJ\", color = \"cyan\" ) + scale_fill_manual(values = dat_colors$fill) + cowplot::theme_cowplot()+ theme(legend.position = \"none\") + labs(title = \"Uniform breaks\") there are 6 data points greater than or equal to 100 are represented with 4 different colors. dat2 &lt;- as.data.frame(table(cut( mat, mat_breaks)))dat2$fill &lt;- inferno(nrow(dat2))ggplot() + geom_bar( data = dat2, mapping = aes(x = Var1, weight = Freq, fill = Var1), color = \"black\", size = 0.1 ) + coord_flip() + scale_fill_manual(values = dat2$fill) + cowplot::theme_cowplot()+ theme(legend.position = \"none\") + labs(y = \"data points\", x = \"breaks\", title = \"Number of data points per color\") If we reposition the breaks at the quantiles of the data, then each color will represent an equal proportion of the data: quantile_breaks &lt;- function(xs, n = 10) { breaks &lt;- quantile(xs, probs = seq(0, 1, length.out = n)) breaks[!duplicated(breaks)]}mat_breaks &lt;- quantile_breaks(mat, n = 11) lets see dat_colors &lt;- data.frame( xmin = mat_breaks[1:(length(mat_breaks)-1)], xmax = mat_breaks[2:length(mat_breaks)], ymin = 0, ymax = max(density(mat, bw = \"SJ\")$y), fill = rev(inferno(length(mat_breaks) - 1)), stringsAsFactors = FALSE)ggplot() + geom_rect( data = dat_colors, mapping = aes( xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill ) ) + geom_density( data = dat, mapping = aes(values), bw = \"SJ\", color = \"cyan\" ) + scale_fill_manual(values = dat_colors$fill) + theme(legend.position = \"none\") + labs(title = \"Quantile breaks\") dat2 &lt;- as.data.frame(table(cut( mat, mat_breaks)))dat2$fill &lt;- inferno(nrow(dat2))ggplot() + geom_bar( data = dat2, mapping = aes(x = Var1, weight = Freq, fill = Var1), color = \"black\", size = 0.1 ) + coord_flip() + scale_fill_manual(values = dat2$fill) + theme(legend.position = \"none\") + labs(y = \"data points\", x = \"breaks\", title = \"Number of data points per color\") When we use quantile breaks in the heatmap, we can clearly see that group 1 values are much larger than values in groups 2 and 3, and we can also distinguish different values within groups 2 and 3: pheatmap( mat = mat, color = inferno(length(mat_breaks) - 1), breaks = mat_breaks, border_color = NA, show_colnames = FALSE, show_rownames = FALSE, annotation_col = mat_col, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 14, main = \"Quantile Color Scale\") We can also transform data pheatmap( mat = log10(mat), color = inferno(10), border_color = NA, show_colnames = FALSE, show_rownames = FALSE, annotation_col = mat_col, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 14, main = \"Log10 Transformed Values\") sort dendrograms library(dendsort)mat_cluster_cols &lt;- hclust(dist(t(mat)))sort_hclust &lt;- function(...) as.hclust(dendsort(as.dendrogram(...)))mat_cluster_cols &lt;- sort_hclust(mat_cluster_cols)plot(mat_cluster_cols, main = \"Sorted Dendrogram\", xlab = \"\", sub = \"\") sort Dendrogram heatmap mat_cluster_rows &lt;- sort_hclust(hclust(dist(mat)))pheatmap( mat = mat, color = inferno(length(mat_breaks) - 1), breaks = mat_breaks, border_color = NA, cluster_cols = mat_cluster_cols, cluster_rows = mat_cluster_rows, show_colnames = FALSE, show_rownames = FALSE, annotation_col = mat_col, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 14, main = \"Sorted Dendrograms\") change colnames angle pheatmap( mat = mat, color = inferno(length(mat_breaks) - 1), breaks = mat_breaks, border_color = NA, cluster_cols = mat_cluster_cols, cluster_rows = mat_cluster_rows, show_colnames = TRUE, show_rownames = FALSE, annotation_col = mat_col, angle_col = 90, fontsize_col = 8, annotation_colors = mat_colors, drop_levels = TRUE, fontsize = 10, main = \"Sorted Dendrograms\")","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"}],"author":null},{"title":"rmarkdown-test","slug":"rmarkdown-test","date":"2020-04-19T16:00:00.000Z","updated":"2025-01-11T17:16:31.862Z","comments":true,"path":"2020/04/20/rmarkdown-test/","permalink":"https://landau1994.github.io/2020/04/20/rmarkdown-test/","excerpt":"","text":"This post test blogdown, reference this repo This post generate by blogdown::new_post(title = “Rmarkdown_test”,ext=“.Rmd”) R Markdown This is an R Markdown document. Please note this page was not rendered using the rmarkdown package or Pandoc. The R Markdown document is compiled to Markdown through knitr, and the Markdown document is rendered to HTML through Hexo’s Markdown renderer. You can embed an R code chunk like this: summary(cars)## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00fit &lt;- lm(dist ~ speed, data = cars)fit## ## Call:## lm(formula = dist ~ speed, data = cars)## ## Coefficients:## (Intercept) speed ## -17.579 3.932 Including Plots You can also embed R plots: par(mar = c(0, 1, 0, 1))pie( c(280, 60, 20), c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'), col = c('#0292D8', '#F7EA39', '#C4B632'), init.angle = -50, border = NA)","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"}],"author":null},{"title":"阿里数学竞赛预赛2020年的一道概率题学习","slug":"阿里数学竞赛预赛2020年的一道概率题学习","date":"2020-04-18T07:41:15.000Z","updated":"2025-01-11T17:16:31.883Z","comments":true,"path":"2020/04/18/阿里数学竞赛预赛2020年的一道概率题学习/","permalink":"https://landau1994.github.io/2020/04/18/%E9%98%BF%E9%87%8C%E6%95%B0%E5%AD%A6%E7%AB%9E%E8%B5%9B%E9%A2%84%E8%B5%9B2020%E5%B9%B4%E7%9A%84%E4%B8%80%E9%81%93%E6%A6%82%E7%8E%87%E9%A2%98%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"阿里巴巴全球数学竞赛是阿里办的一项数学竞赛。出题范围和往届预选赛题目可以在其官网下查看 。 2020年的预选赛，有道题目是这样的： 考虑一个由从左道右的n个小方格组成的1 × n的区域，从左到右依次在每个小方格种一棵树，一共种n棵。树的种类只有两种：胡杨和樟子松。假设在第一个小方格种植的数是胡杨的概率是r。后续的种树的规则为：如果前一个小方格种的是胡杨，则本格种胡杨的概率为s;如果前一个小方格种的是樟子松，则本格种樟子松的概率为t, 0 &lt; r, s, t &lt; 1 假设r = 1/3, s + t ≠ 1。是否存在s, t使得∀i, 2 ≤ i ≤ n,在第i个小方格种植的树是胡杨的概率都等于一个跟i无关的常数？如果存在，请给出s，t满足的关系；如果不存在，请说明理由。 假设。假设我们观察到第2019个小方格里种植的树是胡杨，但我们观察不到其它小方格里种植的是哪种树。请问第一个小方格里种植的树是胡杨的概率是多少？ 这道题考察的其实是马尔科夫链相关的知识，第一问是说什么条件下，题目给定的马尔可夫链在第二步就能达到平稳分布；第二问是从第n步逆推最起始的概率。当然，直接的工具是条件概率和全概率公式。 解答（根据官方答案，有改动）： 首先，我们需要将文字信息转换为便于处理的数学记号，记“E”表示胡杨，“S” 表示樟子松。令Xk表示种在第k个方格的树的种类(根据题意，这是一个随机变量)，令pk = P(Xk = E),则由题设，有： 且由全概率公式 令k = 2, 我们有： 若∀k ≥ 2, pk = p2成立，则, 整理可得 (s − 2t + 1)(s + t − 1) = 0 因为s + t ≠ 1，所以当s − 2t + 1 = 0时，∀k ≥ 2, pk = p2 题目给的r, s, t不满足(a)中的条件，所以我们需要求出一般条件下的情况。 令qk = P(Xk = E|X1 = E),则需要求的概率是： (a)中已经求出了pk得递推式, 仿照(a)的步骤，我们可以求出 解上述递推式，可得： 类似的，由(2)可得 所以有： 将给入条件带入(其实不用计算，因为n = 2019, qn ≈ pn），可得P(X1 = E|Xn = E) ≈ r = 1/3","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"},{"name":"Probability","slug":"Probability","permalink":"https://landau1994.github.io/tags/Probability/"}],"author":"夏目沉吟"},{"title":"机器学习在生物学有应用吗","slug":"机器学习在生物学有应用吗","date":"2020-04-15T16:00:00.000Z","updated":"2025-01-12T00:46:51.065Z","comments":true,"path":"2020/04/16/机器学习在生物学有应用吗/","permalink":"https://landau1994.github.io/2020/04/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9C%A8%E7%94%9F%E7%89%A9%E5%AD%A6%E6%9C%89%E5%BA%94%E7%94%A8%E5%90%97/","excerpt":"","text":"说明：转自站长知乎回答。 当然有应用，而且是很广泛的应用，周志华老师的《机器学习》中的第1章的绪论的1.6节应用现状中这样写到： 机器学习还为许多交叉学科提供了重要的技术支撑。例如，“生物信息学”试图利用信息技术来研究生命现象和规律，而基因组计划的实施和基因药物的美好前景让人们为之心潮澎湃。生物信息学研究涉及从“生命现象”到“规律发现”的整个过程，其间必然包括数据获取、数据管理、数据分析、仿真实验等环节，而“数据分析”恰是机器学习技术的舞台，各种机器学习技术已经在这个舞台上大放异彩。 在本回答中，我们将结合具体的案例，分三部分论述机器学习（包含深度学习）在生物研究的应用。第一部分，我们先对机器学习在生命科学领域的研究做一个全景的介绍。第二部分，我们再结合具体案例如何应用机器学习推动相关生物研究，以及相关生物研究中出现的问题如何催生新的机器学习算法。第三部分我们将进行回顾和反思，探讨未来的机器学习将如何更好的推动生物研究。 在正式讨论之前，我们借用周志华老师的《机器学习》一书来对机器学习下一个描述性的定义： 机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经 验来玫善系统自身的性能在计算机系统中，“经验”通常以“数据”形式存 在，因此机器学习所研究的主要内容，是关于在计算机上从数据中产生“模 型” (model) 的算法，即“学习算法” (learning algorithm). 有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型;在面对新的情况时(例如看到一个没剖开的西瓜)，模型会给我们提供相应的判断(例如好瓜) .如果说 计算机科学是研究关于“算法”的学问，那么类似的，可以说机器学习是研究 关于“学习算法”的学问. 在下面的论述中，我们将从概况以及具体的生物场景看到这个定义还是很合理的。 本回答假定读者已经了解过一些机器学习和生物的概念。 一. 机器学习在生物研究中的应用概览 1. 基本流程 一般来说，在生物研究中，一项应用机器学习中的算法的研究可以分为如下五步流程： 1. 设计实验，收集数据 2. 数据清洗 3. 特征选择 4. 模型构建 5. 模型评估 如下面的流程图，来自Deep learning for computational biology所示 2. 有监督学习与无监督学习 模型构建的方法，按照研究的问题可以分为，有监督和无监督的。 有监督学习是指一类针对有标签的数据来预测无标签数据的标签的算法，如果我们把连续数值变量也视为标签的话，那么回归也是有监督学习。而无监督学习是指一类针对无标签的数据进行规律发现的算法。除此之外，也有半监督学习，即在 一个典型的有监督的问题是分类问题，一个典型的无监督问题是聚类问题。在这个回答我们将介绍这两类问题的具体的场景。下图来自综述Deep learning for computational biology 3. 三类基本数据 大多数生物研究主要对序列数据，矩阵或者张量数据，成像数据这三类基本的数据上进行机器学习算法的应用。 3.1 序列数据 最基本的生物数据之一，通常为DNA序列，RNA序列，蛋白质序列。 在人类基因组计划早期的问题是，如何快速进行基因组注释，该问题可以表示如下,图片来自Machine learning applications in genetics and genomics： 基因组注释是一个有监督或者半监督的问题，因为一段序列是不是基因可以通过EST(表达序列标签)来判定，其他特征可以通过一些生化或者分子实验来标定，所以我们可以得到数据标签。 此外，序列数据更为常见的是要分析一些分子演化的问题，例如最近大家关注的新冠病毒的分子演化。这方面的案例和相关讨论可见：剑桥大学研究称新冠病毒分三个变种，A 类病毒为「爆发根源」，更多发现于美国和澳洲，这一结论靠谱吗？ 这是一个无监督的问题，例如，我们其实并不知道新冠病毒可以分为几个变种，我们需要在数据中看出它能分成几类，然后再通过其他证据证明这种分类是合理的。 3.2 矩阵数据 芯片技术和后续的高通量测序技术带来了很多种矩阵数据,这类矩阵通常是对某类型生物特征（基因，蛋白，表观修饰，染色质互作）的丰度汇总而成的。最典型矩阵数据是基因表达谱，基因表达谱矩阵可以通过RNA-seq数据进行比对后的转录本定量产生，基本流程和常见分析策略如下（图片来自Enter the Matrix: Factorization Uncovers Knowledge from Omics)： 这类数据的分析通常是无监督或者半监督的，我们通常想通过矩阵数据去发现一些可用于诊断的分子marker。 3.3 成像数据 从数据存储的本质上讲，成像数据还是矩阵数据（不过考虑到多通道图像的存在，称为张量数据更为贴切），但是内涵上是不同的，成像数据表达更多的是生物体内部空间位置（还有形状或者结构）的信息。例如，一张蛋白亚细胞定位的图像，可以反映某标记的感兴趣的蛋白质位于细胞中的什么位置，如果我们有很多这样的图片，明智的方法是先标记一部分数据，训练一个卷积神经网络，然后再对剩下的图片进行预测，如下图所示，： 图片来自综述2 4. 关于深度学习及其在生物研究中的应用 深度学习到底是什么呢，按照Yann LeCun, Yoshua Bengio，Geoffrey Hinton三位专家合写的综述的定义： &gt; Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. With the composition of enough such transformations, very complex functions can be learned For. 拙译为：深度学习方法是一种基于多种层级进行表示的表示学习方法。其表示能力是通过组合简单的非线性的模块实现的。每一个小模块都可以把第一层的原始数据转换为更稍微抽像的特征。通过足够多的这样的转换进行组合，可以学习到非常复杂的函数(功能)。 目前，在基因组学的不同层级，均有深度学习的应用案例： 图片来自A primer on deep learning in genomics,想了解更多，请阅读这篇文章。 5. 常见不同机器算法的实现软件 针对不同的学习算法，在R中的可用的机器学习包如下，图片来自Machine learning for Big Data analytics in plants: python上的常用相关软件包如下.图片来自Best Python Libraries for Machine Learning and Deep Learning： Best Python Libraries for Machine Learning and Deep Learning 二. 机器学习在生物研究中的应用案例 1. 基于机器学习的差异表达网络分析 生物学家很感兴趣的一个问题是，不同条件下哪些基因表达会发生变化，这样他们可以深入研究其中的分子机制，进而找到一些可以找到一些增强或者减弱他们想要研究表型的靶点。 常见的思路是做假定基因表达服从一个分布，然后根据这个假设构建统计量，计算统计显著性，设置cutoff来筛选发生差异表达的基因。 但是这样做可能存在问题，例如cutoff为 p &lt; 0.05,那些被判定为统计不显著的基因就真的和表型相关的差异表达基因吗？有无更好的替代方法？ 文献Machine Learning–Based Differential Network Analysis: A Study of Stress-Responsive Transcriptomes in Arabidopsis提供了一种思路。假定我们对于模式植物拟南芥响应各种胁迫条件感兴趣，我们可以用基于机器学习的策略对于之前的差异表达方法做出改进，分为如下步骤： 1）数据收集，清洗以及正负样本构建： 收集不同胁迫条件下的基因表达谱(基因芯片数据），进行预处理和标准化，收集之前报导过的和相关的基因作为正样本，将表达谱中不发生变化的基因作为负样本，剩下的基因的表达谱作为无标签样本； 2）特征提取： 通过共表达网络的策略从表达谱中提取特征。在构建共表达网络的之后，采用随机森林的方法把未标签的样本中的“noninformative” genes（不表达，持续表达，与胁迫无关的基因)过滤掉了，减少了共表达网络构建的无用信息。计算每个基因在共表达网络中的PageRank等统计量，作为特征； 3）模型构建： 根据2）中计算的特征，从分好的正负样本中，再次随机森林构建模型； 4）模型评估 和limma等方法比较； 5）模型预测，并进行验证 将训练好的模型应用于无标记的基因上，预测出和新的胁迫相关的基因，并通过TDNA插入实验验证。 上述步骤可以概括如下， 图片来自Machine learning for Big Data analytics in plants 2. 干细胞分化路径重构与流形学习 案例1是有监督学习的例子，我们接下来看无监督学习的案例。 生物学有一个很著名的模型叫做waddington landscape，该模型描述了干细胞在分化过程可以类比于一个有质量的小球自发沿着山坡从山顶滚下山谷的过程，不同的山底表示了细胞的终末分化状态，而不同的分支点的存在则是细胞命运决定的节点。这个运动的过程中，细胞的基因表达会发生变化，如果我们假定基因表达“相近”的细胞在路径上也挨得很近，那么在基因表达的高维数据中应该嵌入了低维的分化路径，则我们能通过流形学习的技术从基因表达数据中重构出分化的路径，如下图所示， 图片来自Manifold learning-based methods for analyzing single-cell RNA-sequencing data 具体来说，流形学习是如何进行的呢？可以结合如下的案例进行理解。现在有两个变量组成的一个数据集，我们将其画在直角坐标系中，可以看出样本点中存在一个螺旋的趋势，也就是说这个二维数据集中似乎嵌入了一个一维流形。如何通过计算的方式将其找出来呢。直觉告诉我们，必须先计算每两个样本点之间距离。我们在样本点之间的距离之后呢，会发现这个距离里样本点的局部邻近关系和整体邻近关系混淆在了一起，这个时候，我们可以使用叫做核函数的技巧，将距离转换为邻近关系。得到局部的距离之后呢，我们把相邻的点连起来，这样便可以最终得到那个样本点中包含的螺旋的一维流形了。 图片来自Manifold learning-based methods for analyzing single-cell RNA-sequencing data 附注：粗浅的来说，所谓流形就是一个局部看起来像是欧几里得空间的拓扑空间。每个属于这个n维流形的点的邻域都可以与一个n维欧氏空间建立一一映射的关系。（更为严谨的定义请看拓扑学教材）。流形学习一般是用来学习高维数据内部的低维结构。最基础流形学习算法是PCA。 以最近发表的一种同时实现生物高维数据可视化和路径推断的算法PHATE为例，该算法的流程如下，（图片来自原文献）： 该算法的基本流程和其他的流形学习方法大致类似，但是他们的创新之处是引入了随机游走，计算扩散概率，以及最终讲欧式距离转化为信息距离来进行embeding。 篇幅所限，我们不会在这里谈很多该算法的计算细节，感兴趣的读者可看知乎上中文的介绍：Nat. Biotechnol | PHATE：高维生物数据的可视化方法，或者直接阅读原始文献。 3.冷冻电镜中的图像处理 这部分，笔者不是专家，只是为了拓展视野在里记录。 基础知识推荐大家看下coursera上面的加州理工的冷冻电镜的课程，尤其是Tomography那一节。 关于冷冻电镜的背景大家请看 为什么冷冻电镜 (Cryo-EM) 去年突然火了？是有什么技术突破吗？ 以及什么是2015年最受科学界关注的新技术？ 当然还有nature的新闻稿 根据nature这篇新闻稿，冷冻电镜取得突破性进展主要要归功于两个人：Richard Henderson和Sjors Scheres还有他们所在的实验室：UK Medical Research Council Laboratory of Molecular Biology (LMB)。Richard Henderson和他的同事 Nigel Unwin 在1975年的一片文章（Molecular structure determination by electron microscopy of unstained crystalline specimens）中为冷冻电镜技术做出了奠基性的贡献。而新发展的直接电子探测器使得对大分子的高速动态成像成为可能。新技术带来的大数据使得Sjors Scheres有了在方法学和软件上的突破。 那么，冷冻电镜带来的结构生物学的革命是如何实现的？答案是借用到机器学习的思想与方法的，如下面这张图所示： （来自How cryo-EM is revolutionizing structural biology) 第一步，将要解析的蛋白分离纯化制样之后，用高速动态成像的记录蛋白的各种构象; 第二步，处理图像数据，把取向相同的小颗粒re-align，借用贝叶斯的思想；从而将粗颗粒的模型精细化; 第三步，如果是混样的情况，也可以利用分类或者聚类的方法，将混样中存在的不同结构的蛋白构像解析出来。 第二步的基于贝叶斯的re-align和精细化可以概括如下： （图片来自A Bayesian View on Cryo-EM Structure Determination） 策略为通过傅里叶变换的方法用计算机重构出粗略的结构模型然后把这个粗略的结构模型与成千上万的成像数据比对，得到每个图像之间的相对位置。通过作者改进的机器学习中常用的贝叶斯方法，将粗略的结构模型调整为新的一个更精确的结构，如此迭代以精炼我们的模型，文章提到对于核糖体的结构的解析他们迭代了25次。这整个的过程就是所谓的取“平均”了，不过是基于机器学习的方法，结合先验的知识来取得“平均”和进行光滑，取得精细结构。 这部分不是很懂，写的不好，欢迎成像和图像处理方面的专家指正。 三. 回顾反思 在上述论述中，我们介绍的机器学习在生物研究应用案例都只在问这样一类型问题：”某一生物现象是什么？“，不过对于人类社会发展而言更有直接意义的问题是，”认识这一生物现象可能的模式之后我们该怎么办“，问这类问题的人一般都是医生或者药企的科学家。当然，目前也有这方面的成熟流程可以参考: （图片来自Applications of machine learning in drug discovery and development 最近也有科学家用深度学习的方法，发现了新的抗生素： 感兴趣的读者可以看这篇文献。 此外，个人理解，机器学习就是一种智能的数据挖掘技术，它依据先验的知识建立预测模型来识别大数据中的有用信息。所以只要有大数据和前期积累的先验知识，就有机器学习方法用武之地。 说几句与题目无关的话，个人感觉其实这个题目也可以回答学生物的人多学点基础的数学和物理知识有用吗？我觉得是有用的，比如你想搞清楚冷冻电镜成像的原理，你必须懂点物理知识（干涉衍射之类的）还得懂点数学物理方法（如傅里叶变换与它的逆）。当然想要进行机器学习，当然得有统计学和数据的可视化方法的数学基础和计算机编程基础（Python或者R）了。学科之间其实是可以互通有无的，然而这点常常被目光短浅的一些人忽略了，希望关注这个问题的人可以能多从这个角度来学习，思考问题，解决问题。 附：日志 2016.3 创建回答 2016.4.14 用周志华老师《机器学习》补充前言 2020.4.12 原回答因「违反知乎社区管理规定」被删除。 2020.4.13-15 按照知乎社区管理规定做出修订。重新提交。 2020.04.16 修改排版错误","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"machine learning","slug":"machine-learning","permalink":"https://landau1994.github.io/tags/machine-learning/"}],"author":"夏目沉吟"},{"title":"读关于增强子研究的现状与未来的一篇综述","slug":"读关于增强子研究的现状与未来的一篇综述","date":"2020-04-08T13:10:48.000Z","updated":"2025-01-11T17:16:31.880Z","comments":true,"path":"2020/04/08/读关于增强子研究的现状与未来的一篇综述/","permalink":"https://landau1994.github.io/2020/04/08/%E8%AF%BB%E5%85%B3%E4%BA%8E%E5%A2%9E%E5%BC%BA%E5%AD%90%E7%A0%94%E7%A9%B6%E7%9A%84%E7%8E%B0%E7%8A%B6%E4%B8%8E%E6%9C%AA%E6%9D%A5%E7%9A%84%E4%B8%80%E7%AF%87%E7%BB%BC%E8%BF%B0/","excerpt":"","text":"文章信息 题目：Towards a comprehensive catalogue of validated and target- linked human enhancers 内容 回顾了Enhancer biology的研究历史，概述了现有的研究技术，提出了target-linked的研究框架。 文章最有意思的一个总结图如下: 总结与评述： 像Enhancer biology这样的分子机制，带有很强的各方面的异质性，与其寻求一个comprehensive 的理解，不如做透彻在某一种非常重要的疾病，例如Cancer中的调控作用？Enhancer+single cell，细胞内部调控与细胞间调控的研究都很重要。 里面关于ENCODE的各种组学技术，以及3D genome的技术和CRISPR-screen的优缺点介绍很好。","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"sc-seq","slug":"sc-seq","permalink":"https://landau1994.github.io/tags/sc-seq/"},{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/tags/genomics/"},{"name":"genetics","slug":"genetics","permalink":"https://landau1994.github.io/tags/genetics/"},{"name":"ENCODE","slug":"ENCODE","permalink":"https://landau1994.github.io/tags/ENCODE/"},{"name":"HiC","slug":"HiC","permalink":"https://landau1994.github.io/tags/HiC/"},{"name":"ChIP-seq","slug":"ChIP-seq","permalink":"https://landau1994.github.io/tags/ChIP-seq/"},{"name":"ATAC-seq","slug":"ATAC-seq","permalink":"https://landau1994.github.io/tags/ATAC-seq/"}],"author":"夏目沉吟"},{"title":"关于肿瘤的免疫治疗靶点","slug":"关于肿瘤的免疫治疗靶点","date":"2020-04-08T12:58:13.000Z","updated":"2025-01-11T17:16:31.865Z","comments":true,"path":"2020/04/08/关于肿瘤的免疫治疗靶点/","permalink":"https://landau1994.github.io/2020/04/08/%E5%85%B3%E4%BA%8E%E8%82%BF%E7%98%A4%E7%9A%84%E5%85%8D%E7%96%AB%E6%B2%BB%E7%96%97%E9%9D%B6%E7%82%B9/","excerpt":"","text":"今天读到一个很清楚的综述的翻译笔记，讲肿瘤免疫治疗靶点的，读者可以移步到 生物信息学专业需要什么样的生物知识？阅读。 原文献里有张总结的图很不错： 可以作为本文的总结。","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"biology","slug":"biology","permalink":"https://landau1994.github.io/tags/biology/"},{"name":"immunology","slug":"immunology","permalink":"https://landau1994.github.io/tags/immunology/"}],"author":"夏目沉吟"},{"title":"quote_20200405","slug":"quote-20200405","date":"2020-04-05T13:52:53.000Z","updated":"2025-01-11T17:16:31.845Z","comments":true,"path":"2020/04/05/quote-20200405/","permalink":"https://landau1994.github.io/2020/04/05/quote-20200405/","excerpt":"","text":"时间就像一条河流， 在这我们顺流而下， 遇到现实， 需要决策， 但我们无法停留，也无法回避， 只能以最好的方式应付。——《原则》","categories":[{"name":"others","slug":"others","permalink":"https://landau1994.github.io/categories/others/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"}],"author":"夏目沉吟"},{"title":"cxt_Chap6_Cytokines","slug":"cxt-Chap6-Cytokines","date":"2020-04-05T13:44:02.000Z","updated":"2025-01-12T01:19:23.855Z","comments":true,"path":"2020/04/05/cxt-Chap6-Cytokines/","permalink":"https://landau1994.github.io/2020/04/05/cxt-Chap6-Cytokines/","excerpt":"","text":"如无特别说明，引用部分出自《医学免疫学》（第七版，曹雪涛主编，人卫社出版）第六章，细胞因子。 1. 细胞因子的定义 细胞因子是由免疫细胞及组织细胞分泌的在细胞间发挥相互调控作用的的一类小分子可溶性蛋白质，通过结合响应受体调节细胞生长分化和效应，调控免疫应答，在一定条件下也参与炎症等多种疾病的发生。 作用方式：自分泌方式，旁分泌方式，内分泌方式； 功能特点：多效性，重叠性，协同性，拮抗性； 2. 细胞因子的种类 根据结构和功能可以分为如下六大类： - 白细胞介素(interleukin, IL)，IL1-IL38。 - 集落刺激因子(colony-stimulating factor, CSF)，是指能够刺激多能造血干细胞和不同分化阶段的造血祖细胞分化和增殖的细胞因子。主要包括粒细胞-巨噬细胞集落刺激因子(GM-CSF), 巨噬细胞集落刺激因子（M-CSF)，红细胞生成素(EPO)，干细胞因子(SCF)和血小板生成素(TPO)等。分别诱导造血干细胞或祖细胞分化增殖为相应的细胞。 - 干扰素（interferon, IFN), 因具有干扰病毒复制的功能而得名。IFN根据其结构特征及生物学活性可分为I型、II型和III型。I型IFN主要包括IFN-α、IFN-β, 主要由病毒感染的细胞、pDC细胞等产生；II型IFN即IFN-γ，主要由活化T细胞和NK细胞产生。III型IFN包括IFN-λ1(IL-29)，IFN-λ2(IL-28A)和IFN-λ3(IL-28B)，主要由DC细胞产生。IFN具有抗病毒、抗细胞增殖、抗肿瘤和免疫调节等作用。 - 肿瘤坏死因子(tumor necrosis factor, TNF)家族。肿瘤坏死因子因最初被发现其能造成肿瘤组织坏死而得名，包括TNF-α和TNF-β，前者主要由活化的单核/巨噬细胞产生，后者主要由活化的T细胞产生，又称淋巴毒素(lymphotoxin, LT)。TNF家族目前已经发现TRAIL(TNF related apoptosis-inducing ligand)、FasL、CD40L等30余种细胞因子。TNF家族成员在调节免疫应答、杀伤靶细胞和诱导细胞凋亡等过程中发挥重要作用。 - 生长因子（growth factor，GF)泛指一类可促进相应细胞生长和分化的细胞因子。其种类较多，包括转化生长因子-β(transforming growth factor-β,TGF-β)、血管内皮细胞生长因子(VEGF)、表皮生长因子(EGF)、成纤维细胞生长因子(FGF)、神经生长因子(NGF)、血小板生长因子(PDGF)等。 - 趋化因子(chemokine) 是一类结构相似，分子量约8~12kD，具有趋化功能的细胞因子。几乎所有的趋化因子都含有由2对或一对保守的半胱氨酸残基(C)形成的分子内二硫化键。可以根据靠近氨基端的C的个数以及排列顺序将趋化因子分为四个家族：1）C亚家族：氨基酸端只有1个C，该分子内只有一个分子内二硫化键；2）CC亚家族：氨基端2个C相邻；3）CXC亚家族：氨基酸2个C被1个氨基酸残基隔开；4）CX3C亚家族：氨基端2个C被3个氨基酸残基隔开，羧基端跨细胞膜。 已经发现的趋化因子有，CXCL1 ~ 16，CCL1 ~ 28，XCL1 ~ 2，CX3CL1. 3. 细胞因子受体 细胞因子受体可以根据其结构特点被分为如下六个家族： - I型细胞因子受体家族，也称为血细胞生辰素受体家族(hematopoietin receptor family)， 通过 JAK-STAT通路转导信号； - II型细胞因子受体家族，也称为干扰素受体家族(interferon receptor family)，也是通过JAK-STAT通路转导信号； - 肿瘤坏死因子受体家族(tumor necrosis factor family)，主要通过TRAF-NF-kB，TRAF-AP-1 通路转导信号； - 免疫球蛋白超家族受体(Ig superfamily receptor, IgSFR)，会结合集落刺激因子； - IL-17受体家族(IL-17 receptor family)，主要通过TRAF-NF-kB通路转导信号； - 趋化因子受体家族(chemokine receptor family) ，属于GPCR中的一员。 4.remark 可否从基因表达调控出发，来描述细胞因子的功能？ 2025.01.12 comment 这些都是知识性的，或者字典里的内容，我觉得需要结合组学研究实践，才能变得有意义。","categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"biology","slug":"biology","permalink":"https://landau1994.github.io/tags/biology/"},{"name":"immunology","slug":"immunology","permalink":"https://landau1994.github.io/tags/immunology/"}],"author":"夏目沉吟"},{"title":"HCL papar","slug":"HCL-papar","date":"2020-04-05T13:32:40.000Z","updated":"2025-01-11T17:16:31.813Z","comments":true,"path":"2020/04/05/HCL-papar/","permalink":"https://landau1994.github.io/2020/04/05/HCL-papar/","excerpt":"","text":"题目：Construction of human cell landscape at single-cell level 科学问题：如何构建人类细胞图谱 实验：用其自己开发的Microwell-seq，该研究充分利用Microwell-seq成本低廉，双细胞污染率低和细胞普适性广等优势，建立了70多万个单细胞的转录组数据库，鉴定了人体100余种细胞大类和800余种细胞亚类。基于该数据库，团队开发了scHCL单细胞比对系统用于人体细胞类型的识别，并搭建了人类细胞蓝图网站http://bis.zju.edu.cn/HCL/（国家基因库镜像https://db.cngb.org/HCL/）。 分析：“tSNE+图聚类”（fig1b,fig1c,fig1d); EC,Epi, Stromal cell分泌Ligand的能力（Fig2c)主要是Adult的细胞（微环境？）；路径分析（Fig3)；调控分析（Fig4) 讨论：图谱式工作；证明了概念的可行性；但是不如HCA那么激动人心？","categories":[{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"},{"name":"biology","slug":"biology","permalink":"https://landau1994.github.io/tags/biology/"}],"author":"夏目沉吟"},{"title":"Dobrow-chap2","slug":"Dobrow-chap2","date":"2020-04-05T13:17:46.000Z","updated":"2025-01-11T17:16:31.801Z","comments":true,"path":"2020/04/05/Dobrow-chap2/","permalink":"https://landau1994.github.io/2020/04/05/Dobrow-chap2/","excerpt":"","text":"对于 Introduction to stochastic processes with R一书的笔记 Let us finish the article and the whole book with a good example of dependent trials, which approximately can be considered as a simple chain. –Andrei Andreyevich Markov Chap2: Markov Chains: First steps 本章讲马尔可夫链 Introduction 引入的案例： 这一节，用一个类似大富翁的游戏来引入马尔可夫夫性。 马尔可夫链的形式化定义为 &gt; Markov Chain &gt; Let 𝒮 be a discrete set. A Markov chain is a sequence of random variables X0, X1, … taking values in 𝒮 with the property that &gt; &gt; for all x0, …, xn − 1, i, j ∈ 𝒮, n ≥ 0 The set 𝒮 is the state space of the Markov chain. 、 Xn = i 称为在时刻n到达状态i。 时间齐性马尔可夫链： transition matrix: n步转移矩阵计算（矩阵乘法） 若干例子： 收敛于一个各行相等的矩阵； 不收敛，进入跳跃的状态； 收敛于一个各行不相等的矩阵 第五部分从直观上为下一章铺路。","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"}],"author":"夏目沉吟"},{"title":"Dobrow_chap1","slug":"Dobrow-chap1","date":"2020-04-04T11:41:57.000Z","updated":"2025-01-11T17:16:31.799Z","comments":true,"path":"2020/04/04/Dobrow-chap1/","permalink":"https://landau1994.github.io/2020/04/04/Dobrow-chap1/","excerpt":"","text":"This is a note of the textbook Introduction to stochastic processes with R We demand rigidly defined areas of doubt and uncertainty! –Douglas Adams, The Hitchhiker’s Guide to the Galaxy Introduction and preview We demand rigidly defined areas of doubt and uncertatinty –Douglas Adams, The Hitchhiker’s Guide to the Galaxy 1.1 DETERMINISTIC AND STOCHASTIC MODELS Consider a simple exponential growthmodel where the random arises？ The deterministic model does not address the uncertainty present in the reproduction rate of individual organisms. In many biological processes, the exponential distribution is a common choice for modeling the times of births and deaths. Ex1.1 PageRank: random walks on graphs Ex1.2 Spread of infectious disease SIR model: Susceptible-infected-removed Reed-Frost model: Stochastic SIR model in discrete time. 1.2 What is a stochastic process The author said &gt; A stochastic process, also called a random process, is simply one in which outcomes are uncertain. By contrast, in a deterministic system there is no randomness. In a deterministic system, the same output is always produced from a given input. A stochastic process is specified by its index and state sapce, and by the dependency relationships among its random variables &gt; Stochastic process: A stochastic process is a collection of random variables {Xt, t ∈ I}.The set I is the index set of the process. The random variables are defined on a commmon state space S. Ex 1.3 Monopoly EX 1.4 Discrete time, continous state space Ex 1.5 Continuous time, discrete state space arrival process, Poisson process Ex 1.6 Random walk and gambler’s ruin: Random walk, discrete-time stochastic process whose state space is ℤ Ex 1.7 Brownian motion: Brownian motion is a continuous-time, contiuous state space stochastic process 1.3 Monte Carlo Simulation Given a random experiment and event A, a Monte Carlo estimate of P(A) is obtained by repeating random experiment many times and taking the proportion of trials in which A occurs as an approximation for P(A) Strong law of large numbers 1.4 Conditional Probability The simplest stochastic process is a sequence of i.i.d. random variables. Such sequences are often used to model random samples in statistics. However, most real-world systems exhibit some type of dependency between variables, and an independent sequence is often an unrealistic model. Thus, the study of stochastic processes really begins with conditional probability—conditional distributions and conditional expectation. These will become essential tools for all that follows. Conditional Probability: Law of Total probability: Let B1, …, Bk be a sequence of events that partition the sample space. That is, the Bi are mutually exclusive(disjoint) and their union is equal to Ω. Then, for many event A, Ex1.8 Disease tests Ex1.9 Find the probability that it is a heart Ex1.10 Gambler’s ruin let pk denote the probability of reaching n when the gambler’s fortune is k. or using p0 = 0, pn = 1 we have The gambler’s ruin is Bayes Rule Given a countable sequence of events B1, B2, … which partition the sample space, a more general form of Bayes’ rule is Ex 1.11 The probability that teh employee is in fact lying. Conditional Distribution joint density function: P(X ≤ x, Y ≤ y) = ∫ − ∞x∫ − ∞yf(x, t)dtds Discrete Case: P(Y=y|X=x)= Continuous Case: For continuous randomo variables X and Y, the conditional density function of Y given X=x is P(Y ∈ R|X = x) = ∫RfY|X(y|x)dy 1.5 Conditional Expectation of Y given X=x Conditional Expectation of Y given X=x","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"}],"author":"夏目沉吟"},{"title":"几个重要假设检验的推导","slug":"几个重要假设检验的推导","date":"2018-08-01T07:16:53.000Z","updated":"2025-01-11T17:16:31.869Z","comments":true,"path":"2018/08/01/几个重要假设检验的推导/","permalink":"https://landau1994.github.io/2018/08/01/%E5%87%A0%E4%B8%AA%E9%87%8D%E8%A6%81%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E6%8E%A8%E5%AF%BC/","excerpt":"","text":"前言 假设检验是我们在日常研究中，经常碰到的统计问题。对于追求实用与效率的科研人员来说，各种不同的假设检验是可以用软件，点点鼠标，或者写写代码，就可以完成的。 不过，对于我们这些想要在生物信息领域深入和进阶，并且最终有所建树的学生来说，我们光会拧螺丝和用板子，用轮子是不够的，当有新的技术，新的需求出来之后，我们得要造新轮子，开发新方法。因此，我们还是得学学火箭是咋飞起来和板子以及轮子是咋造出来的知识。 我们以学习和介绍研究中比较基础的χ2, t, F三种检验的所对应的分布推导，开始我们的进阶之旅。 说明：本文的推导来自《概率统计讲义》第三版附录二，陈家鼎等编著，高等教育出版社出版。略微有所修改，阅读本文，只需修过本科阶段非数学专业的三门基础数学课：高等数学(不是很深，也不是很浅的数学分析)，线性代数，概率论与数理统计。 ## 正交矩阵与正态分布 在线性代数课程中，我们知道，若n阶方阵A = (aij)n × n满足ATA = I，写成标量的形式就是： 此时，我们称方阵A为正交矩阵。而且，通过线性代数的课程，我们知道，正交矩阵满足如下性质： + 1-1 设A是正交矩阵，则AAT = I，并且结合（1）可得： 1-2 设A是正交矩阵，则AT也是正交矩阵，并且|A| = 1或|A| = − 1，其中| ⋅ |表示行列式。 1-3 若A = (aij)n × n是正交矩阵，而x1, x2, …, xn是任意n个实数，对于 我们有 很抱歉，开头罗列了这么多线性代数的事实，不过，也没办法，要做菜，我们得先备料不是吗。下面我们开始做菜了。 定理1 设X1, X2, …, Xn相互独立，且都服从N(0, σ2)，又A = (aij)是正交矩阵，构造随机变量 证明 因Xi的分布密度是,且Xi是独立同分布样本（i.i.d.），故X1, X2, …, Xn联合密度为： 构造n维空间中的区域D: 则有： 注意到 于是（利用正交矩阵的性质） 容易验证，变换的雅可比式为 又故 故Y1, Y2, …, Yn相互独立，且不难看出，都服从N(0, σ2)。定理1证毕。 定理2设X1, X2, …, Xn相互独立，且X ∼ N(μ, σ2)。A = (aij)是n阶正交矩阵,构造随机变量， 则Y1, Y2, …, Yn相互独立，且 证明令Zi = Xi − μ，则Z1, Z2, …, Zn相互独立，都服从N(0, σ2),根据定理1知，相互独立。 且 但是 故Y1, Y2, …, Yn相互独立，且 关于χ2分布 前面的的都是小菜，接下来上主菜。我们要开始证明一系列很fancy的定理 定理3 设X1, X2, …, Xn相互独立，并且都服从N(0, 1),则服从n个自由度的χ2分布，其PDF(probability density function)为 证明 我们证明的策略是，先求出CDF(cumulative distribution function)F(u) = P{ξ ≤ u}，然后利用中值定理，证明F′(u) = kn(u)。 显然，当u ≤ 0, F(u) = 0, F′(u) = kn(u) 当u &gt; 0时，由于X1, X2, …, Xn相互独立，故X1, X2, …, Xn联合密度为， 故 故对于h &gt; 0,有 令 则 问题现在变为如何求S(x) 做代换,则 由此 有趣的是，我们可以看出 是n维单位球体的体积。不过在我们的问题中，我们可以看出它只和n有关的量。故 根据之前的不等式，结合中值定理： 所以 综上 由归一化条件∫ − ∞ + ∞p(u)du = 1知 而在数学分析的知识告诉我们 定理得证。 这个定理的一个副产物是，告诉了我们n维单位球体的体积 推论 若ξ ∼ χ2(n)，则有E(ξ) = n 证明 由定理1，结合数学期望的性质，知 □ 定理4 若ξ与η相互独立，且ξ ∼ χ2(n1), η ∼ χ2(n2)，则ξ + η ∼ χ2(n1 + n2) 证明 设ξ, η，ξ + η的分布函数分别为p1(x), p2(x), p(x)，我们先分别不加证明的引用概率论和Gamma函数的两个结论： 1).已知(X,Y)的联合密度是p(x, y)，Z = Y + Y的PDF为： pz(z) = ∫ − ∞∞p(x, z − x)dx 2).(p,q为正整数) 下面开始证明： 当 x ≤ 0时，P(ξ + η ≤ 0) = 0, p(x) = 0,定理成立。 当 x &gt; 0时， （ 综上： □ 定理5 若x1, x2, …, xn相互独立，且都服从分布N(0, 1),则有如下三条结论： X̄与相互独立 证明 构造正交矩阵 由此正交矩阵，我们可以构造随机变量： 有定理1可知，Y1, Y2, …, Yn相互独立，且都服从N(0, 1)， 我们发现Y1 ∼ N(0, 1)，因此，第一条结论得证。 由于故 第二条结论得证。 由于Y1, Y2, …, Yn相互独立，且 故X̄与独立，第三条结论得证 □ 推论 若x1, x2, …, xn相互独立，且都服从分布N(μ, σ2),则有如下三条结论： X̄与相互独立 关于t分布 定理6 设ξ, η相互独立，且ξ ∼ N(0, 1), η ∼ χ2(n)， 则，其PDF为： 证明 与定理3证明的思路类似，设F(u) = P{ζ ≤ u}证明F′(u) = tn(u), 由已知： 故F′(u) = tn(u) □ 定理5,6可以用来证明下面这个在统计学里很有作用的定理： 定理7 设X1, X2, …, Xn(n ≥ 2)相互独立，且都服从N(μ, σ2),则其中 证明 构造随机变量 根据定理5的推论，我们知道ξ, η相互独立，且ξ ∼ N(0, 1), η ∼ χ2(n − 1) 故根据定理6， 故 ## 关于F分布 定理8 设ξ, η相互独立，且ξ ∼ χ2(n1), η ∼ χ2(n2) 则 其PDF为： 证明 跟之前一样，令F(u) = P{ξ ≤ u} ，证明F′(u) = fn1, n2(u) 当 u ≤ 0, F(u) = 0, 故F′(u) = fn1, n2(u) □ 定理9 设X1, X2, …, Xn1, Y1, Y2, …, Yn, 这n1 + n2个随机变量相互独立，且都服从N(μ, σ2),则 证明 构造随机变量 由之前的结论，我们知道ξ ∼ χ2(n1 − 1), η ∼ χ2(n2 − 1), 接下来证明ξ, η的独立性，构造随机变量： 则 由已知U1, U2, …, Un1, V1, V2, …, Vn2 相互独立，且都服从N(0, 1),于是其联合分布密度为 所以,对于任意的实数a, b, c, d 独立性得证。 再结合定理8，","categories":[{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"Probability","slug":"Probability","permalink":"https://landau1994.github.io/tags/Probability/"}],"author":"夏目沉吟"},{"title":"Hello World","slug":"hello-world","date":"2018-07-29T03:35:19.000Z","updated":"2025-01-11T17:16:31.835Z","comments":false,"path":"2018/07/29/hello-world/","permalink":"https://landau1994.github.io/2018/07/29/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post $ hexo new &quot;My New Post&quot; More info: Writing Run server $ hexo server More info: Server Generate static files $ hexo generate More info: Generating Deploy to remote sites $ hexo deploy More info: Deployment","categories":[{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://landau1994.github.io/tags/hexo/"},{"name":"NodeJS","slug":"NodeJS","permalink":"https://landau1994.github.io/tags/NodeJS/"}]}],"categories":[{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/categories/genomics/"},{"name":"note","slug":"note","permalink":"https://landau1994.github.io/categories/note/"},{"name":"implementation","slug":"implementation","permalink":"https://landau1994.github.io/categories/implementation/"},{"name":"others","slug":"others","permalink":"https://landau1994.github.io/categories/others/"},{"name":"orthers","slug":"orthers","permalink":"https://landau1994.github.io/categories/orthers/"},{"name":"math","slug":"math","permalink":"https://landau1994.github.io/categories/math/"},{"name":"reference","slug":"reference","permalink":"https://landau1994.github.io/categories/reference/"}],"tags":[{"name":"note","slug":"note","permalink":"https://landau1994.github.io/tags/note/"},{"name":"AIVC","slug":"AIVC","permalink":"https://landau1994.github.io/tags/AIVC/"},{"name":"生物信息学","slug":"生物信息学","permalink":"https://landau1994.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"资源导航","slug":"资源导航","permalink":"https://landau1994.github.io/tags/%E8%B5%84%E6%BA%90%E5%AF%BC%E8%88%AA/"},{"name":"AI工具","slug":"AI工具","permalink":"https://landau1994.github.io/tags/AI%E5%B7%A5%E5%85%B7/"},{"name":"学习路径","slug":"学习路径","permalink":"https://landau1994.github.io/tags/%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/"},{"name":"AI","slug":"AI","permalink":"https://landau1994.github.io/tags/AI/"},{"name":"art","slug":"art","permalink":"https://landau1994.github.io/tags/art/"},{"name":"Python","slug":"Python","permalink":"https://landau1994.github.io/tags/Python/"},{"name":"Graph","slug":"Graph","permalink":"https://landau1994.github.io/tags/Graph/"},{"name":"Network","slug":"Network","permalink":"https://landau1994.github.io/tags/Network/"},{"name":"R","slug":"R","permalink":"https://landau1994.github.io/tags/R/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://landau1994.github.io/tags/scRNA-seq/"},{"name":"sc-seq","slug":"sc-seq","permalink":"https://landau1994.github.io/tags/sc-seq/"},{"name":"cell biology","slug":"cell-biology","permalink":"https://landau1994.github.io/tags/cell-biology/"},{"name":"stochastic Process","slug":"stochastic-Process","permalink":"https://landau1994.github.io/tags/stochastic-Process/"},{"name":"Probability","slug":"Probability","permalink":"https://landau1994.github.io/tags/Probability/"},{"name":"machine learning","slug":"machine-learning","permalink":"https://landau1994.github.io/tags/machine-learning/"},{"name":"genomics","slug":"genomics","permalink":"https://landau1994.github.io/tags/genomics/"},{"name":"genetics","slug":"genetics","permalink":"https://landau1994.github.io/tags/genetics/"},{"name":"ENCODE","slug":"ENCODE","permalink":"https://landau1994.github.io/tags/ENCODE/"},{"name":"HiC","slug":"HiC","permalink":"https://landau1994.github.io/tags/HiC/"},{"name":"ChIP-seq","slug":"ChIP-seq","permalink":"https://landau1994.github.io/tags/ChIP-seq/"},{"name":"ATAC-seq","slug":"ATAC-seq","permalink":"https://landau1994.github.io/tags/ATAC-seq/"},{"name":"biology","slug":"biology","permalink":"https://landau1994.github.io/tags/biology/"},{"name":"immunology","slug":"immunology","permalink":"https://landau1994.github.io/tags/immunology/"},{"name":"hexo","slug":"hexo","permalink":"https://landau1994.github.io/tags/hexo/"},{"name":"NodeJS","slug":"NodeJS","permalink":"https://landau1994.github.io/tags/NodeJS/"}]}